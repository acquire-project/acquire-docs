{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Acquire project","text":"<p>acquire-python is a python package that provides a multi-camera video streaming library focusing on performant microscopy.</p> <p>Note</p> <p>This is an early stage project. If you find it interesting please reach out!</p> <p>Support for:</p> <ul> <li>Up to two independent video streams</li> <li>Camera support:<ul> <li>Hamamatsu Orca Fusion BT (C15440-20UP) (windows only)</li> <li>Vieworks VC-151MX-M6H00</li> </ul> </li> <li>Streaming file format support:<ul> <li>Tiff</li> <li>Zarr v2</li> </ul> </li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>python -m pip install acquire-imaging\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>See the tests for more examples.</p> <p>The provided napari plugin is a good example of how to stream for visualization.</p>"},{"location":"#list-devices","title":"List devices","text":"<pre><code>import acquire\nprint(acquire.Runtime().device_manager().devices())\n</code></pre>"},{"location":"#finite-triggered-acquisition","title":"Finite triggered acquisition","text":"<pre><code>import acquire\nruntime = acquire.Runtime()\ndm = runtime.device_manager()\n\nprops = runtime.get_configuration()\n# select the first Hamamatsu camera\nprops.video[0].camera.identifier = dm.select(DeviceKind.Camera, \"hamamatsu.*\")\n# stream to zarr\nprops.video[0].storage.identifier = dm.select(DeviceKind.Storage, \"zarr\")\nprops.video[0].storage.settings.filename = \"out.zarr\"\nprops.video[0].camera.settings.shape = (2304, 2304)\nprops.video[0].camera.settings.pixel_type = SampleType.U16\nprops.video[0].max_frame_count = 100\nprops = runtime.set_configuration(props)\n\nruntime.start()\nruntime.stop()  # wait for acquisition to complete\n</code></pre>"},{"location":"#development","title":"Development","text":"<p>We welcome contributors. The following will help you get started building the code.</p>"},{"location":"#environment","title":"Environment","text":"<p>Requires</p> <ul> <li>CMake 3.23+ (download page or via   chocolatey)</li> <li>A C++20 compiler (Microsoft Visual Studio Community download   page, or clang)</li> <li>Rust (via rustup, see install   page)</li> <li>conda (optional; via   miniconda)</li> <li>libclang &gt;= v5.0 (on windows via choco <code>choco   install llvm</code> or, on osx, via brew <code>brew install llvm</code>)</li> </ul> <p>It's strongly recommended you create a python environment for development</p> <pre><code>conda create --name acquire python=3.11\nconda activate acquire\n</code></pre>"},{"location":"#build","title":"Build","text":"<pre><code>conda activate acquire\ngit submodule update --init --recursive\npip install maturin\nmaturin build -i python\n</code></pre> <p>Important When updating the 'acquire-video-runtime' (the c api), you need to manually trigger a rebuild by touching <code>wrapper.h</code>.</p> <pre><code>git submodule update # updates acquire-video-runtime\ntouch wrapper.h # will trigger a rebuild\npython -m build\n</code></pre> <p>This package depends on a submodule (acquire-video-runtime) and binaries from the following Acquire drivers:</p> <ul> <li>acquire-driver-common</li> <li>acquire-driver-hdcam</li> <li>acquire-driver-egrabber</li> <li>acquire-driver-zarr</li> <li>acquire-driver-spinnaker</li> </ul> <p>The build script will automatically try to fetch the binaries from GitHub releases. In order to configure which release of each driver to use, you can set the value in <code>drivers.json</code>:</p> <pre><code>{\n  \"acquire-driver-common\": \"0.1.0\",\n  \"acquire-driver-hdcam\": \"0.1.0\",\n  \"acquire-driver-egrabber\": \"0.1.0\",\n  \"acquire-driver-zarr\": \"0.1.0\",\n  \"acquire-driver-spinnaker\": \"0.1.0\"\n}\n</code></pre> <p>These values can be set to a specific version, or to <code>nightly</code> for nightly builds.</p>"},{"location":"#develop","title":"Develop","text":"<pre><code>pip install -e \".[testing]\"\npytest -s --tb=short --log-cli-level=0\n</code></pre> <p>This project uses <code>pre-commit</code> to run required checks as git hooks.</p> <pre><code>pip install pre-commit\npre-commit install\n</code></pre>"},{"location":"#troubleshooting","title":"Troubleshooting","text":""},{"location":"#maturin-cant-find-a-python-interpreter","title":"Maturin can't find a python interpreter","text":"<p><code>Maturin</code> is a command line tool associated with <code>pyo3</code>. It helps automate the build and packaging process. It's invoked by <code>setuptools</code> during a build.</p> <ol> <li>Double-check you've activated the right conda environment.</li> <li>Try <code>maturin build -i python</code></li> </ol> <p>This seems to happen on windows in anaconda environments when multiple python interpreters are available on the path.</p> <p>It seems to happen less frequently when invoked via pip - <code>pip install -e .</code> will end up invoking maturin.</p>"},{"location":"#working-with-an-editable-install-how-do-i-update-the-build","title":"Working with an editable install, how do I update the build?","text":"<p>It depends on what you changed:</p> <ul> <li>acquire-video-runtime (c/c++ code): <code>touch wrapper.h; maturin develop</code></li> <li>rust code: <code>maturin develop</code></li> </ul>"},{"location":"api_reference/","title":"API Reference","text":"<p>Information on the classes in <code>acquire-imaging</code> along with the attributes and methods associated with them.</p>"},{"location":"api_reference/#class-availabledata","title":"Class <code>AvailableData</code>","text":"<p>The <code>AvailableData</code> class represents the collection of frames that have been captured since the last call to runtime.get_available_data(). <code>AvailableData</code> objects should be set to have a short lifetime, since these objects reserve space on the video queue and will eventually block camera acquisition to ensure no data is overwritten before it can be processed.</p> <pre><code>class AvailableData:\n    def frames(self) -&gt; Iterator[VideoFrame]:\n        \"\"\"Returns an iterator over the video frames in the available data.\"\"\"\n\n    def get_frame_count(self) -&gt; int:\n        \"\"\"Returns the total number of video frames in the available data.\"\"\"\n\n    def __iter__(self) -&gt; Iterator[VideoFrame]:\n        \"\"\"Returns an iterator over the video frames in the available data.\"\"\"\n</code></pre> <ul> <li> <p>The <code>frames</code> method provides an iterator over these frames.</p> </li> <li> <p>Call <code>get_frame_count()</code> to query the number of frames in an <code>AvailableData</code> object.</p> </li> <li> <p>The <code>__iter__</code> method enables <code>AvailableData</code> objects to be iterated. </p> </li> </ul>"},{"location":"api_reference/#class-camera","title":"Class <code>Camera</code>","text":"<p>The <code>Camera</code> class is used to describe cameras or other video sources.</p> <pre><code>class Camera:\n    identifier: Optional[DeviceIdentifier]\n    settings: CameraProperties\n\n    def __init__(self, *args: None, **kwargs: Any) -&gt; None: ...\n    \"\"\"Initializes a Camera object with optional arguments.\"\"\"\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the Camera attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>identifier</code>: An optional attribute which contains an instance of the <code>DeviceIdentifier</code> class that describes the camera, or video source, if that device is natively supported. Otherwise, it is of type <code>None</code>.</p> </li> <li> <p><code>settings</code>: An instance of the <code>CameraProperties</code> class which contains the settings for the camera.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>Camera</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-cameraproperties","title":"Class <code>CameraProperties</code>","text":"<p>The <code>CameraProperties</code> class is used to set the desired camera properties for acquisition.</p> <pre><code>class CameraProperties:\n    exposure_time_us: float\n    line_interval_us: float\n    binning: float\n    pixel_type: SampleType\n    readout_direction: Direction\n    offset: Tuple[int, int]\n    shape: Tuple[int, int]\n    input_triggers: InputTriggers\n    output_triggers: OutputTriggers\n\n    def __init__(self, *args: None, **kwargs: Any) -&gt; None: ...\n    \"\"\"Initializes a CameraProperties object with optional arguments.\"\"\"\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the CameraProperties attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>exposure_time_us</code>: How long in microseconds your camera should collect light from the sample. However, for simulated cameras, this is just a waiting period before generating the next frame.</p> </li> <li> <p><code>line_interval_us</code>: The time to scan one line in microseconds in a rolling shutter camera.</p> </li> <li> <p><code>binning</code>: How many adjacent pixels in each direction to combine by averaging. For example, if <code>binning</code> is set to 2, a 2x2 square of pixels will be combined by averaging. If <code>binning</code> is set to 1, no pixels will be combined.</p> </li> <li> <p><code>pixel_type</code>: An instance of the <code>SampleType</code> class which specifies the numerical data type, for example u16, a 16-bit unsigned integer type.</p> </li> <li> <p><code>readout_direction</code>: An instance of the <code>Direction</code> class which specifies whether the data is readout forwards or backwards.</p> </li> <li> <p><code>offset</code>: A tuple of two integers representing the (x, y) offset in pixels of the image region of interest on the camera.</p> </li> <li> <p><code>shape</code>: A tuple of two integers representing the size in pixels of the image region of interest on the camera.</p> </li> <li> <p><code>input_triggers</code>: An instance of the <code>InputTriggers</code> class, which describes the trigger signals for starting acquisition, camera exposure, and acquiring a frame.</p> </li> <li> <p><code>output_triggers</code>: An instance of the <code>OutputTriggers</code> class, which describes the trigger signals for the camera exposure, acquiring a frame, as well as any wait times for sending the trigger signal.</p> </li> <li> <p>The <code>dict</code> method create a dictionary of a <code>CameraProperties</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-chunkingproperties","title":"Class <code>ChunkingProperties</code>","text":"<p>The <code>ChunkingProperties</code> class represents properties related to data chunking for storage in a Zarr container.</p> <pre><code>class ChunkingProperties:\n    max_bytes_per_chunk: int\n    tile: TileShape\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the ChunkingProperties attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>max_bytes_per_chunk</code>: The maximum number of bytes per data chunk.</p> </li> <li> <p><code>tile</code>: An instance of the <code>TileShape</code> class representing the shape of the data chunk tile.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>ChunkingProperties</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-deviceidentifier","title":"Class <code>DeviceIdentifier</code>","text":"<p>The <code>DeviceIdentifier</code> class represents an identifier for a device, such as a camera or video source.</p> <pre><code>class DeviceIdentifier:\n    id: Tuple[int, int]\n    kind: DeviceKind\n    name: str\n\n    def __init__(self, *args: None, **kwargs: Any) -&gt; None: ...\n    \"\"\"Initializes a DeviceIdentifier object with optional arguments.\"\"\"\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the DeviceIdentifier attributes.\"\"\"\n\n    @staticmethod\n    def none() -&gt; DeviceIdentifier: ...\n    \"\"\"Returns a \"None\" type DeviceIdentifier. Useful when a DeviceIdentifier is not needed.\"\"\"\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two DeviceIdentifier objects are equal.\"\"\"\n\n    def __ge__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceIdentifier is greater than or equal to another.\"\"\"\n\n    def __gt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceIdentifier is greater than another.\"\"\"\n\n    def __le__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceIdentifier is less than or equal to another.\"\"\"\n\n    def __lt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceIdentifier is less than another.\"\"\"\n\n    def __ne__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two DeviceIdentifier objects are not equal.\"\"\"\n</code></pre> <ul> <li> <p><code>id</code>: A tuple (driver_id, device_id) containing two U8 integers that serve to identify each driver and device uniquely for a given run.</p> </li> <li> <p><code>kind</code>: An instance of the <code>DeviceKind</code> class that represents the type or kind of the device.</p> </li> <li> <p><code>name</code>: A string representing the name or label of the device.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>DeviceIdentifier</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-devicekind","title":"Class <code>DeviceKind</code>","text":"<p>The <code>DeviceKind</code> class represents properties for supported devices, such as a camera or video source, in a given system.</p> <pre><code>class DeviceKind:\n    Camera: ClassVar[DeviceKind] = DeviceKind.Camera\n    NONE: ClassVar[DeviceKind] = DeviceKind.NONE\n    Signals: ClassVar[DeviceKind] = DeviceKind.Signals\n    StageAxis: ClassVar[DeviceKind] = DeviceKind.StageAxis\n    Storage: ClassVar[DeviceKind] = DeviceKind.Storage\n\n    def __init__(self, *args: None, **kwargs: Any) -&gt; None:\n        \"\"\"Initializes the DeviceKind class.\"\"\"\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two DeviceKind objects are equal.\"\"\"\n\n    def __ge__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceKind is greater than or equal to another.\"\"\"\n\n    def __gt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceKind is greater than another.\"\"\"\n\n    def __int__(self) -&gt; int:\n        \"\"\"Converts the DeviceKind to an integer.\"\"\"\n\n    def __le__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceKind is less than or equal to another.\"\"\"\n\n    def __lt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceKind is less than another.\"\"\"\n\n    def __ne__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two DeviceKind objects are not equal.\"\"\"\n</code></pre> <ul> <li> <p><code>Camera</code>: Enum-type class variable of <code>DeviceKind</code> that defines the cameras supported by the system. </p> </li> <li> <p><code>NONE</code>: Enum-type class variable of <code>DeviceKind</code> that is set to None if no device of the specified kind is available.</p> </li> <li> <p><code>Signals</code>: Enum-type class variable of <code>DeviceKind</code> that defines the signals supported by the system.</p> </li> <li> <p><code>StageAxis</code>: Enum-type class variable of <code>DeviceKind</code> that defines the stage axes supported by the system.</p> </li> <li> <p><code>Storage</code>: Enum-type class variable of <code>DeviceKind</code> that defines the storage supported by the system.</p> </li> </ul>"},{"location":"api_reference/#class-devicemanager","title":"Class <code>DeviceManager</code>","text":"<p>The <code>DeviceManager</code> class manages selection of available devices in the system.</p> <pre><code>class DeviceManager:\n    def devices(self) -&gt; List[DeviceIdentifier]:\n        \"\"\"Returns a list of all available device identifiers.\"\"\"\n\n    @overload\n    def select(self, kind: DeviceKind) -&gt; Optional[DeviceIdentifier]:\n        \"\"\"Selects the first available device of `kind`.\n\n        Args:\n            kind (DeviceKind): The type of device to select.\n\n        Returns:\n            Optional[DeviceIdentifier]: The identifier of the first available device of `kind`, or `None` if no such device is available.\n        \"\"\"\n\n    @overload\n    def select(self, kind: DeviceKind, name: Optional[str]) -&gt; Optional[DeviceIdentifier]:\n        \"\"\"Selects a specified device.\n\n        Args:\n            kind (DeviceKind): The type of device to select.\n            name (Optional[str]): The name of the device to select.\n\n        Returns:\n            Optional[DeviceIdentifier]: The selected device identifier, or None if the specified device is not available.\n        \"\"\"\n\n    def select_one_of(self, kind: DeviceKind, names: List[str]) -&gt; Optional[DeviceIdentifier]:\n        \"\"\"Selects the first device in the list of devices that is of one of the specified kinds.\n\n        Args:\n            kind (DeviceKind): The type of device to select.\n            names (List[str]): A list of device names to choose from.\n\n        Returns:\n            Optional[DeviceIdentifier]: The selected device identifier, or None if none of the specified devices are available.\n        \"\"\"\n</code></pre> <ul> <li> <p>Call <code>devices</code> to list all available devices. </p> </li> <li> <p>Call <code>select</code> to choose a type of device for acquisition.</p> </li> <li> <p>Call <code>select_one_of</code> to choose a particular instance in a category of devices for acquisition.</p> </li> </ul>"},{"location":"api_reference/#class-devicestate","title":"Class <code>DeviceState</code>","text":"<p>The <code>DeviceState</code> class represents the acquisition status of a device.</p> <pre><code>class DeviceState:\n    Closed: ClassVar[DeviceState] = DeviceState.Closed\n    AwaitingConfiguration: ClassVar[DeviceState] = DeviceState.AwaitingConfiguration\n    Armed: ClassVar[DeviceState] = DeviceState.Armed\n    Running: ClassVar[DeviceState] = DeviceState.Running\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two DeviceState objects are equal.\"\"\"\n\n    def __ge__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceState is greater than or equal to another.\"\"\"\n\n    def __gt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceState is greater than another.\"\"\"\n\n    def __int__(self) -&gt; int:\n        \"\"\"Converts the DeviceState to an integer.\"\"\"\n\n    def __le__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceState is less than or equal to another.\"\"\"\n\n    def __lt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this DeviceState is less than another.\"\"\"\n\n    def __ne__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two DeviceState objects are not equal.\"\"\"\n</code></pre> <ul> <li> <p><code>Closed</code>: Enum-type class variable of <code>DeviceState</code> that species when a device is not ready for configuration. </p> </li> <li> <p><code>AwaitingConfiguration</code>: Enum-type class variable of <code>DeviceState</code> that species when a device is ready for configuration.</p> </li> <li> <p><code>Armed</code>: Enum-type class variable of <code>DeviceState</code> that species when a device ready to stream data.</p> </li> <li> <p><code>Running</code>: Enum-type class variable of <code>DeviceState</code> that species when a device is streaming data.</p> </li> </ul>"},{"location":"api_reference/#class-direction","title":"Class <code>Direction</code>","text":"<p>The <code>Direction</code> class represents the direction that data is read for streaming.</p> <pre><code>class Direction:\n    Backward: ClassVar[Direction] = Direction.Backward\n    Forward: ClassVar[Direction] = Direction.Forward\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two Direction objects are equal.\"\"\"\n\n    def __ge__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this Direction is greater than or equal to another.\"\"\"\n\n    def __gt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this Direction is greater than another.\"\"\"\n\n    def __int__(self) -&gt; int:\n        \"\"\"Converts the Direction to an integer.\"\"\"\n\n    def __le__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this Direction is less than or equal to another.\"\"\"\n\n    def __lt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this Direction is less than another.\"\"\"\n\n    def __ne__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two Direction objects are not equal.\"\"\"\n</code></pre> <ul> <li> <p><code>Backward</code>: Enum-type class variable of <code>Direction</code> that species when data is streamed backward. </p> </li> <li> <p><code>Forward</code>: Enum-type class variable of <code>Direction</code> that species when data is streamed forward.</p> </li> </ul>"},{"location":"api_reference/#class-inputtriggers","title":"Class <code>InputTriggers</code>","text":"<p>The <code>InputTriggers</code> class represents input triggers for a device.</p> <pre><code>class InputTriggers:\n    acquisition_start: Trigger\n    exposure: Trigger\n    frame_start: Trigger\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the InputTriggers attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>acquisition_start</code>: An instance of the <code>Trigger</code> class representing the trigger for starting acquisition.</p> </li> <li> <p><code>exposure</code>: An instance of the <code>Trigger</code> class representing the trigger for exposure.</p> </li> <li> <p><code>frame_start</code>: An instance of the <code>Trigger</code> class representing the trigger for starting a frame.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>InputTriggers</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-outputtriggers","title":"Class <code>OutputTriggers</code>","text":"<p>The <code>OutputTriggers</code> class represents output triggers for a device.</p> <pre><code>class OutputTriggers:\n    exposure: Trigger\n    frame_start: Trigger\n    trigger_wait: Trigger\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the OutputTriggers attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>exposure</code>: An instance of the <code>Trigger</code> class representing the trigger for exposure.</p> </li> <li> <p><code>frame_start</code>: An instance of the <code>Trigger</code> class representing the trigger for starting a frame.</p> </li> <li> <p><code>trigger_wait</code>: An instance of the <code>Trigger</code> class representing the trigger for waiting before continuing acquisition.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>OutputTriggers</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-pid","title":"Class <code>PID</code>","text":"<p>The <code>PID</code> class represents proportional-integral-derivative (PID) values.</p> <pre><code>class PID:\n    derivative: float\n    integral: float\n    proportional: float\n\n    def __init__(self, *args: None, **kwargs: Any) -&gt; None: ...\n    \"\"\"Initializes a PID object with optional arguments.\"\"\"\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the PID attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>derivative</code>: The derivative value for the PID.</p> </li> <li> <p><code>integral</code>: The integral value for the PID.</p> </li> <li> <p><code>proportional</code>: The proportional value for the PID.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>PID</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-properties","title":"Class <code>Properties</code>","text":"<p>The <code>Properties</code> class represents properties related to video streams.</p> <pre><code>class Properties:\n    video: Tuple[VideoStream, VideoStream]\n\n    def __init__(self, *args: None, **kwargs: Any) -&gt; None: ..\n    \"\"\"Initializes a Properties object with optional arguments.\"\"\".\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the Properties attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>video</code>: A tuple containing two <code>VideoStream</code> instances which contain information on the camera was used for acquisition and how the data is stored.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>Properties</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-runtime","title":"Class <code>Runtime</code>","text":"<p>The <code>Runtime</code> class coordinates the devices with the storage disc including selecting the devices, setting their properties, and starting and stopping acqusition.</p> <pre><code>class Runtime:\n    def __init__(self, *args: None, **kwargs: Any) -&gt; None:\n        \"\"\"Initializes the Runtime object with optional arguments.\"\"\"\n\n    def device_manager(self) -&gt; DeviceManager:\n        \"\"\"Returns the DeviceManager instance associated with this Runtime.\"\"\"\n\n    def get_available_data(self, stream_id: int) -&gt; AvailableData:\n        \"\"\"Returns the AvailableData instance for the given stream ID.\n\n        Args:\n            stream_id (int): The ID of the stream for which available data is requested.\n\n        Returns:\n            AvailableData: The AvailableData instance for the given stream ID.\n        \"\"\"\n\n    def get_configuration(self) -&gt; Properties:\n        \"\"\"Returns the current configuration properties of the runtime.\"\"\"\n\n    def get_state(self) -&gt; DeviceState:\n        \"\"\"Returns the current state of the device.\"\"\"\n\n    def set_configuration(self, properties: Properties) -&gt; Properties:\n        \"\"\"Applies the provided configuration properties to the runtime.\n\n        Args:\n            properties (Properties): The properties to be set.\n\n        Returns:\n            Properties: The updated configuration properties.\n        \"\"\"\n\n    def start(self) -&gt; None:\n        \"\"\"Starts the runtime, allowing it to collect data.\"\"\"\n\n    def stop(self) -&gt; None:\n        \"\"\"Stops the runtime, ending data collection after the max number of frames is collected.\"\"\"\n\n    def abort(self) -&gt; None:\n        \"\"\"Aborts the runtime, terminating it immediately.\"\"\"\n</code></pre> <ul> <li> <p>Call <code>device_manager()</code> to return the <code>DeviceManager</code> object associated with this <code>Runtime</code> instance. </p> </li> <li> <p>Call <code>get_available_data</code> with a specific <code>stream_id</code> to return the <code>AvailableData</code> associated with the <code>stream_id</code>.</p> </li> <li> <p>Call <code>get_configuration()</code> to return the <code>Properties</code> object associated with this <code>Runtime</code> instance.</p> </li> <li> <p>Call <code>get_state()</code> to return the <code>DeviceState</code> object associated with this <code>Runtime</code> instance.</p> </li> <li> <p>Call <code>set_configuration</code> with a <code>Properties</code> object to change the properties of this <code>Runtime</code> instance.</p> </li> <li> <p>Call <code>start()</code> to begin data acquisition.</p> </li> <li> <p>Call <code>stop()</code> to end data acquisition once the max number of frames specified in <code>config.video[0].max_frame_count</code> is collected.</p> </li> <li> <p>Call <code>abort()</code> to  <code>Runtime</code> instance.</p> </li> </ul>"},{"location":"api_reference/#class-sampleratehz","title":"Class <code>SampleRateHz</code>","text":"<p>The <code>SampleRateHz</code> class represents the sampling rate in hertz.</p> <pre><code>class SampleRateHz:\n    numerator: int\n    denominator: int\n\n    def __init__(self, *args: None, **kwargs: Any) -&gt; None: ...\n    \"\"\"Initializes a SampleRateHz object with optional arguments.\"\"\"\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the SampleRateHz attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>numerator</code>: The numerator part of the sampling rate fraction.</p> </li> <li> <p><code>denominator</code>: The denominator part of the sampling rate fraction.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>SampleRateHz</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-sampletype","title":"Class <code>SampleType</code>","text":"<p>The <code>SampleType</code> class defines the type of the values in the streamed data.</p> <pre><code>class SampleType:\n    F32: ClassVar[SampleType] = SampleType.F32\n    I16: ClassVar[SampleType] = SampleType.I16\n    I8: ClassVar[SampleType] = SampleType.I8\n    U16: ClassVar[SampleType] = SampleType.U16\n    U8: ClassVar[SampleType] = SampleType.U8\n    U10: ClassVar[SampleType] = SampleType.U10\n    U12: ClassVar[SampleType] = SampleType.U12\n    U14: ClassVar[SampleType] = SampleType.U14\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two SampleType objects are equal.\"\"\"\n\n    def __ge__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SampleType is greater than or equal to another.\"\"\"\n\n    def __gt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SampleType is greater than another.\"\"\"\n\n    def __int__(self) -&gt; int:\n        \"\"\"Converts the SampleType to an integer.\"\"\"\n\n    def __le__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SampleType is less than or equal to another.\"\"\"\n\n    def __lt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SampleType is less than another.\"\"\"\n\n    def __ne__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two SampleType objects are not equal.\"\"\"\n</code></pre> <ul> <li> <p><code>F32</code>: Enum-type class variable of <code>SampleType</code> that specifies values of 32-bit floating point type.</p> </li> <li> <p><code>I16</code>: Enum-type class variable of <code>SampleType</code> that specifies values of 16-bit signed integer type.</p> </li> <li> <p><code>I8</code>: Enum-type class variable of <code>SampleType</code> that specifies values of 8-bit signed integer type.</p> </li> <li> <p><code>U16</code>: Enum-type class variable of <code>SampleType</code> that specifies values of 16-bit unsigned integer type.</p> </li> <li> <p><code>U8</code>: Enum-type class variable of <code>SampleType</code> that specifies values of 8-bit unsigned integer type.</p> </li> <li> <p><code>U10</code>: Enum-type class variable of <code>SampleType</code> that specifies values of 10-bit unsigned integer type.</p> </li> <li> <p><code>U12</code>: Enum-type class variable of <code>SampleType</code> that specifies values of 12-bit unsigned integer type.</p> </li> <li> <p><code>U14</code>: Enum-type class variable of <code>SampleType</code> that specifies values of 14-bit unsigned integer type.</p> </li> </ul>"},{"location":"api_reference/#class-signaliokind","title":"Class <code>SignalIOKind</code>","text":"<p>The <code>SignalIOKind</code> class defines the type of input and output signals.</p> <pre><code>class SignalIOKind:\n    Input: ClassVar[SignalIOKind] = SignalIOKind.Input\n    Output: ClassVar[SignalIOKind] = SignalIOKind.Output\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two SignalIOKind objects are equal.\"\"\"\n\n    def __ge__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SignalIOKind is greater than or equal to another.\"\"\"\n\n    def __gt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SignalIOKind is greater than another.\"\"\"\n\n    def __int__(self) -&gt; int:\n        \"\"\"Converts the SignalIOKind to an integer.\"\"\"\n\n    def __le__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SignalIOKind is less than or equal to another.\"\"\"\n\n    def __lt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SignalIOKind is less than another.\"\"\"\n\n    def __ne__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two SignalIOKind objects are not equal.\"\"\"\n</code></pre> <ul> <li> <p><code>Input</code>: Enum-type class variable of <code>SignalIOKind</code> that specifies signal coming in to the device.</p> </li> <li> <p><code>Output</code>: Enum-type class variable of <code>SignalIOKind</code> that specifies signal sent out of the device.</p> </li> </ul>"},{"location":"api_reference/#class-signaltype","title":"Class <code>SignalType</code>","text":"<p>The <code>SignalType</code> class specifies whether a signal is analog or digital.</p> <pre><code>class SignalType:\n    Analog: ClassVar[SignalType] = SignalType.Analog\n    Digital: ClassVar[SignalType] = SignalType.Digital\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two SignalType objects are equal.\"\"\"\n\n    def __ge__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SignalType is greater than or equal to another.\"\"\"\n\n    def __gt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SignalType is greater than another.\"\"\"\n\n    def __int__(self) -&gt; int:\n        \"\"\"Converts the SignalType to an integer.\"\"\"\n\n   def __le__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SignalType is less than or equal to another.\"\"\"\n\n    def __lt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this SignalType is less than another.\"\"\"\n\n    def __ne__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two SignalType objects are not equal.\"\"\"\n</code></pre> <ul> <li> <p><code>Analog</code>: Enum-type class variable of <code>SignalType</code> that specifies a signal is analog.</p> </li> <li> <p><code>Input</code>: Enum-type class variable of <code>SignalType</code> that specifies signal coming in to the device.</p> </li> </ul>"},{"location":"api_reference/#class-storage","title":"Class <code>Storage</code>","text":"<p>The <code>Storage</code> class represents storage settings for the acquired data.</p> <pre><code>class Storage:\n    identifier: Optional[DeviceIdentifier]\n    settings: StorageProperties\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the Storage attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>identifier</code>: An optional attribute which contains an instance of the <code>DeviceIdentifier</code> class that describes the storage device if that device is natively supported. Otherwise, it is of type <code>None</code>.</p> </li> <li> <p><code>settings</code>: An instance of the <code>StorageProperties</code> class which contains the settings for the data storage.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>Storage</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-storageproperties","title":"Class <code>StorageProperties</code>","text":"<p>The <code>StorageProperties</code> class represents properties for data storage.</p> <pre><code>class StorageProperties:\n    external_metadata_json: Optional[str]\n    filename: Optional[str]\n    first_frame_id: int\n    pixel_scale_um: Tuple[float, float]\n    chunking: ChunkingProperties\n    enable_multiscale: bool\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the StorageProperties attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>external_metadata_json</code>: An optional attribute representing external metadata in JSON format.</p> </li> <li> <p><code>filename</code>: An optional attribute representing the filename.</p> </li> <li> <p><code>first_frame_id</code>: An integer representing the ID of the first frame.</p> </li> <li> <p><code>pixel_scale_um</code>: A tuple of two floats representing pixel size in micrometers.</p> </li> <li> <p><code>chunking</code>: An instance of the <code>ChunkingProperties</code> class representing data chunking settings.</p> </li> <li> <p><code>enable_multiscale</code>: A boolean indicating whether multiscale storage is desired.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>StorageProperties</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-tileshape","title":"Class <code>TileShape</code>","text":"<p>The <code>TileShape</code> class represents the tile shape, or voxel size, for tile scanning acquisition.</p> <pre><code>class TileShape:\n    width: int\n    height: int\n    planes: int\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the TileShape attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>width</code>: The width of the tile.</p> </li> <li> <p><code>height</code>: The height of the tile.</p> </li> <li> <p><code>planes</code>: The number of planes in the tile.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>TileShape</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-trigger","title":"Class <code>Trigger</code>","text":"<p>The <code>Trigger</code> class represents a trigger signal.</p> <pre><code>class Trigger:\n    edge: TriggerEdge\n    enable: bool\n    line: int\n    kind: SignalIOKind\n\n    def __init__(self, *args: None, **kwargs: Any) -&gt; None: ...\n    \"\"\"Initializes a Trigger object with optional arguments.\"\"\"\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the Trigger attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>edge</code>: An instance of the <code>TriggerEdge</code> class specifying if the trigger is on the rising or falling edge trigger signal.</p> </li> <li> <p><code>enable</code>: A boolean indicating whether the trigger is enabled.</p> </li> <li> <p><code>line</code>: An integer representing the line of the trigger signal.</p> </li> <li> <p><code>kind</code>: An instance of the <code>SignalIOKind</code> class specifying if the signal is input or output.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>Trigger</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-triggeredge","title":"Class <code>TriggerEdge</code>","text":"<p>The <code>TriggerEdge</code> class represents what edge of the trigger function initiates the trigger.</p> <pre><code>class TriggerEdge:\n    Falling: ClassVar[TriggerEdge] = TriggerEdge.Falling\n    NotApplicable: ClassVar[TriggerEdge] = TriggerEdge.NotApplicable\n    Rising: ClassVar[TriggerEdge] = TriggerEdge.Rising\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two TriggerEdge objects are equal.\"\"\"\n\n    def __ge__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this TriggerEdge is greater than or equal to another.\"\"\"\n\n    def __gt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this TriggerEdge is greater than another.\"\"\"\n\n    def __int__(self) -&gt; int:\n        \"\"\"Converts the TriggerEdge to an integer.\"\"\"\n\n    def __le__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this TriggerEdge is less than or equal to another.\"\"\"\n\n    def __lt__(self, other: object) -&gt; bool:\n        \"\"\"Checks if this TriggerEdge is less than another.\"\"\"\n\n    def __ne__(self, other: object) -&gt; bool:\n        \"\"\"Checks if two TriggerEdge objects are not equal.\"\"\"\n</code></pre> <ul> <li> <p><code>Falling</code>: Enum-type class variable of <code>TriggerEdge</code> that defines the falling edge of the trigger. </p> </li> <li> <p><code>NotApplicable</code>: Enum-type class variable of <code>TriggerEdge</code> that defines if a trigger does not have a rising or falling edge.</p> </li> <li> <p><code>Rising</code>: Enum-type class variable of <code>TriggerEdge</code> that defines the rising edge of the trigger.</p> </li> </ul>"},{"location":"api_reference/#class-videoframe","title":"Class <code>VideoFrame</code>","text":"<p>The <code>VideoFrame</code> class represents data from acquisition of a frame.</p> <pre><code>class VideoFrame:\n    def data(self) -&gt; NDArray[Any]:\n        \"\"\"Returns the data of the video frame as an NDArray.\"\"\"\n\n    def metadata(self) -&gt; VideoFrameMetadata:\n        \"\"\"Returns the metadata associated with the video frame.\"\"\"\n</code></pre> <ul> <li> <p>Call <code>data()</code> to create an NDArray of the <code>VideoFrame</code> data. </p> </li> <li> <p>Call <code>metadata()</code> to query the metadata of <code>VideoFrame</code>. </p> </li> </ul>"},{"location":"api_reference/#class-videoframemetadata","title":"Class <code>VideoFrameMetadata</code>","text":"<p>The <code>VideoFrameMetadata</code> class represents metadata related to a video frame.</p> <pre><code>class VideoFrameMetadata:\n    frame_id: int\n    timestamps: VideoFrameTimestamps\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the VideoFrameMetadata attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>frame_id</code>: An integer representing the ID of the video frame.</p> </li> <li> <p><code>timestamps</code>: An instance of the <code>VideoFrameTimestamps</code> class specifying whether the video timestamps are based on the hardware clock or the acquisition clock.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>VideoFrameTimestamps</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-videoframetimestamps","title":"Class <code>VideoFrameTimestamps</code>","text":"<p>The <code>VideoFrameTimestamps</code> class represents timestamps related to a video frame.</p> <pre><code>class VideoFrameTimestamps:\n    hardware: int\n    acq_thread: int\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the VideoFrameTimestamps attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>hardware</code>: An integer representing hardware timestamps.</p> </li> <li> <p><code>acq_thread</code>: An integer representing timestamps from the acquisition thread.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>VideoFrameTimestamps</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-videostream","title":"Class <code>VideoStream</code>","text":"<p>The <code>VideoStream</code> class represents a video stream.</p> <pre><code>class VideoStream:\n    camera: Camera\n    storage: Storage\n    max_frame_count: int\n    frame_average_count: int\n\n    def dict(self) -&gt; Dict[str, Any]: ...\n    \"\"\"Returns a dictionary of the VideoStream attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>camera</code>: An instance of the <code>Camera</code> class representing the camera used in the video stream.</p> </li> <li> <p><code>storage</code>: An instance of the <code>Storage</code> class representing the storage settings for the video stream.</p> </li> <li> <p><code>max_frame_count</code>: An integer representing the maximum number of frames in the video stream.</p> </li> <li> <p><code>frame_average_count</code>: An integer representing the number of frames to average in the video stream.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>VideoStream</code> object's attributes.</p> </li> </ul>"},{"location":"api_reference/#class-voltagerange","title":"Class <code>VoltageRange</code>","text":"<p>The <code>VoltageRange</code> class represents a range of voltage values.</p> <pre><code>class VoltageRange:\n    mn: float\n    mx: float\n\n    @overload\n    def __init__(self) -&gt; None: ...\n    \"\"\"Initializes a VoltageRange object\"\"\"\n\n    @overload\n    def __init__(self, mn: float, mx: float) -&gt; None: ...\n    \"\"\"Initializes a VoltageObject object with mn and mx provided.\"\"\"\n\n    def dict(self) -&gt; Dict[str, float]: ...\n    \"\"\"Returns a dictionary of the VoltageRange attributes.\"\"\"\n</code></pre> <ul> <li> <p><code>mn</code>: A float representing the minimum voltage value.</p> </li> <li> <p><code>mx</code>: A float representing the maximum voltage value.</p> </li> <li> <p>The <code>dict</code> method creates a dictionary of a <code>VoltageRange</code> object's attributes.</p> </li> </ul>"},{"location":"for_contributors/","title":"For contributors","text":"<p>Documentation for those looking to contribute to the Acquire project.</p> <p>GitHub repositories: https://github.com/acquire-project</p>"},{"location":"get_started/","title":"Getting Started with Acquire","text":"<p>Acquire (<code>acquire-imaging</code> on PyPI) is a Python package providing a multi-camera video streaming library focused on performant microscopy, with support for up to two simultaneous, independent, video streams.</p> <p>This tutorial covers Acquire installation and shows an example of using Acquire with its provided simulated cameras to demonstrate the acquisition process. </p>"},{"location":"get_started/#installation","title":"Installation","text":"<p>To install Acquire on Windows, macOS, or Ubuntu, simply run the following command:</p> <pre><code>python -m pip install acquire-imaging\n</code></pre> <p>You will probably want to have a fresh conda environment or virtualenv. For example, with conda:</p> <pre><code>conda create -n acquire python=3.10 # follow the prompts and proceed with the defaults\nconda activate acquire\npython -m pip install acquire-imaging\n</code></pre> <p>or with virtualenv:</p> <pre><code>$ python -m venv venv\n$ . ./venv/bin/activate # or on Windows: .\\venv\\Scripts\\Activate.bat or .\\venv\\Scripts\\Activate.ps1\n(venv) $ python -m pip install acquire-imaging\n</code></pre> <p>Once you have Acquire installed, simply call <code>import acquire</code> in your script, notebook, or module to start utilizing the package.</p> <pre><code>import acquire\n</code></pre>"},{"location":"get_started/#supported-cameras-and-file-formats","title":"Supported Cameras and File Formats","text":"<p>Acquire supports the following cameras (currently only on Windows):</p> <ul> <li>Hamamatsu Orca Fusion BT (C15440-20UP)</li> <li>Vieworks VC-151MX-M6H00</li> <li>FLIR Blackfly USB3 (BFLY-U3-23S6M-C)</li> <li>FLIR Oryx 10GigE (ORX-10GS-51S5M-C)</li> </ul> <p>Acquire also supports the following output file formats:</p> <ul> <li>Tiff</li> <li>Zarr</li> </ul> <p>For testing and demonstration purposes, Acquire provides a few simulated cameras, as well as raw and trash output devices. To see all the devices that Acquire supports, you can run the following script:</p> <pre><code>import acquire\n\nfor device in acquire.Runtime().device_manager().devices():\n    print(device)\n</code></pre>"},{"location":"get_started/#tutorial-prerequisites","title":"Tutorial Prerequisites","text":"<p>We will be writing to and reading from the Zarr format, using the Dask library to load and inspect the data, and visualizing the data using napari.</p> <p>You can install these prerequisites with:</p> <pre><code>python -m pip install dask \"napari[all]\" zarr\n</code></pre>"},{"location":"get_started/#setup-for-acquisition","title":"Setup for Acquisition","text":"<p>We will use one of Acquire's simulated cameras to generate data for us and use Zarr for our output file format.</p> <p>Let's set up our runtime and device manager, then list the currently supported devices.</p> <p><pre><code>import acquire\n\nruntime = acquire.Runtime()\ndm = runtime.device_manager()\n\nfor device in dm.devices():\n    print(device)\n</code></pre> The runtime is the main entry point in Acquire. Through the runtime, you configure your devices, start acquisition, check acquisition status, inspect data as it streams from your cameras, and terminate acquisition.</p> <p>Let's configure our devices now. To do this, we'll get a copy of the current runtime configuration. We can update the configuration with identifiers from the the runtime's device manager, but we won't actually instantiate these devices until we start acquiring.</p> <p>Acquire supports up to two video streams. These streams consist of a source (i.e., a camera), optionally a filter, and a sink (an output, like a Zarr dataset or a Tiff file). Before configuring the streams, grab the current configuration of the <code>Runtime</code> object with:</p> <pre><code>config = runtime.get_configuration()\n</code></pre> <p>Video streams are configured independently. Configure the first video stream by setting properties on <code>config.video[0]</code> and the second video stream with <code>config.video[1]</code>. We'll be using simulated cameras, one generating a radial sine pattern and one generating a random pattern.</p> <pre><code>config.video[0].camera.identifier = dm.select(acquire.DeviceKind.Camera, \"simulated: radial sin\")\n\n# how many adjacent pixels in each direction to combine by averaging; here, 1 means not to combine\nconfig.video[0].camera.settings.binning = 1\n\n# how long (in microseconds) your camera should collect light from the sample; for simulated cameras,\n# this is just a waiting period before generating the next frame\nconfig.video[0].camera.settings.exposure_time_us = 5e4  # 50 ms\n\n# the data type representing each pixel; here we choose unsigned 8-bit integer\nconfig.video[0].camera.settings.pixel_type = acquire.SampleType.U8\n\n# the shape, in pixels, of the image; width first, then height\nconfig.video[0].camera.settings.shape = (1024, 768)\n</code></pre> <pre><code>config.video[1].camera.identifier = dm.select(acquire.DeviceKind.Camera, \"simulated: uniform random\")\n\n# how many adjacent pixels in each direction to combine by averaging; here, 1 means not to combine\nconfig.video[1].camera.settings.binning = 1\n\n# how long (in microseconds) your camera should collect light from the sample; for simulated cameras,\n# this is just a waiting period before generating the next frame\nconfig.video[1].camera.settings.exposure_time_us = 1e4  # 10 ms\n\n# the data type representing each pixel; here we choose unsigned 8-bit integer\nconfig.video[1].camera.settings.pixel_type = acquire.SampleType.U8\n\n# the shape, in pixels, of the image; width first, then height\nconfig.video[1].camera.settings.shape = (1280, 720)\n</code></pre> <p>Now we'll configure each output, or sink device. For both simulated cameras, we'll be writing to Zarr, a format which supports chunked arrays.</p> <pre><code>config.video[0].storage.identifier = dm.select(acquire.DeviceKind.Storage, \"Zarr\")\n\n# what file or directory to write the data to\nconfig.video[0].storage.settings.filename = \"output1.zarr\"\n\n# where applicable, how large should a chunk file get before opening the next chunk file\nconfig.video[0].storage.settings.chunking.max_bytes_per_chunk = 32 * 2**20  # 32 MiB chunk sizes\n</code></pre> <pre><code>config.video[1].storage.identifier = dm.select(acquire.DeviceKind.Storage, \"Zarr\")\n\n# what file or directory to write the data to\nconfig.video[1].storage.settings.filename = \"output2.zarr\"\n\n# where applicable, how large should a chunk file get before opening the next chunk file\nconfig.video[1].storage.settings.chunking.max_bytes_per_chunk = 64 * 2**20  # 64 MiB chunk sizes\n</code></pre> <p>Finally, let's specify how many frames to generate for each camera before stopping our simulated acquisition. We also need to register our configuration with the runtime.</p> <p>If you want to let the runtime just keep acquiring effectively forever, you can set <code>max_frame_count</code> to <code>2**64 - 1</code>.</p> <pre><code>config.video[0].max_frame_count = 100 # collect 100 frames\nconfig.video[1].max_frame_count = 150 # collect 150 frames\n\nconfig = runtime.set_configuration(config)\n</code></pre> <p>Note</p> <p>If you run this tutorial multiple times, you can clear output from previous runs with:</p> <pre><code>import os\nimport shutil\n\nif config.video[0].storage.settings.filename in os.listdir(\".\"):\n    shutil.rmtree(config.video[0].storage.settings.filename)\n\nif config.video[1].storage.settings.filename in os.listdir(\".\"):\n    shutil.rmtree(config.video[1].storage.settings.filename)\n</code></pre>"},{"location":"get_started/#acquire-data","title":"Acquire Data","text":"<p>To start aquiring data:</p> <pre><code>runtime.start()\n</code></pre> <p>Acquisition happens in a separate thread, so at any point we can check on the status by calling <code>runtime.get_state()</code>.</p> <pre><code>runtime.get_state()\n</code></pre> <p>Finally, once we're done acquiring, we call <code>runtime.stop()</code>. This method will wait until you've reached the number of frames specified in <code>config.video[0].max_frame_count</code> or <code>config.video[1].max_frame_count</code>, whichever is larger.</p> <pre><code>runtime.stop()\n</code></pre>"},{"location":"get_started/#visualizing-the-data-with-napari","title":"Visualizing the Data with napari","text":"<p>Let's take a look at what we've written. We'll load each Zarr dataset as a Dask array and inspect its dimensions, then we'll use napari to view it.</p> <pre><code>import dask.array as da\nimport napari\n</code></pre> <pre><code>data1 = da.from_zarr(config.video[0].storage.settings.filename, component=\"0\")\ndata1\n</code></pre> <pre><code>data2 = da.from_zarr(config.video[1].storage.settings.filename, component=\"0\")\ndata2\n</code></pre> <pre><code>viewer1 = napari.view_image(data1)\n</code></pre> <pre><code>viewer2 = napari.view_image(data2)\n</code></pre>"},{"location":"get_started/#conclusion","title":"Conclusion","text":"<p>For more examples of using Acquire, check out our tutorials page. #ADD LINK</p>"},{"location":"props_json/","title":"Saving and Loading Properties from a JSON file","text":"<p>This tutorial will provide an example of saving and subsequently loading a <code>Properties</code> object from a JSON file.</p>"},{"location":"props_json/#initialize-runtime","title":"Initialize Runtime","text":"<p>To start, we'll import <code>Acquire</code> and create a <code>Runtime</code> object, which coordinates the streaming process.</p> <pre><code>import acquire\nruntime = acquire.Runtime()\n</code></pre>"},{"location":"props_json/#configure-camera","title":"Configure Camera","text":"<p>All camera settings are captured by an instance of the <code>Properties</code> class, which will be associated with a given camera acquisition. </p> <p><pre><code># Instantiate a Properties object for the Runtime\nprops = runtime.get_configuration()\n</code></pre> You can update any of the settings in this instance of <code>Properties</code>. To save any updated settings, use the <code>set_configuration</code> function.  For this tutorial, we'll simply specify a camera, and then save these new settings. Note that more settings must be provided before this <code>Properties</code> object could be used for an acquistion.</p> <pre><code># set the radial sine simulated camera as the first video stream\nprops.video[0].camera.identifier = runtime.device_manager().select(acquire.DeviceKind.Camera, \"simulated: radial sin\")\n\n# save the updated settings\nprops = runtime.set_configuration(props)\n</code></pre>"},{"location":"props_json/#save-properties-to-a-json-file","title":"Save Properties to a JSON file","text":"<p>We'll utilize the json library to write our properties to a JSON file to save for subsequent acquisition.</p> <pre><code>import json\n\n# cast the properties to a dictionary\nprops = props.dict()\n\n# convert the dictionary to json with \"human-readable\" formatting\nprops = json.dumps(props, indent=4, sort_keys=True)\n\n# save the properties to file \"sample_props.json\" in the current directory\nwith open(\"sample_props.json\", \"w\") as outfile:\n    outfile.write(props)\n</code></pre>"},{"location":"props_json/#example-json-file","title":"Example JSON file","text":"<p>The resulting sample_props.json file is below:</p> <pre><code>{\n    \"video\": [\n        {\n            \"camera\": {\n                \"identifier\": {\n                    \"id\": [\n                        0,\n                        1\n                    ],\n                    \"kind\": \"Camera\",\n                    \"name\": \"simulated: radial sin\"\n                },\n                \"settings\": {\n                    \"binning\": 1,\n                    \"exposure_time_us\": 0.0,\n                    \"input_triggers\": {\n                        \"acquisition_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"exposure\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"frame_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        }\n                    },\n                    \"line_interval_us\": 0.0,\n                    \"offset\": [\n                        0,\n                        0\n                    ],\n                    \"output_triggers\": {\n                        \"exposure\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"frame_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"trigger_wait\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        }\n                    },\n                    \"pixel_type\": \"U16\",\n                    \"readout_direction\": \"Forward\",\n                    \"shape\": [\n                        1,\n                        1\n                    ]\n                }\n            },\n            \"frame_average_count\": 0,\n            \"max_frame_count\": 18446744073709551615,\n            \"storage\": {\n                \"identifier\": {\n                    \"id\": [\n                        0,\n                        0\n                    ],\n                    \"kind\": \"NONE\",\n                    \"name\": \"\"\n                },\n                \"settings\": {\n                    \"chunking\": {\n                        \"max_bytes_per_chunk\": 16777216,\n                        \"tile\": {\n                            \"height\": 0,\n                            \"planes\": 0,\n                            \"width\": 0\n                        }\n                    },\n                    \"enable_multiscale\": false,\n                    \"external_metadata_json\": \"\",\n                    \"filename\": \"\",\n                    \"first_frame_id\": 0,\n                    \"pixel_scale_um\": [\n                        0.0,\n                        0.0\n                    ]\n                },\n                \"write_delay_ms\": 0.0\n            }\n        },\n        {\n            \"camera\": {\n                \"identifier\": {\n                    \"id\": [\n                        0,\n                        0\n                    ],\n                    \"kind\": \"NONE\",\n                    \"name\": \"\"\n                },\n                \"settings\": {\n                    \"binning\": 1,\n                    \"exposure_time_us\": 0.0,\n                    \"input_triggers\": {\n                        \"acquisition_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"exposure\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"frame_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        }\n                    },\n                    \"line_interval_us\": 0.0,\n                    \"offset\": [\n                        0,\n                        0\n                    ],\n                    \"output_triggers\": {\n                        \"exposure\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"frame_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"trigger_wait\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        }\n                    },\n                    \"pixel_type\": \"U16\",\n                    \"readout_direction\": \"Forward\",\n                    \"shape\": [\n                        0,\n                        0\n                    ]\n                }\n            },\n            \"frame_average_count\": 0,\n            \"max_frame_count\": 18446744073709551615,\n            \"storage\": {\n                \"identifier\": {\n                    \"id\": [\n                        0,\n                        0\n                    ],\n                    \"kind\": \"NONE\",\n                    \"name\": \"\"\n                },\n                \"settings\": {\n                    \"chunking\": {\n                        \"max_bytes_per_chunk\": 16777216,\n                        \"tile\": {\n                            \"height\": 0,\n                            \"planes\": 0,\n                            \"width\": 0\n                        }\n                    },\n                    \"enable_multiscale\": false,\n                    \"external_metadata_json\": \"\",\n                    \"filename\": \"\",\n                    \"first_frame_id\": 0,\n                    \"pixel_scale_um\": [\n                        0.0,\n                        0.0\n                    ]\n                },\n                \"write_delay_ms\": 0.0\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"props_json/#load-properties-from-a-json-file","title":"Load Properties from a JSON file","text":"<p>You can load the settings in the JSON file to a <code>Properties</code> object and set this configuration for your <code>Runtime</code> as shown below:</p> <pre><code>import acquire\nimport json\n\n# create a Runtime object\nruntime = acquire.Runtime()\n\n# Instantiate a `Properties` object from the settings in sample_props.json\nprops = acquire.Properties(**json.load(open('sample_props.json')))\n\n# save the properties for this instance of Runtime\nprops = runtime.set_configuration(props)\n</code></pre>"},{"location":"trig_json/","title":"Saving and Loading Trigger Settings from a JSON file","text":"<p>This tutorial will provide an example of saving and subsequently loading a <code>Trigger</code> object from a JSON file.</p>"},{"location":"trig_json/#initialize-runtime","title":"Initialize Runtime","text":"<p>To start, we'll import <code>Acquire</code> and create a <code>Runtime</code> object, which coordinates the streaming process.</p> <pre><code>import acquire\nruntime = acquire.Runtime()\n</code></pre>"},{"location":"trig_json/#create-a-trigger-object","title":"Create a Trigger Object","text":"<p><code>Trigger</code> objects have 4 attributes: edge, enable, line, and kind. In this example, will only adjust the edge attribute.</p> <pre><code># Instantiate a Trigger object\ntrig = acquire.Trigger()\n\n# change the edge attribute from the default Rising to Falling\ntrig.edge = acquire.TriggerEdge.Falling\n</code></pre>"},{"location":"trig_json/#save-properties-to-a-json-file","title":"Save Properties to a JSON file","text":"<p>We'll utilize the json library to write our <code>Trigger</code> to a JSON file to save for subsequent acquisition.</p> <pre><code>import json\n\n# cast the properties to a dictionary\ntrig = trig.dict()\n\n# convert the dictionary to json with \"human-readable\" formatting\ntrig = json.dumps(trig, indent=4, sort_keys=True)\n\n# save the trigger to file \"sample_trig.json\" in the current directory\nwith open(\"sample_trig.json\", \"w\") as outfile:\n    outfile.write(trig)\n</code></pre>"},{"location":"trig_json/#example-json-file","title":"Example JSON file","text":"<p>The resulting sample_trig.json file is below:</p> <pre><code>{\n    \"edge\": \"Falling\",\n    \"enable\": false,\n    \"kind\": \"Input\",\n    \"line\": 0\n}\n</code></pre>"},{"location":"trig_json/#load-properties-from-a-json-file","title":"Load Properties from a JSON file","text":"<p>You can load the trigger attributes in the JSON file to a <code>Trigger</code> object as shown below:</p> <pre><code># Instantiate a `Trigger` object from the settings in sample_trig.json\ntrig = acquire.Trigger(**json.load(open('sample_trig.json')))\n</code></pre>"},{"location":"tutorials/trigger/","title":"Finite Triggered Acquisition","text":"<p>Acquire (<code>acquire-imaging</code> on PyPI) is a Python package providing a multi-camera video streaming library focused on performant microscopy, with support for up to two simultaneous, independent, video streams.</p> <p>This tutorial shows an example of setting up triggered acquisition of a finite number of frames with one of Acquire's supported devices and saving the data to a Zarr file.</p>"},{"location":"tutorials/trigger/#initialize-acquisition","title":"Initialize Acquisition","text":"<p>To start, we'll import <code>Acquire</code> and create an acquisition <code>Runtime</code> object, which initializes the driver adaptors needed for the supported cameras.</p> <pre><code>import acquire\nruntime = acquire.Runtime()\n</code></pre>"},{"location":"tutorials/trigger/#configure-camera","title":"Configure Camera","text":"<p>All camera settings can be captured by an instance of the <code>Properties</code> class, which will be associated with a given camera acquisition. The settings can be stored in a dictionary (e.g: <code>Properties.dict()</code>). These settings can be saved to a JSON file to be subsequently loaded, (e.g. <code>Properties(**json.load('acquire.json'))</code> ), using the json library.</p> <pre><code>props = runtime.get_configuration()\n\nimport json\nwith open(\"/path/to/acquire.json\", \"w\") as f:\n    json.dump(props.dict(), f)\n</code></pre> <p>The current configuration settings can be checked and assigned to an instance of the <code>Properties</code> class with:</p> <pre><code>props = runtime.get_configuration() \n</code></pre> <p>Since <code>Acquire</code> supports 2 video streams, each camera, or source, must be configured separately. In this example, we will only use 1 source for the acquisition, so we will only need to configure <code>props.video[0]</code>. To set the first video stream to Hamamatsu Orca Fusion BT (C15440-20UP), you can use the following with a regular expression to grab the Hamamatsu camera:</p> <pre><code>props.video[0].camera.identifier = runtime.device_manager().select(acquire.DeviceKind.Camera, 'Hamamatsu C15440.*')\n</code></pre> <p>Next we'll choose the settings for the Hamamatsu camera. The <code>CameraProperties</code> class describes the available settings, which include exposure time (in microseconds), binning, pixel data type (e.g. u16), and how many frames to acquire.</p> <p>Every property can be set using the following, but in this example, we will only change a few of the available settings.</p> <pre><code>props.video[0].camera.settings.binning = 1 # no pixels will be combined\nprops.video[0].camera.settings.shape = (1700, 512) # shape of the image to be acquired in pixels\nprops.video[0].camera.settings.offset = (302, 896) # centers the image region of interest on the camera sensor\nprops.video[0].camera.settings.pixel_type = acquire.SampleType.U16 # sets the pixel data type to a 16-bit unsigned integer\nprops.video[0].max_frame_count = 10 # finite acquisition of 10 frames. Use 0 for infinite acquisition.\n</code></pre> <p>Triggers can also be set in the <code>CameraProperties</code> object. The parameters can be stored in a dictionary (e.g: <code>Trigger.dict()</code>). You can construct a <code>Trigger</code> from a JSON file (e.g. <code>acquire.Trigger(**json.loads(open('trigger.json')))</code> ), using the json library. </p> <pre><code>trig = acquire.Trigger()\n\nimport json\nwith open(\"/path/to/trigger.json\", \"w\") as f:\n    json.dump(trig.dict(), f)\n</code></pre> <p>In this example, we'll only utilize output triggers. By default, the camera's internal triggering is used, but you may explicitly disable external input triggers using:</p> <pre><code>props.video[0].camera.settings.input_triggers = acquire.InputTriggers() # default: disabled\n</code></pre> <p>Output triggers can be set to begin exposure, start a new frame, or wait before acquiring. We can enable an exposure trigger to start on the rising edge with:</p> <pre><code>props.video[0].camera.settings.output_triggers.exposure = acquire.Trigger(\n    enable=True, line=1, edge=\"Rising\"\n)\n</code></pre>"},{"location":"tutorials/trigger/#select-storage","title":"Select Storage","text":"<p><code>Storage</code> objects have identifiers which specify the file type (e.g. Zarr or tiff) and settings described by an instance of the <code>StorageProperties</code> class. We can set the file type to Zarr and set the file name to \"out\" with:</p> <pre><code>props.video[0].storage.identifier = runtime.device_manager().select(acquire.DeviceKind.Storage,'zarr') \nprops.video[0].storage.settings.filename=\"out.zarr\"\n</code></pre>"},{"location":"tutorials/trigger/#save-configuration","title":"Save configuration","text":"<p>None of these settings will be updated in the <code>Properties</code> object until you call the <code>set_configuration</code> method. This method reads what the current configuration settings are on the device.</p> <p>We'll set the configuration with:</p> <pre><code>props = runtime.set_configuration(props)\n</code></pre> <p>You can optionally print out these settings using the Rich python library to save for your records with:</p> <pre><code>from rich.pretty import pprint\npprint(props.dict())\n</code></pre>"},{"location":"tutorials/trigger/#acquire-data","title":"Acquire data","text":"<p>To begin acquisition:</p> <pre><code>runtime.start()\n</code></pre> <p>You can stop acquisition with <code>runtime.stop()</code> to stop after the specified number of frames is collected or <code>runtime.abort()</code> to immediately stop acquisition.</p>"},{"location":"tutorials/tutorials/","title":"Tutorials","text":""}]}