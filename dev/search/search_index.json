{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Acquire Zarr Streaming","text":""},{"location":"#background","title":"Background","text":"<p>Cloud-native file streaming solutions (e.g. file writers) are essential for building efficient image data acquisition workflows, especially when acquiring more data than fits into memory or a single external hard drive. Zarr is a cloud-native data format that supports imaging data and has strong early adoption within the imaging community. The Acquire project developed this standalone Zarr streaming library with interfaces in both Python and C. This library easily integrates into custom acquisition workflows since it does not rely on runtime or hardware support.</p>"},{"location":"#installation","title":"Installation","text":"<p>See our Getting Started page for installation instructions.</p>"},{"location":"#guides","title":"Guides","text":"Python API Reference <p>A detailed description of the Python API. Assumes understanding of core concepts.</p> Python API Reference C API Reference <p>A detailed description of the C API. Assumes understanding of core concepts.</p> C API Reference Examples in Python <p>Code examples demonstrating library usage</p> Python Examples Examples in C <p>Code examples demonstrating library usage</p> C Examples"},{"location":"#citing-acquire-zarr","title":"Citing <code>acquire-zarr</code>","text":"<pre><code>authors:\n- affiliation: Chan Zuckerberg Initiative (United States)\n  family-names: Liddell\n  given-names: Alan\n- affiliation: Chan Zuckerberg Initiative (United States)\n  family-names: Eskesen\n  given-names: Justin\n- affiliation: Chan Zuckerberg Initiative (United States)\n  family-names: Clack\n  given-names: Nathan\n  orcid: 0000-0001-6236-9282\ncff-version: 1.2.0\ndate-released: '2025-02-06'\ndoi: 10.5280/zenodo.14828040\nlicense:\n- apache-2.0\ntitle: 'acquire-zarr: Software for fast streaming to Zarr on the filesystem or in thecloud'\ntype: software\n</code></pre>"},{"location":"#acquire-zarr-license","title":"Acquire Zarr License","text":"<p><code>acquire-zarr</code>is provided under an Apache 2.0 license. Learn more about the Apache license.</p>"},{"location":"core_concepts/","title":"Core concepts","text":"<p>The following sections describe the core concepts and terminology used in the acquire-zarr library. See the Concepts and terminology section of the Zarr V3 specification for more details.</p> <p></p>"},{"location":"core_concepts/#zarr","title":"Zarr","text":"<p>Zarr is a specification for storing large, multi-dimensional arrays in a \"cloud-ready\" format, i.e., one which is designed to be efficient for both local and remote storage. Arrays are stored as a grid of chunks, which are (optionally) compressed blocks of data that can be accessed independently. Zarr supports multiple storage backends, including local filesystems and cloud storage services like S3. There are two major versions of the Zarr specification: V2 and V3. The acquire-zarr library implements both specifications.</p> <p>[!WARNING] The V2 specification is currently deprecated and will be removed in a future release. We recommend using V3 for new projects.</p>"},{"location":"core_concepts/#ome-zarr","title":"OME-Zarr","text":"<p>The OME-Zarr specification is an extension of the Zarr specification that adds support for additional metadata and multiscale arrays.</p>"},{"location":"core_concepts/#stream","title":"Stream","text":"<p>A stream is the primary interface for writing data to Zarr arrays in acquire-zarr. The stream manages the process of organizing incoming data into chunks and shards, applying compression, and writing to the underlying storage backend.</p> <p>[!NOTE] acquire-zarr is designed to be used in a streaming fashion, meaning you can append data to the stream incrementally. This is particularly useful for large datasets that cannot be loaded into memory all at once. This means that random-access writing, i.e., writing to arbitrary locations in the array, is not supported; neither is reading from the stream. While this is limiting in some use cases, it provides several advantages: - High throughput: acquire-zarr is optimized for high-speed data acquisition, allowing you to write large amounts of data quickly. - Low memory usage: acquire-zarr does not require loading the entire dataset into memory, making it suitable for large datasets. - Real-time data acquisition: acquire-zarr is designed for real-time data acquisition, allowing you to write data as it is generated.</p> <p>You configure a stream by specifying one or more arrays, their dimensions, and storage settings. Once created, you can append data to the stream, and acquire-zarr handles all the details of chunking, compression, and storage.</p>"},{"location":"core_concepts/#storage","title":"Storage","text":""},{"location":"core_concepts/#store","title":"Store","text":"<p>When we refer to a store, we mean a Zarr store, which is a hierarchical key-value store that can be used to store Zarr datasets. The store can be local (on disk) or remote (e.g., in cloud storage). We sometimes use this term interchangeably with \"Zarr dataset\" when the context is clear. The store contains child nodes, which can be either arrays or groups.</p>"},{"location":"core_concepts/#array","title":"Array","text":"<p>By array we mean a multi-dimensional array that can be stored as a child node in a Zarr store. Arrays can have any number of dimensions and can consist of one of several data types supported by acquire-zarr. Those data types are:</p> <ul> <li>Unsigned integral types:</li> <li><code>uint8</code></li> <li><code>uint16</code></li> <li><code>uint32</code></li> <li><code>uint64</code></li> <li>Signed integral types:</li> <li><code>int8</code></li> <li><code>int16</code></li> <li><code>int32</code></li> <li><code>int64</code></li> <li>Floating-point types:</li> <li><code>float32</code></li> <li><code>float64</code></li> </ul>"},{"location":"core_concepts/#multiscale-arrays","title":"Multiscale arrays","text":"<p>In acquire-zarr, arrays may be multiscale (see below), meaning they can store data at multiple resolutions or scales. Multiscale arrays are represented in the hierarchy as a group containing multiple arrays, each representing a different scale, e.g.,</p> <pre><code>my_array.zarr/\n    \u251c\u2500\u2500 0/\n    \u2502   \u2514\u2500\u2500 ... (data)\n    \u251c\u2500\u2500 1/\n    \u2502   \u2514\u2500\u2500 ... (data)\n    \u2514\u2500\u2500 2/\n        \u2514\u2500\u2500 ... (data)\n</code></pre> <p>An image in the array at scale 0 is the full resolution image, while at scale <code>n</code>, the image is downsampled by a factor of <code>2^n</code> in x, y, and, if applicable, z. See Dimensions below for more information.</p>"},{"location":"core_concepts/#output-key","title":"Output key","text":"<p>The output key is the path within a Zarr store where an array is located. This allows you to organize multiple arrays within a single store using a hierarchical structure. For example, you might use output keys like <code>\"sample1/brightfield\"</code> and <code>\"sample1/fluorescence\"</code> to organize different imaging modalities for the same sample, or you might additionally have a <code>\"labels\"</code> array for segmentation data.</p>"},{"location":"core_concepts/#group","title":"Group","text":"<p>A group is a node in a Zarr store that may contain other nodes, such as arrays or other groups.</p>"},{"location":"core_concepts/#s3-storage","title":"S3 storage","text":"<p>The acquire-zarr library can work with S3-compatible storage backends. When using S3, the Zarr store is represented as a hierarchy of objects in an S3 bucket. Each object corresponds to a node in the Zarr store, and the hierarchy is maintained using prefixes in the object keys.</p> <pre><code>s3://my-bucket/my_array.zarr/\n    \u251c\u2500\u2500 0/\n    \u2502   \u2514\u2500\u2500 ... (data)\n    \u251c\u2500\u2500 1/\n    \u2502   \u2514\u2500\u2500 ... (data)\n    \u2514\u2500\u2500 2/\n        \u2514\u2500\u2500 ... (data)\n</code></pre>"},{"location":"core_concepts/#dimensions-chunking-and-sharding","title":"Dimensions, chunking, and sharding","text":""},{"location":"core_concepts/#dimension","title":"Dimension","text":"<p>A dimension is a named axis of an array that can be used to organize and access the data within the array. Each dimension has a name, a type, and a size. The dimension type can be one of the following:</p> <ul> <li>Time</li> <li>Channel</li> <li>Space (e.g., x, y, z)</li> <li>Other (custom types can be defined)</li> </ul> <p>When creating a stream with acquire-zarr, you must specify at least 3 dimensions: a spatial dimension X, a spatial dimension Y, and a third dimension of any type. Apart from this constraint, you can define as many dimensions of any type as you like, though you should keep in mind that if you are targeting the OME-Zarr specification, there are some constraints on the types and order of your dimensions.</p> <p>When you configure a dimension in acquire-zarr, you must specify the following properties: - <code>name</code>: The name of the dimension (e.g., \"t\", \"c\", \"z\", \"y\", \"x\") - <code>type</code>: The type of the dimension (as above) - <code>array_size_px</code>: The size of the array in pixels for this dimension - <code>chunk_size_px</code>: The size of the chunk (see below) in pixels for this dimension - <code>shard_size_chunks</code>: The size of the shard (see below) in chunks for this dimension (Zarr V3 only)</p> <p>Dimensions are configured in order of slowest changing to fastest changing. For example, if you have a 4D array with dimensions time, channel, y, and x, you would configure the dimensions in that order.</p>"},{"location":"core_concepts/#append-dimension","title":"Append dimension","text":"<p>The append dimension is the slowest-varying dimension in the array, meaning it is the dimension that changes the least frequently as you append data to the stream. It is called the append dimension because it is the dimension that grows dynamically as you append new data to the stream, with no predetermined limit. In the example above, the append dimension is the time dimension. You can set <code>array_size_px</code> to any value for this dimension, but it will be ignored in favor of the actual size of the data you append to the stream, so it's typical to set it to 0. Append dimensions are usually time or spatial dimensions, but can be any type.</p>"},{"location":"core_concepts/#chunk","title":"Chunk","text":"<p>A chunk is a contiguous block of data within an array that is stored together. Chunks are used to optimize data access and storage efficiency, and are considered compressible units. When you stream data to an array, acquire-zarr will automatically divide the data into chunks based on the chunk size specified in the stream settings.</p> <p>When you configure a dimension in acquire-zarr, you must specify the chunk size, in pixels, for that dimension. The chunk size for a given dimension need not evenly divide the array size for that dimension. Such a dimension is said to be ragged in its chunking.</p> <p>For example, if you have an array with a size of 1080 pixels in the Y dimension and a chunk size of 256 pixels, the array will be divided into 5 chunks, 4 of which will be of size 256 pixels and the last one will be of size 1080 - 4 * 256 = 56 pixels.</p>"},{"location":"core_concepts/#shard","title":"Shard","text":"<p>A shard is a contiguous group of chunks (a superchunk, if you will) that are stored together in a single object in the Zarr store. Sharding is used to optimize data access and storage efficiency, especially for large arrays. When you stream data to an array, acquire-zarr will automatically divide the data into chunks as above, and then aggregate those chunks into shards based on the shard size specified in the stream settings.</p> <p>When you configure a dimension in acquire-zarr, you must specify the shard size, in units of chunks, for that dimension. The shard size for a given dimension need not evenly divide the number of chunks for that dimension. For example, if you have an array with 10 chunks in the Y dimension and a shard size of 3 chunks, the array will be divided into 4 shards, 3 of which will contain 3 chunks and the last one will contain 1 chunk.</p>"},{"location":"core_concepts/#compression","title":"Compression","text":"<p>Zarr supports compression of chunks to reduce storage space and improve data transfer speeds. When you stream data to an array, acquire-zarr can compress the chunks based on the compression settings specified in the stream settings. Because acquire-zarr uses Blosc for compression, it supports multiple compression codecs, including LZ4 and Zstandard. You can also specify the compression level, 0-9, where 0 means no compression and 9 means maximum compression, and the shuffle filter, which can be used to improve compression ratios for certain data types. (See this article for a discussion of the shuffle filter: New 'bitshuffle' filter.)</p>"},{"location":"core_concepts/#write-behavior","title":"Write behavior","text":"<p>The timing of when data is written to storage depends on the storage backend:</p> <ul> <li>Filesystem: Data is written when chunks are complete, allowing for efficient streaming of large datasets.</li> <li>S3: Because S3 objects cannot be appended to, data is written when entire shards are complete. This means you may need to configure larger shards when using S3 to avoid frequent uploads. However, you should take care not to make shards too large, as this can lead to inefficient storage and retrieval.</li> </ul>"},{"location":"get_started/","title":"Getting started","text":"<p>You can use <code>acquire-zarr</code> to stream data in either Python or C/C++ programs. This document provides a quick overview of how to get started with both languages.</p> <p>[!TIP] New to Zarr streaming? Check out our Core concepts page to understand the key terminology used throughout this guide.</p>"},{"location":"get_started/#getting-started-with-python","title":"Getting started with Python","text":""},{"location":"get_started/#installation","title":"Installation","text":"<p>The <code>acquire-zarr</code> Python library is supported for Python versions 3.9-3.13.</p> <p>To install the library on Windows, macOS, or Linux, run the following command, after ensuring that the <code>python</code> command points to the correct Python version you want to use:</p> <pre><code>python -m pip install acquire-zarr\n</code></pre> <p>We recommend installing <code>acquire-zarr</code> in a fresh conda environment or virtualenv. For example, to install <code>acquire-zarr</code> in a conda environment named <code>acquire</code>:</p> <pre><code>conda create -n acquire python=3.13 # or python=3.12, python=3.11, etc.\nconda activate acquire\npython -m pip install acquire-zarr\n</code></pre> <p>or with virtualenv:</p> <pre><code>$ python -m venv venv\n$ . ./venv/bin/activate # or on Windows: .\\venv\\Scripts\\Activate\n(venv) $ python -m pip install acquire-zarr\n</code></pre> <p>Now in your scripts or notebooks, import acquire-zarr with:</p> <pre><code>import acquire_zarr as aqz # or simply `import acquire_zarr`\n</code></pre>"},{"location":"get_started/#usage","title":"Usage","text":"<p>The typical workflow for acquiring data in Python is to create a stream by configuring it with the desired settings, and then to append data to the stream.</p> <p>The stream represents a Zarr dataset that can be written to. You can write data to one or more arrays in the stream, where each array corresponds to a separate subset of the data. For example, you might have a stream for a multi-camera acquisition, where each camera's data is stored in a separate array.</p> <p>Here's how you might configure a stream for a 4-dimensional acquisition (time, channel, height, width) with a single array and append data to it:</p> <pre><code>import acquire_zarr as aqz\nimport numpy as np\n\nsettings = aqz.StreamSettings(\n    store_path=\"my_stream.zarr\",\n    version=aqz.ZarrVersion.V3,\n    overwrite=True,  # this will remove any existing data at my_stream.zarr\n    arrays=[\n        aqz.ArraySettings(\n            output_key=\"array1\",\n            data_type=np.uint16,\n            dimensions = [\n                aqz.Dimension(\n                    name=\"t\",\n                    type=aqz.DimensionType.TIME,\n                    array_size_px=0,\n                    chunk_size_px=32,\n                    shard_size_chunks=10\n                ),\n                aqz.Dimension(\n                    name=\"c\",\n                    type=aqz.DimensionType.CHANNEL,\n                    array_size_px=3,\n                    chunk_size_px=1,\n                    shard_size_chunks=1\n                ),\n                aqz.Dimension(\n                    name=\"y\",\n                    type=aqz.DimensionType.SPACE,\n                    array_size_px=1080,\n                    chunk_size_px=270,\n                    shard_size_chunks=2\n                ),\n                aqz.Dimension(\n                    name=\"x\",\n                    type=aqz.DimensionType.SPACE,\n                    array_size_px=1920,\n                    chunk_size_px=480,\n                    shard_size_chunks=2\n                )\n            ]\n        )\n    ]\n)\n\n# Generate some random data: one time point, all channels, full frame\nmy_frame_data = np.random.randint(0, 2 ** 16, (3, 1080, 1920), dtype=np.uint16)\n\nstream = aqz.ZarrStream(settings)\nstream.append(my_frame_data)\n\n# ... append more data as needed ...\n\n# When done, close the stream to flush any remaining data\nstream.close()\n</code></pre> <p>When all is said and done, the data will be stored in a Zarr dataset on disk at <code>my_stream.zarr</code>, which can be read by any Zarr-compatible library. It will contain one array named <code>array1</code> with the data organized in the specified dimensions according to the chunk and shard layout you specified.</p> <p>If you instead had a multichannel acquisition with both brightfield and fluorescence channels, you could create a stream with two arrays, one for each channel type:</p> <pre><code>import acquire_zarr as aqz\nimport numpy as np\n\n# configure the stream with two arrays\nsettings = aqz.StreamSettings(\n    store_path=\"experiment.zarr\",\n    version=aqz.ZarrVersion.V3,\n    overwrite=True,  # this will remove any existing data at experiment.zarr\n    arrays=[\n        aqz.ArraySettings(\n            output_key=\"sample1/brightfield\",\n            data_type=np.uint16,\n            dimensions=[\n                aqz.Dimension(\n                    name=\"t\",\n                    type=aqz.DimensionType.TIME,\n                    array_size_px=0,\n                    chunk_size_px=100,\n                    shard_size_chunks=1\n                ),\n                aqz.Dimension(\n                    name=\"c\",\n                    type=aqz.DimensionType.CHANNEL,\n                    array_size_px=1,\n                    chunk_size_px=1,\n                    shard_size_chunks=1\n                ),\n                aqz.Dimension(\n                    name=\"y\",\n                    type=aqz.DimensionType.SPACE,\n                    array_size_px=1080,\n                    chunk_size_px=270,\n                    shard_size_chunks=2\n                ),\n                aqz.Dimension(\n                    name=\"x\",\n                    type=aqz.DimensionType.SPACE,\n                    array_size_px=1920,\n                    chunk_size_px=480,\n                    shard_size_chunks=2\n                )\n            ]\n        ),\n        aqz.ArraySettings(\n            output_key=\"sample1/fluorescence\",\n            data_type=np.uint16,\n            dimensions=[\n                aqz.Dimension(\n                    name=\"t\",\n                    type=aqz.DimensionType.TIME,\n                    array_size_px=0,\n                    chunk_size_px=100,\n                    shard_size_chunks=1\n                ),\n                aqz.Dimension(\n                    name=\"c\",\n                    type=aqz.DimensionType.CHANNEL,\n                    array_size_px=2,  # two fluorescence channels\n                    chunk_size_px=1,\n                    shard_size_chunks=1\n                ),\n                aqz.Dimension(\n                    name=\"y\",\n                    type=aqz.DimensionType.SPACE,\n                    array_size_px=1080,\n                    chunk_size_px=270,\n                    shard_size_chunks=2\n                ),\n                aqz.Dimension(\n                    name=\"x\",\n                    type=aqz.DimensionType.SPACE,\n                    array_size_px=1920,\n                    chunk_size_px=480,\n                    shard_size_chunks=2\n                )\n            ]\n        )\n    ]\n)\n\nstream = aqz.ZarrStream(settings)\n\n# ... append data ...\nbrightfield_frame_data = ... # define your brightfield frame data here\nfluorescence_frame_data = ... # define your fluorescence frame data here\n\nstream.append(brightfield_frame_data, key=\"sample1/brightfield\")\nstream.append(fluorescence_frame_data, key=\"sample1/fluorescence\")\n\n# ... append more data as needed ...\n\n# When done, close the stream to flush any remaining data\nstream.close()\n</code></pre> <p>See the API reference for more details on the available settings and methods.</p>"},{"location":"get_started/#building-the-python-library-from-source","title":"Building the Python library from source","text":"<p>If you want to contribute to acquire-zarr, or customize the installation for your own system, you'll need to be able to build the Python bindings from source. The first step is to install the system dependencies as found in the \"Installing dependencies\" section of the README.md file in the <code>acquire-zarr</code> repository. In your Python environment, you also need the following dependencies:</p> <ul> <li>cmake&lt;4.0.0</li> <li>ninja</li> <li>pybind11[global]</li> <li>setuptools</li> <li>wheel</li> </ul> <p>You can install these dependencies with:</p> <pre><code>python -m pip install cmake&lt;4.0.0 ninja pybind11[global] setuptools wheel\n</code></pre> <p>Then, clone the <code>acquire-zarr</code> repository and install acquire-zarr in your Python environment:</p> <pre><code>git clone --recursive https://github.com/acquire-project/acquire-zarr.git\ncd acquire-zarr\npython -m pip install .\n</code></pre>"},{"location":"get_started/#getting-started-with-cc","title":"Getting started with C/C++","text":""},{"location":"get_started/#install-the-library","title":"Install the library","text":"<p><code>acquire-zarr</code> provides a C API that works with both C and C++ projects. You can download the library for your system from our Releases page. The library ships with header files and precompiled binaries for Windows x86, macOS (x86 or ARM), or Linux (x86 or ARM), as well as source code examples and a sample CMakeLists.txt file.</p>"},{"location":"get_started/#usage_1","title":"Usage","text":"<p>Similarly with Python, the typical workflow for acquiring data in C is to create a stream by configuring it with the desired settings, and then to append data to the stream.</p> <p>The library provides two main structs. First, <code>ZarrStream</code>, representing an output stream to a Zarr dataset. Second, <code>ZarrStreamSettings</code> to configure a Zarr stream.</p> <p>A typical use case for a 4-dimensional acquisition in C might look like this:</p> <pre><code>#include \"acquire.zarr.h\"\n#include \"assert.h\"\n\nint main() {\n    ZarrStreamSettings settings = (ZarrStreamSettings){\n        .store_path = \"my_stream.zarr\",\n        .data_type = ZarrDataType_uint16,\n        .version = ZarrVersion_3,\n    };\n\n    ZarrStreamSettings_create_dimension_array(&amp;settings, 4);\n    settings.dimensions[0] = (ZarrDimensionProperties){\n        .name = \"t\",\n        .type = ZarrDimensionType_Time,\n        .array_size_px = 0,      // this is the append dimension\n        .chunk_size_px = 100,    // 100 time points per chunk\n        .shard_size_chunks = 10, // 10 chunks per shard\n    };\n\n    settings.dimensions[1] = (ZarrDimensionProperties){\n        .name = \"c\",\n        .type = ZarrDimensionType_Channel,\n        .array_size_px = 3,     // 3 channels\n        .chunk_size_px = 1,     // 1 channel per chunk\n        .shard_size_chunks = 1, // 1 chunk per shard\n    };\n\n    settings.dimensions[2] = (ZarrDimensionProperties){\n        .name = \"y\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 1080,  // height\n        .chunk_size_px = 270,   // 4 x 4 tiles of size 270 x 480\n        .shard_size_chunks = 2, // 2 x 2 tiles per shard\n    };\n\n    settings.dimensions[3] = (ZarrDimensionProperties){\n        .name = \"x\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 1920,  // width\n        .chunk_size_px = 480,   // 4 x 4 tiles of size 270 x 480\n        .shard_size_chunks = 2, // 2 x 2 tiles per shard\n    };\n\n    ZarrStream* stream = ZarrStream_create(&amp;settings);\n\n    size_t bytes_written;\n    ZarrStream_append(stream, my_frame_data, my_frame_size, &amp;bytes_written);\n    assert(bytes_written == my_frame_size);\n}\n</code></pre> <p>Look at acquire.zarr.h for more details.</p>"},{"location":"get_started/#building-the-library-from-source","title":"Building the library from source","text":"<p>If you want to contribute to acquire-zarr, or customize the installation for your own system, you'll need to be able to build the library from source. The first step is to install the system dependencies as found in the \"Installing dependencies\" section of the README.md file in the <code>acquire-zarr</code> repository. As in the README, we recommend using vcpkg to install them. You will also need CMake to build the library.</p> <p>Once you have built the library, try running the tests to ensure everything is working correctly.</p> <pre><code>cd build # or wherever you built the library\nctest -C ${BUILD_TYPE} -L acquire-zarr --output-on-failure\n</code></pre> <p>where <code>${BUILD_TYPE}</code> can be <code>Debug</code>, <code>Release</code>, or <code>RelWithDebInfo</code>, depending on how you built the library. (If you did not specify a build type, it defaults to <code>Debug</code>.)</p> <p>If the tests pass, you can install the library to your system with:</p> <pre><code>cmake --install . --config ${BUILD_TYPE}\n</code></pre>"},{"location":"acquire-imaging/","title":"Acquire Docs","text":""},{"location":"acquire-imaging/#guides","title":"Guides","text":"Get Started <p>Install Acquire and use simulated cameras</p> Get Started API Reference <p>Information on classes and methods</p> API Reference Tutorials <p>Guides on using Acquire for specific tasks</p> Tutorials For contributors <p>Learn how to contribute code or documentation to Acquire</p> For contributors"},{"location":"acquire-imaging/#about-acquire","title":"About Acquire","text":"<p>Acquire (<code>acquire-imaging</code> on PyPI) provides high-speed, multi-camera, video streaming and image acquisition with a programming interface for streaming video data directly to napari, Python and cloud-friendly file formats.</p>"},{"location":"acquire-imaging/#installation","title":"Installation","text":"<p>To install Acquire on Windows, macOS, or Ubuntu, simply run the following command:</p> <pre><code>python -m pip install acquire-imaging\n</code></pre>"},{"location":"acquire-imaging/#supported-cameras-and-file-formats","title":"Supported Cameras and File Formats","text":"<p>Acquire supports the following cameras (currently only on Windows):</p> <ul> <li>Hamamatsu Orca Fusion BT (C15440-20UP)</li> <li>Vieworks VC-151MX-M6H00</li> <li>FLIR Blackfly USB3 (BFLY-U3-23S6M-C)</li> <li>FLIR Oryx 10GigE (ORX-10GS-51S5M-C)</li> </ul> <p>For testing and demonstration purposes, Acquire also provides a few simulated video sources. For more information on supported cameras and video sources, check out this tutorial.</p> <p>Acquire supports the following output file formats:</p> <ul> <li>Tiff</li> <li>OME-Zarr for Zarr v2</li> <li>Zarr v3</li> </ul> <p>Acquire also supports raw and trash storage devices. For more information on supported file formats and storage devices, check out the Storage Device Selection tutorial.</p>"},{"location":"acquire-imaging/#citing-acquire","title":"Citing Acquire","text":"<pre><code>cff-version: 1.2.0\ntitle: Acquire: a multi-camera video streaming software focusing on microscopy\nmessage: &gt;-\n  If you use this software, please cite it using the\n  metadata from this file.\ntype: software\nauthors:\n  - given-names: Nathan\n    family-names: Clack\n    email: nclack@chanzuckerberg.com\n    affiliation: Chan-Zuckerberg Initiative Foundation\n    orcid: 'https://orcid.org/0000-0001-6236-9282'\n  - given-names: Alan\n    family-names: Liddell\n    email: aliddell@chanzuckerberg.com\n    affiliation: Chan-Zuckerberg Initiative Foundation\n  - given-names: Andrew\n    family-names: Sweet\n    email: andrewdsweet@gmail.com\n    affiliation: Chan-Zuckerberg Initiative Foundation\nrepository-code: 'https://github.com/acquire-project/acquire-python'\nrepository-artifact: 'https://pypi.org/project/acquire-imaging/'\nabstract: &gt;-\n  acquire-imaging is a library focusing on multi-camera video\n  streaming for microscopy.\nlicense: Apache-2.0\n</code></pre>"},{"location":"acquire-imaging/#acquire-license","title":"Acquire License","text":"<p><code>Acquire</code> is provided under an Apache 2.0 license. Learn more about the Apache license.</p>"},{"location":"acquire-imaging/api_reference/","title":"API Reference","text":"<p>Information on the classes in the <code>acquire-imaging</code> package along with the attributes and methods associated with them.</p>"},{"location":"acquire-imaging/api_reference/#acquire.AvailableData","title":"<code>acquire.AvailableData</code>","text":"<p>The AvailableData class represents the collection of frames that have been captured since the last call to <code>runtime.get_available_data()</code>.</p> <p><code>AvailableData</code> objects should be set to have a short lifetime, since these objects reserve space on the video queue and will eventually block camera acquisition to ensure no data is overwritten before it can be processed.</p> <p>Methods:</p> Name Description <code>frames</code> <p>Returns an iterator over the video frames in the available data.</p> <code>get_frame_count</code> <p>Returns the total number of video frames in the available data.</p>"},{"location":"acquire-imaging/api_reference/#acquire.AvailableData.frames","title":"<code>frames() -&gt; Iterator[VideoFrame]</code>","text":"<p>Returns an iterator over the video frames in the available data.</p> <p>Returns:</p> Type Description <code>Iterator[VideoFrame]</code> <p>An iterator over the video frames in the available data.</p>"},{"location":"acquire-imaging/api_reference/#acquire.AvailableData.get_frame_count","title":"<code>get_frame_count() -&gt; int</code>","text":"<p>Returns the total number of video frames in the available data.</p> <p>Call <code>get_frame_count()</code> to query the number of frames in a <code>AvailableData</code> object.</p> <p>Returns:</p> Type Description <code>int</code> <p>The total number of video frames in the AvailableData object.</p>"},{"location":"acquire-imaging/api_reference/#acquire.AvailableDataContext","title":"<code>acquire.AvailableDataContext</code>","text":"<p>The <code>AvailableDataContext</code> class is the context manager for available data for the given VideoStream ID.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Camera","title":"<code>acquire.Camera</code>","text":"<p>The <code>Camera</code> class is used to describe cameras or other video sources.</p> <p>Attributes:</p> Name Type Description <code>identifier</code> <code>Optional[DeviceIdentifier]</code> <p>An optional attribute which contains an instance of the <code>DeviceIdentifier</code> class. <code>DeviceIdentifier</code> has <code>id</code> and <code>kind</code> attributes assigned by <code>acquire</code> if the device is natively supported. Otherwise, it is of type <code>None</code>.</p> <code>settings</code> <code>CameraProperties</code> <p>An instance of the <code>CameraProperties</code> class which contains the settings for the camera.</p>"},{"location":"acquire-imaging/api_reference/#acquire.CameraCapabilities","title":"<code>acquire.CameraCapabilities</code>","text":"<p>The <code>CameraCapabilities</code> class is used to describe the camera's supported properties.</p> <p>Attributes:</p> Name Type Description <code>exposure_time_us</code> <code>Property</code> <p>An instance of the <code>Property</code> class that captures the range and type of supported values in microseconds for the camera's exposure time, which is how long in microseconds the camera collects light from the sample for a single frame.</p> <code>line_interval_us</code> <code>Property</code> <p>An instance of the <code>Property</code> class that captures the range and type of supported values in microseconds for a rolling shutter camera to scan one line.</p> <code>readout_direction</code> <code>Property</code> <p>An instance of the <code>Property</code> class that specifies whether the data is read out of the camera forwards or backwards and if that direction can be chosen by the user.</p> <code>binning</code> <code>Property</code> <p>An instance of the <code>Property</code> class that captures the range and type of support values for binning, which is combining adjacent pixels by averaging in each direction, and whether the binning factor can be chosen by the user.</p> <code>offset</code> <code>OffsetCapabilities</code> <p>An instance of the <code>OffsetShapeCapabilities</code> class that represents the horizontal and vertical offset for the region of interest on the camera chip.</p> <code>shape</code> <code>ShapeCapabilities</code> <p>An instance of the <code>OffsetShapeCapabilities</code> class that represents the width and height of the region of interest on the camera chip.</p> <code>supported_pixel_types</code> <code>List[SampleType]</code> <p>A list containing instances of the <code>SampleType</code> class representing each of the supported pixel types, such as 8-bit unsigned integer (uint8).</p> <code>digital_lines</code> <code>DigitalLineCapabilities</code> <p>An instance of the <code>DigitalLineCapabilities</code> class which indicates the number and names of the available lines. Up to 8 lines are supported with the last line typically being the camera software trigger.</p> <code>triggers</code> <code>TriggerCapabilities</code> <p>An instance of the <code>TriggerCapabilities</code> class which indicate what kinds of triggers (start acquisition, start exposure, or start a frame) are supported.</p>"},{"location":"acquire-imaging/api_reference/#acquire.CameraProperties","title":"<code>acquire.CameraProperties</code>","text":"<p>The <code>CameraProperties</code> class is used to set the desired camera properties for acquisition.</p> <p>Attributes:</p> Name Type Description <code>exposure_time_us</code> <code>float</code> <p>How long in microseconds your camera should collect light from the sample. However, for simulated cameras, this is just a waiting period before generating the next frame.</p> <code>line_interval_us</code> <code>float</code> <p>The time to scan one line in microseconds in a rolling shutter camera.</p> <code>binning</code> <code>float</code> <p>How many adjacent pixels in each direction to combine by averaging. For example, if <code>binning</code> is set to 2, a 2x2 square of pixels will be combined by averaging. If <code>binning</code> is set to 1, no pixels will be combined.</p> <code>pixel_type</code> <code>SampleType</code> <p>An instance of the <code>SampleType</code> class which specifies the numerical data type, for example Uint16, a 16-bit unsigned integer type.</p> <code>readout_direction</code> <code>Direction</code> <p>An instance of the <code>Direction</code> class which specifies whether the data is readout forwards or backwards.</p> <code>offset</code> <code>Tuple[int, int]</code> <p>A tuple of two integers representing the (x, y) offset in pixels of the image region of interest on the camera.</p> <code>shape</code> <code>Tuple[int, int]</code> <p>A tuple of two integers representing the (x, y)size in pixels of the image region of interest on the camera.</p> <code>input_triggers</code> <code>InputTriggers</code> <p>An instance of the <code>InputTriggers</code> class, which describes the trigger signals for starting acquisition, camera exposure, and acquiring a frame.</p> <code>output_triggers</code> <code>OutputTriggers</code> <p>An instance of the <code>OutputTriggers</code> class, which describes the trigger signals for the camera exposure, acquiring a frame, as well as any wait times for sending the trigger signal.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Capabilities","title":"<code>acquire.Capabilities</code>","text":"<p>The <code>Capabilities</code> class contains representations of each of the 2 supported VideoStream objects.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Tuple[VideoStreamCapabilities, VideoStreamCapabilities]</code> <p>A tuple containing two <code>VideoStreamCapabilities</code> instances since <code>acquire</code> supports simultaneous streaming from 2 video sources.</p>"},{"location":"acquire-imaging/api_reference/#acquire.DeviceIdentifier","title":"<code>acquire.DeviceIdentifier</code>","text":"<p>Represents an identifier for a supported device, including its unique id and type, such as a camera or storage.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>Tuple[int, int]</code> <p>A tuple of <code>(driver_id, device_id)</code> containing two Uint8 integers that serve to identify each driver and device uniquely for a given run.</p> <code>kind</code> <code>DeviceKind</code> <p>An instance of the <code>DeviceKind</code> class that represents the type or kind of the device.</p> <code>name</code> <code>str</code> <p>A string representing the name or label of the device.</p> <p>Methods:</p> Name Description <code>none</code> <p>Returns a \"None\" type DeviceIdentifier.</p>"},{"location":"acquire-imaging/api_reference/#acquire.DeviceIdentifier.none","title":"<code>none() -&gt; DeviceIdentifier</code>","text":"<p>Returns a \"None\" type DeviceIdentifier.</p> <p>Useful when a DeviceIdentifier is not needed.</p>"},{"location":"acquire-imaging/api_reference/#acquire.DeviceKind","title":"<code>acquire.DeviceKind</code>","text":"<p>This class represents the types of devices in a given system.</p> <p>Attributes:</p> Name Type Description <code>Camera</code> <code>DeviceKind</code> <p>Enum-type class variable of <code>DeviceKind</code> that specifies a device is a camera.</p> <code>NONE</code> <code>DeviceKind</code> <p>Enum-type class variable of <code>DeviceKind</code> for if a device's kind is unavailable.</p> <code>Signals</code> <code>DeviceKind</code> <p>Enum-type class variable of <code>DeviceKind</code> that specifies a device is a signal.</p> <code>StageAxis</code> <code>DeviceKind</code> <p>Enum-type class variable of <code>DeviceKind</code> that specifies a device is a stage.</p> <code>Storage</code> <code>DeviceKind</code> <p>Enum-type class variable of <code>DeviceKind</code> that specifies a device is for storage.</p>"},{"location":"acquire-imaging/api_reference/#acquire.DeviceManager","title":"<code>acquire.DeviceManager</code>","text":"<p>The <code>DeviceManager</code> class manages selection of available devices in the system.</p> <p>Regular expressions are accepted for the name argument.</p> <p>Methods:</p> Name Description <code>devices</code> <p>Returns a list of all available device identifiers.</p> <code>select</code> <p>Selects a specified device.</p> <code>select_one_of</code> <p>Selects the first device in the list of devices that is of one of</p>"},{"location":"acquire-imaging/api_reference/#acquire.DeviceManager.devices","title":"<code>devices() -&gt; List[DeviceIdentifier]</code>","text":"<p>Returns a list of all available device identifiers.</p>"},{"location":"acquire-imaging/api_reference/#acquire.DeviceManager.select","title":"<code>select(kind: DeviceKind, name: Optional[str] = None) -&gt; Optional[DeviceIdentifier]</code>","text":"<p>Selects a specified device.</p> <p>Call this method to choose the first available device of a given type or to select a specific device by name.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>DeviceKind</code> <p>The type of device to select.</p> required <code>name</code> <code>Optional[str]</code> <p>The name of the device to select. Regular expressions supported.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[DeviceIdentifier]</code> <p>The selected device identifier, or None if the specified device is</p> <code>Optional[DeviceIdentifier]</code> <p>not available.</p>"},{"location":"acquire-imaging/api_reference/#acquire.DeviceManager.select_one_of","title":"<code>select_one_of(kind: DeviceKind, names: List[str]) -&gt; Optional[DeviceIdentifier]</code>","text":"<p>Selects the first device in the list of devices that is of one of the specified kinds.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>DeviceKind</code> <p>The type of device to select.</p> required <code>names</code> <code>List[str]</code> <p>A list of device names to choose from. Regular expressions supported.</p> required <p>Returns:</p> Type Description <code>Optional[DeviceIdentifier]</code> <p>Optional[DeviceIdentifier]: The selected device identifier, or None</p> <code>Optional[DeviceIdentifier]</code> <p>if none of the specified devices are available.</p>"},{"location":"acquire-imaging/api_reference/#acquire.DeviceState","title":"<code>acquire.DeviceState</code>","text":"<p>The <code>DeviceState</code> class represents the acquisition status of a device.</p> <p>Attributes:</p> Name Type Description <code>Closed</code> <code>DeviceState</code> <p>Enum-type class variable of <code>DeviceState</code> that specifies when a device is not ready for configuration.</p> <code>AwaitingConfiguration</code> <code>DeviceState</code> <p>Enum-type class variable of <code>DeviceState</code> that specifies when a device is ready for configuration.</p> <code>Armed</code> <code>DeviceState</code> <p>Enum-type class variable of <code>DeviceState</code> that specifies when a device is ready to stream data.</p> <code>Running</code> <code>DeviceState</code> <p>Enum-type class variable of <code>DeviceState</code> that specifies when a device is streaming data.</p>"},{"location":"acquire-imaging/api_reference/#acquire.DigitalLineCapabilities","title":"<code>acquire.DigitalLineCapabilities</code>","text":"<p>The <code>DigitalLineCapabilities</code> class represents the digital lines supported by the device.</p> <p>Attributes:</p> Name Type Description <code>line_count</code> <code>int</code> <p>Integer number representing the number of digital lines supported.</p> <code>names</code> <code>Tuple[str, ...]</code> <p>Tuple of strings to name each of the digital lines, typically the last one is the camera software trigger.</p>"},{"location":"acquire-imaging/api_reference/#acquire.DimensionType","title":"<code>acquire.DimensionType</code>","text":"<p>Used to specify the physical meaning of a dimension, such as space or time dimension.</p> <p>When downsampling, Space and Time dimensions are downsampled by the same factor. Channel and Other dimensions are not downsampled.</p> <p>This value is also reflected in the dimension metadata of an OME-Zarr dataset.</p> <p>Attributes:</p> Name Type Description <code>Space</code> <code>DimensionType</code> <p>Enum-type class variable of <code>DimensionType</code> that indicates a spatial dimension.</p> <code>Channel</code> <code>DimensionType</code> <p>Enum-type class variable of <code>DimensionType</code> that indicates a color channel dimension.</p> <code>Time</code> <code>DimensionType</code> <p>Enum-type class variable of <code>DimensionType</code> that indicates a time dimension.</p> <code>Other</code> <code>DimensionType</code> <p>Enum-type class variable of <code>DimensionType</code> that indicates the dimension is not a space, channel, or time.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Direction","title":"<code>acquire.Direction</code>","text":"<p>The direction that data is read for streaming.</p> <p>Attributes:</p> Name Type Description <code>Backward</code> <code>Direction</code> <p>Enum-type class variable of <code>Direction</code> that specifies when data is streamed backward.</p> <code>Forward</code> <code>Direction</code> <p>Enum-type class variable of <code>Direction</code> that specifies when data is streamed forward.</p>"},{"location":"acquire-imaging/api_reference/#acquire.InputTriggers","title":"<code>acquire.InputTriggers</code>","text":"<p>The <code>InputTriggers</code> class represents input triggers for a camera device.</p> <p>Attributes:</p> Name Type Description <code>acquisition_start</code> <code>Trigger</code> <p>An instance of the <code>Trigger</code> class representing the trigger for starting acquisition.</p> <code>exposure</code> <code>Trigger</code> <p>An instance of the <code>Trigger</code> class representing the trigger for exposure.</p> <code>frame_start</code> <code>Trigger</code> <p>An instance of the <code>Trigger</code> class representing the trigger for starting a frame.</p>"},{"location":"acquire-imaging/api_reference/#acquire.OffsetCapabilities","title":"<code>acquire.OffsetCapabilities</code>","text":""},{"location":"acquire-imaging/api_reference/#acquire.OutputTriggers","title":"<code>acquire.OutputTriggers</code>","text":"<p>The <code>OutputTriggers</code> class represents output triggers for a camera device.</p> <p>Attributes:</p> Name Type Description <code>exposure</code> <code>Trigger</code> <p>An instance of the <code>Trigger</code> class representing the trigger for exposure.</p> <code>frame_start</code> <code>Trigger</code> <p>An instance of the <code>Trigger</code> class representing the trigger for starting a frame.</p> <code>trigger_wait</code> <code>Trigger</code> <p>An instance of the <code>Trigger</code> class representing the trigger for waiting before continuing acquisition.</p>"},{"location":"acquire-imaging/api_reference/#acquire.PID","title":"<code>acquire.PID</code>","text":"<p>The <code>PID</code> class represents proportional-integral-derivative (PID) values.</p> <p>Attributes:</p> Name Type Description <code>derivative</code> <code>float</code> <p>The derivative value for the PID.</p> <code>integral</code> <code>float</code> <p>The integral value for the PID.</p> <code>proportional</code> <code>float</code> <p>The proportional value for the PID.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Properties","title":"<code>acquire.Properties</code>","text":"<p>The <code>Properties</code> class represents properties related to video streams.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Tuple[VideoStream, VideoStream]</code> <p>A tuple containing two <code>VideoStream</code> instances since <code>acquire</code> supports simultaneous streaming from 2 video sources. <code>VideoStream</code> objects have 2 attributes <code>camera</code> and <code>storage</code> to set the source and sink for the stream.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Property","title":"<code>acquire.Property</code>","text":"<p>Indicates the type of and whether the property can be overwritten.</p> <p>For numerical values, it also captures the accepted range of values.</p> <p>Attributes:</p> Name Type Description <code>writable</code> <code>bool</code> <p>A boolean indicating whether the property can be written.</p> <code>low</code> <code>float</code> <p>Floating point number for the lower bound of the property, if applicable.</p> <code>high</code> <code>float</code> <p>Floating point number for the upper bound of the property, if applicable.</p> <code>kind</code> <code>PropertyType</code> <p>An instance of the <code>PropertyType</code> class which indicates the type of the property (fixed precision, floating-point, enum, or string).</p>"},{"location":"acquire-imaging/api_reference/#acquire.PropertyType","title":"<code>acquire.PropertyType</code>","text":"<p>The <code>PropertyType</code> class indicates the type of the property (fixed precision, floating-point, enum, or string).</p> <p>Attributes:</p> Name Type Description <code>FixedPrecision</code> <code>PropertyType</code> <p>Enum-type class variable of <code>PropertyType</code> that indicates fixed precision or integer values.</p> <code>FloatingPrecision</code> <code>PropertyType</code> <p>Enum-type class variable of <code>PropertyType</code> that indicates floating point precision values.</p> <code>Enum</code> <code>PropertyType</code> <p>Enum-type class variable of <code>PropertyType</code> that indicates enum-type values.</p> <code>String</code> <code>PropertyType</code> <p>Enum-type class variable of <code>PropertyType</code> that indicates string values.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime","title":"<code>acquire.Runtime</code>","text":"<p>Coordinates runtime.</p> <p>The <code>Runtime</code> class coordinates the devices with the storage disc including selecting the devices, setting their properties, and starting and stopping acquisition.</p> <p>Methods:</p> Name Description <code>abort</code> <p>Aborts the runtime, terminating it immediately.</p> <code>device_manager</code> <p>Returns the DeviceManager instance associated with this Runtime.</p> <code>execute_trigger</code> <p>Executes a trigger for the given stream ID.</p> <code>get_available_data</code> <p>Returns the AvailableDataContext instance for the given stream ID.</p> <code>get_capabilities</code> <p>Returns the current capabilites of the runtime as an instance of</p> <code>get_configuration</code> <p>Returns the current configuration properties of the runtime.</p> <code>get_state</code> <p>Returns the current state of the device.</p> <code>set_configuration</code> <p>Applies the provided configuration properties to the runtime.</p> <code>start</code> <p>Starts the runtime, allowing it to collect data.</p> <code>stop</code> <p>Stops the runtime, ending data collection after the max number of</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime.abort","title":"<code>abort() -&gt; None</code>","text":"<p>Aborts the runtime, terminating it immediately.</p> <p>Call <code>abort()</code> to immediately end data acqusition. All objects are deleted to free up disk space upon shutdown of <code>Runtime</code>.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime.device_manager","title":"<code>device_manager() -&gt; DeviceManager</code>","text":"<p>Returns the DeviceManager instance associated with this Runtime.</p> <p>Call <code>device_manager()</code> to return the <code>DeviceManager</code> object associated with this <code>Runtime</code> instance.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime.execute_trigger","title":"<code>execute_trigger(stream_id: int) -&gt; None</code>","text":"<p>Executes a trigger for the given stream ID.</p> <p>Call <code>execute_trigger</code> with a specific <code>stream_id</code>, 0 or 1, to execute a trigger for that video source.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime.get_available_data","title":"<code>get_available_data(stream_id: int) -&gt; AvailableDataContext</code>","text":"<p>Returns the AvailableDataContext instance for the given stream ID.</p> <p>Call <code>get_available_data</code> with a specific <code>stream_id</code>, 0 or 1, to return the context manager, <code>AvailableDataContext</code>, associated with the 1st or 2nd video source, respectively.</p> <p>Parameters:</p> Name Type Description Default <code>stream_id</code> <code>int</code> <p>The ID of the stream for which available data is requested.</p> required <p>Returns:</p> Name Type Description <code>AvailableDataContext</code> <code>AvailableDataContext</code> <p>Context manager for available data for the given VideoStream ID.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime.get_capabilities","title":"<code>get_capabilities() -&gt; Capabilities</code>","text":"<p>Returns the current capabilites of the runtime as an instance of Capabilities.</p> <p>Call <code>get_capabilities()</code> to return the <code>Capabilities</code> object associated with this <code>Runtime</code> instance.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime.get_configuration","title":"<code>get_configuration() -&gt; Properties</code>","text":"<p>Returns the current configuration properties of the runtime.</p> <p>Call <code>get_configuration()</code> to return the <code>Properties</code> object associated with this <code>Runtime</code> instance.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime.get_state","title":"<code>get_state() -&gt; DeviceState</code>","text":"<p>Returns the current state of the device.</p> <p>Call <code>get_state()</code> to return the <code>DeviceState</code> object associated with this <code>Runtime</code> instance.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime.set_configuration","title":"<code>set_configuration(properties: Properties) -&gt; Properties</code>","text":"<p>Applies the provided configuration properties to the runtime.</p> <p>Call <code>set_configuration</code> with a <code>Properties</code> object to change the properties of this <code>Runtime</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>properties</code> <code>Properties</code> <p>The properties to be set.</p> required <p>Returns:</p> Type Description <code>Properties</code> <p>The updated configuration properties.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime.start","title":"<code>start() -&gt; None</code>","text":"<p>Starts the runtime, allowing it to collect data.</p> <p>Call <code>start()</code> to begin data acquisition.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Runtime.stop","title":"<code>stop() -&gt; None</code>","text":"<p>Stops the runtime, ending data collection after the max number of frames is collected.</p> <p>Call <code>stop()</code> to end data acquisition once the max number of frames specified in <code>acquire.VideoStream.max_frame_count</code> is collected. All objects are deleted to free up disk space upon shutdown of <code>Runtime</code>.</p>"},{"location":"acquire-imaging/api_reference/#acquire.SampleRateHz","title":"<code>acquire.SampleRateHz</code>","text":"<p>The <code>SampleRateHz</code> class represents the sampling rate in hertz.</p> <p>Attributes:</p> Name Type Description <code>numerator</code> <code>int</code> <p>The numerator part of the sampling rate fraction.</p> <code>denominator</code> <code>int</code> <p>The denominator part of the sampling rate fraction.</p>"},{"location":"acquire-imaging/api_reference/#acquire.SampleType","title":"<code>acquire.SampleType</code>","text":"<p>The <code>SampleType</code> class defines the type of the values in the streamed data.</p> <p>Attributes:</p> Name Type Description <code>F32</code> <code>SampleType</code> <p>Enum-type class variable of <code>SampleType</code> that specifies values of 32-bit floating point type.</p> <code>I16</code> <code>SampleType</code> <p>Enum-type class variable of <code>SampleType</code> that specifies values of 16-bit signed integer type.</p> <code>I8</code> <code>SampleType</code> <p>Enum-type class variable of <code>SampleType</code> that specifies values of 8-bit signed integer type.</p> <code>U16</code> <code>SampleType</code> <p>Enum-type class variable of <code>SampleType</code> that specifies values of 16-bit unsigned integer type.</p> <code>U8</code> <code>SampleType</code> <p>Enum-type class variable of <code>SampleType</code> that specifies values of 8-bit unsigned integer type.</p> <code>U10</code> <code>SampleType</code> <p>Enum-type class variable of <code>SampleType</code> that specifies values of 10-bit unsigned integer type.</p> <code>U12</code> <code>SampleType</code> <p>Enum-type class variable of <code>SampleType</code> that specifies values of 12-bit unsigned integer type.</p> <code>U14</code> <code>SampleType</code> <p>Enum-type class variable of <code>SampleType</code> that specifies values of 14-bit unsigned integer type.</p>"},{"location":"acquire-imaging/api_reference/#acquire.ShapeCapabilities","title":"<code>acquire.ShapeCapabilities</code>","text":"<p>Represents the size of the offset or the shape of the region of interest on the camera.</p> <p>The sum of the offset and shape is the size of the full camera chip.</p> <p>Attributes:</p> Name Type Description <code>x</code> <code>Property</code> <p>An instance of the <code>Property</code> class which represents the width of the region of interest on the camera or the horizontal offset of the region of interest on the camera chip.</p> <code>y</code> <code>Property</code> <p>An instance of the <code>Property</code> class which represents the height of the region of interest on the camera or the vertical offset of the region of interest on the camera chip.</p>"},{"location":"acquire-imaging/api_reference/#acquire.SignalIOKind","title":"<code>acquire.SignalIOKind</code>","text":"<p>The <code>SignalIOKind</code> class defines the signal type, input or output, for a trigger.</p> <p>Attributes:</p> Name Type Description <code>Input</code> <code>SignalIOKind</code> <p>Enum-type class variable of <code>SignalIOKind</code> that specifies signal coming in to the device.</p> <code>Output</code> <code>SignalIOKind</code> <p>Enum-type class variable of <code>SignalIOKind</code> that specifies signal sent out of the device.</p>"},{"location":"acquire-imaging/api_reference/#acquire.SignalType","title":"<code>acquire.SignalType</code>","text":"<p>The <code>SignalType</code> class specifies whether a signal is analog or digital.</p> <p>Attributes:</p> Name Type Description <code>Analog</code> <code>SignalType</code> <p>Enum-type class variable of <code>SignalType</code> that specifies a signal is analog.</p> <code>Digital</code> <code>SignalType</code> <p>Enum-type class variable of <code>SignalType</code> that specifies a signal is digital.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Storage","title":"<code>acquire.Storage</code>","text":"<p>The <code>Storage</code> class represents storage devices and their settings.</p> <p>Attributes:</p> Name Type Description <code>identifier</code> <code>Optional[DeviceIdentifier]</code> <p>An optional attribute which contains an instance of the <code>DeviceIdentifier</code> class that describes the storage device if that device is natively supported. Otherwise, it is of type <code>None</code>.</p> <code>settings</code> <code>StorageProperties</code> <p>An instance of the <code>StorageProperties</code> class which contains the settings for the data storage.</p>"},{"location":"acquire-imaging/api_reference/#acquire.StorageCapabilities","title":"<code>acquire.StorageCapabilities</code>","text":"<p>The <code>StorageCapabilities</code> class represents what types of data handling is supported by the storage device.</p> <p>Attributes:</p> Name Type Description <code>chunking_is_supported</code> <code>bool</code> <p>A boolean indicating whether chunking is supported for this storage device.</p> <code>sharding_is_supported</code> <code>bool</code> <p>A boolean indicating whether sharding is supported for this storage device.</p> <code>multiscale_is_supported</code> <code>bool</code> <p>A boolean indicating whether multiscale storage is supported.</p>"},{"location":"acquire-imaging/api_reference/#acquire.StorageDimension","title":"<code>acquire.StorageDimension</code>","text":"<p>Represents the type and size of the dimension for storage.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>A string representing the name or label of the storage dimension.</p> <code>kind</code> <code>DimensionType</code> <p>An instance of the <code>DimensionType</code> specifying if the storage dimension is space, channel, time, or a different physical dimension</p> <code>array_size_px</code> <code>int</code> <p>The size of the output array along this dimension, in pixels. The final (i.e., append) dimension must have size 0.</p> <code>chunk_size_px</code> <code>int</code> <p>The size of a chunk along this dimension, in pixels.</p> <code>shard_size_chunks</code> <code>int</code> <p>Integer number of chunks per shard. Shards enable aggregating multiple chunks into a single file. This value is ignored if sharding is not supported by the storage device.</p>"},{"location":"acquire-imaging/api_reference/#acquire.StorageProperties","title":"<code>acquire.StorageProperties</code>","text":"<p>The <code>StorageProperties</code> class represents properties for data storage.</p> <p>Attributes:</p> Name Type Description <code>uri</code> <code>Optional[str]</code> <p>The URI where the image data will be stored.</p> <code>external_metadata_json</code> <code>Optional[str]</code> <p>Optional JSON-formatted metadata for the acquisition.</p> <code>s3_access_key_id</code> <code>Optional[str]</code> <p>The access key ID for the S3 bucket. This value is only applicable for Zarr storage devices and S3 URIs.</p> <code>s3_secret_access_key</code> <code>Optional[str]</code> <p>The secret access key for the S3 bucket. This value is only applicable for Zarr storage devices and S3 URIs.</p> <code>first_frame_id</code> <code>int</code> <p>The ID of the first frame.</p> <code>pixel_scale_um</code> <code>Tuple[float, float]</code> <p>A tuple of two floats representing the pixel size of the camera in micrometers.</p> <code>acquisition_dimensions</code> <code>List[StorageDimension]</code> <p>A list of instances of the <code>StorageDimension</code> class, one for each acquisition dimension. The fastest changing dimension should be first in the list and the append dimension should be last. This value is only applicable for Zarr storage devices.</p> <code>enable_multiscale</code> <code>bool</code> <p>A boolean indicating whether multiscale storage is enabled.</p>"},{"location":"acquire-imaging/api_reference/#acquire.Trigger","title":"<code>acquire.Trigger</code>","text":"<p>The <code>Trigger</code> class represents a trigger signal.</p> <p>Attributes:</p> Name Type Description <code>edge</code> <code>TriggerEdge</code> <p>An instance of the <code>TriggerEdge</code> class specifying if the trigger is on the rising or falling edge trigger signal.</p> <code>enable</code> <code>bool</code> <p>A boolean indicating whether the trigger is enabled.</p> <code>line</code> <code>int</code> <p>An integer representing the max value of the trigger signal.</p> <code>kind</code> <code>SignalIOKind</code> <p>An instance of the <code>SignalIOKind</code> class specifying if the signal is input or output.</p>"},{"location":"acquire-imaging/api_reference/#acquire.TriggerCapabilities","title":"<code>acquire.TriggerCapabilities</code>","text":"<p>Specifies what types of events the trigger can initiate.</p> <p>Attributes:</p> Name Type Description <code>acquisition_start</code> <code>TriggerInputOutputCapabilities</code> <p>An instance of the <code>TriggerInputOutputCapabilities</code> class indicating which lines, either input or output, are supported for starting acquisition.</p> <code>exposure</code> <code>TriggerInputOutputCapabilities</code> <p>An instance of the <code>TriggerInputOutputCapabilities</code> class indicating which lines, either input or output, are supported for starting exposure.</p> <code>frame_start</code> <code>TriggerInputOutputCapabilities</code> <p>An instance of the <code>TriggerInputOutputCapabilities</code> class indicating which lines, either input or output, are supported for starting a frame.</p>"},{"location":"acquire-imaging/api_reference/#acquire.TriggerEdge","title":"<code>acquire.TriggerEdge</code>","text":"<p>The <code>TriggerEdge</code> class represents what edge of the trigger function initiates the trigger.</p> <p>Attributes:</p> Name Type Description <code>Falling</code> <code>TriggerEdge</code> <p>Enum-type class variable of <code>TriggerEdge</code> that defines the falling edge of the trigger.</p> <code>NotApplicable</code> <code>TriggerEdge</code> <p>Enum-type class variable of <code>TriggerEdge</code> that defines if a trigger does not have a rising or falling edge.</p> <code>Rising</code> <code>TriggerEdge</code> <p>Enum-type class variable of <code>TriggerEdge</code> that defines the rising edge of the trigger.</p> <code>AnyEdge</code> <code>TriggerEdge</code> <p>Enum-type class variable of <code>TriggerEdge</code> that defines any edge of the trigger.</p> <code>LevelLow</code> <code>TriggerEdge</code> <p>Enum-type class variable of <code>TriggerEdge</code> that defines the low level of the trigger.</p> <code>LevelHigh</code> <code>TriggerEdge</code> <p>Enum-type class variable of <code>TriggerEdge</code> that defines the high level of the trigger.</p>"},{"location":"acquire-imaging/api_reference/#acquire.TriggerInputOutputCapabilities","title":"<code>acquire.TriggerInputOutputCapabilities</code>","text":"<p>Specifies which of the up to 8 supported digital lines can be used for either input or output triggering.</p> <p>The 2 attributes, input and output, each are read-only values and 8-bit integers from the conversion of the 8 binary digit representation of the digital lines to a decimal integer.</p> <p>Attributes:</p> Name Type Description <code>input</code> <code>int</code> <p>8-bit integer representing which digital lines can be used for input triggering. For example, if lines 0 and 2 were available for input triggers, the 8 binary digit representation of the lines is 00000101, which is 5 in the decimal system.</p> <code>output</code> <code>int</code> <p>8-bit integer representing which digital lines can be used for output triggering. For example, if lines 3 and 5 were available for output triggers, the 8 binary digit representation of the lines is 00101000, which is 40 in the decimal system.</p> <p>Examples:</p> <p>If lines 0 and 2 were available for input triggers, the 8 binary digit representation would be 0b00000101, since the 8 available lines are zero indexed. 00000101 binary is 5 in the decimal system, so the input attribute would have a value of 5.</p>"},{"location":"acquire-imaging/api_reference/#acquire.VideoFrame","title":"<code>acquire.VideoFrame</code>","text":"<p>The <code>VideoFrame</code> class represents data from acquisition of a frame.</p> <p>Methods:</p> Name Description <code>data</code> <p>Returns the data of the video frame as an NDArray.</p> <code>metadata</code> <p>Returns the metadata associated with the video frame.</p>"},{"location":"acquire-imaging/api_reference/#acquire.VideoFrame.data","title":"<code>data() -&gt; NDArray[Any]</code>","text":"<p>Returns the data of the video frame as an NDArray.</p> <p>Call <code>data()</code> to create an NDArray of the <code>VideoFrame</code> data.</p>"},{"location":"acquire-imaging/api_reference/#acquire.VideoFrame.metadata","title":"<code>metadata() -&gt; VideoFrameMetadata</code>","text":"<p>Returns the metadata associated with the video frame.</p> <p>Call <code>metadata()</code> to create a <code>VideoFrameMetadata</code> object containing the metadata of <code>VideoFrame</code>.</p>"},{"location":"acquire-imaging/api_reference/#acquire.VideoFrameMetadata","title":"<code>acquire.VideoFrameMetadata</code>","text":"<p>The <code>VideoFrameMetadata</code> class represents metadata related to a video frame.</p> <p>Attributes:</p> Name Type Description <code>frame_id</code> <code>int</code> <p>An integer representing the ID of the video frame.</p> <code>timestamps</code> <code>VideoFrameTimestamps</code> <p>An instance of the <code>VideoFrameTimestamps</code> class specifying the video timestamps based on the hardware clock and the acquisition clock.</p>"},{"location":"acquire-imaging/api_reference/#acquire.VideoFrameTimestamps","title":"<code>acquire.VideoFrameTimestamps</code>","text":"<p>The <code>VideoFrameTimestamps</code> class represents timestamps related to a video frame.</p> <p>Attributes:</p> Name Type Description <code>hardware</code> <code>int</code> <p>An integer representing hardware timestamps.</p> <code>acq_thread</code> <code>int</code> <p>An integer representing timestamps from the acquisition thread.</p>"},{"location":"acquire-imaging/api_reference/#acquire.VideoStream","title":"<code>acquire.VideoStream</code>","text":"<p>The <code>VideoStream</code> class represents a video stream.</p> <p>Attributes:</p> Name Type Description <code>camera</code> <code>Camera</code> <p>An instance of the <code>Camera</code> class representing the camera device for the video stream.</p> <code>storage</code> <code>Storage</code> <p>An instance of the <code>Storage</code> class representing the storage device for the video stream.</p> <code>max_frame_count</code> <code>int</code> <p>An integer representing the maximum number of frames to acquire.</p> <code>frame_average_count</code> <code>int</code> <p>An integer representing the number of frames to average, if any, before streaming. The default value is 0, which disables this feature. Setting this to 1 will also prevent averaging.</p>"},{"location":"acquire-imaging/api_reference/#acquire.VideoStreamCapabilities","title":"<code>acquire.VideoStreamCapabilities</code>","text":"<p>The <code>VideoStreamCapabilities</code> class captures the capabilities for a video stream.</p> <p>Attributes:</p> Name Type Description <code>camera</code> <code>CameraCapabilities</code> <p>An instance of the CameraCapabilities class which represents the capabilities for the camera in this video stream.</p> <code>storage</code> <code>StorageCapabilities</code> <p>An instance of the StorageCapabilities class which represents the capabilities for the storage device in this video stream.</p> <code>max_frame_count</code> <code>Property</code> <p>An instance of the Property class.</p> <code>frame_average_count</code> <code>Property</code> <p>An instance of the Property class.</p>"},{"location":"acquire-imaging/api_reference/#acquire.VoltageRange","title":"<code>acquire.VoltageRange</code>","text":"<p>The <code>VoltageRange</code> class represents a range of voltage values.</p> <p>Attributes:</p> Name Type Description <code>mn</code> <code>float</code> <p>A float representing the minimum voltage value.</p> <code>mx</code> <code>float</code> <p>A float representing the maximum voltage value.</p>"},{"location":"acquire-imaging/api_reference/#acquire._get_runtime","title":"<code>acquire._get_runtime() -&gt; Runtime</code>","text":"<p>Potentially create and get the global acquire runtime.</p>"},{"location":"acquire-imaging/api_reference/#acquire.core_api_version","title":"<code>acquire.core_api_version() -&gt; str</code>","text":"<p>Returns the version string for the core API.</p>"},{"location":"acquire-imaging/api_reference/#acquire.gui","title":"<code>acquire.gui(viewer: napari.Viewer, frame_count: int = 100, stream_count: int = 2) -&gt; None</code>","text":"<p>Napari dock-widget plugin entry-point</p> <p>This instances a magicgui dock widget that streams video to a layer.</p>"},{"location":"acquire-imaging/api_reference/#acquire.setup","title":"<code>acquire.setup(runtime: Runtime, camera: Union[str, List[str]] = 'simulated: radial sin', storage: Union[str, List[str]] = 'Tiff', output_filename: Optional[str] = 'out.tif') -&gt; Properties</code>","text":"<p>Set up the runtime with a camera and storage device.</p>"},{"location":"acquire-imaging/api_reference/#acquire.setup_one_streams","title":"<code>acquire.setup_one_streams(runtime: Runtime, frame_count: int) -&gt; Properties</code>","text":""},{"location":"acquire-imaging/api_reference/#acquire.setup_two_streams","title":"<code>acquire.setup_two_streams(runtime: Runtime, frame_count: int) -&gt; Properties</code>","text":""},{"location":"acquire-imaging/get_started/","title":"Getting Started with Acquire","text":"<p>Acquire (<code>acquire-imaging</code> on PyPI) is a Python package providing a multi-camera video streaming library focused on performant microscopy, with support for up to two simultaneous, independent, video streams.</p> <p>This tutorial covers Acquire installation and shows an example of using Acquire with its provided simulated cameras to demonstrate the acquisition process.</p>"},{"location":"acquire-imaging/get_started/#installation","title":"Installation","text":"<p>To install Acquire on Windows, macOS, or Ubuntu, simply run the following command:</p> <pre><code>python -m pip install acquire-imaging\n</code></pre> <p>We recommend installing <code>Acquire</code> in a fresh conda environment or virtualenv. For example, to install <code>Acquire</code> in a conda environment named <code>acquire</code>:</p> <pre><code>conda create -n acquire python=3.10 # follow the prompts and proceed with the defaults\nconda activate acquire\npython -m pip install acquire-imaging\n</code></pre> <p>or with virtualenv:</p> <pre><code>$ python -m venv venv\n$ . ./venv/bin/activate # or on Windows: .\\venv\\Scripts\\Activate.bat or .\\venv\\Scripts\\Activate.ps1\n(venv) $ python -m pip install acquire-imaging\n</code></pre> <p>Once you have Acquire installed, simply call <code>import acquire</code> in your script, notebook, or module to start utilizing the package.</p> <pre><code>import acquire\n</code></pre>"},{"location":"acquire-imaging/get_started/#supported-cameras-and-file-formats","title":"Supported Cameras and File Formats","text":"<p>Acquire supports the following cameras (currently only on Windows):</p> <ul> <li>Hamamatsu Orca Fusion BT (C15440-20UP)</li> <li>Vieworks VC-151MX-M6H00</li> <li>FLIR Blackfly USB3 (BFLY-U3-23S6M-C)</li> <li>FLIR Oryx 10GigE (ORX-10GS-51S5M-C)</li> </ul> <p>Acquire also supports the following output file formats:</p> <ul> <li>Tiff</li> <li>Zarr</li> </ul> <p>Acquire also provides a few simulated cameras, as well as raw byte storage and \"trash,\" which discards all data written to it.</p>"},{"location":"acquire-imaging/get_started/#tutorial-prerequisites","title":"Tutorial Prerequisites","text":"<p>We will be streaming to TIFF, using scikit-image to load and inspect the data, and visualizing the data using napari.</p> <p>You can install the prerequisites with:</p> <pre><code>python -m pip install \"napari[all]\" scikit-image\n</code></pre>"},{"location":"acquire-imaging/get_started/#setup-for-acquisition","title":"Setup for Acquisition","text":"<p>In Acquire parlance, the combination of a source (camera), filter, and sink (output) is called a video stream. We will generate data using simulated cameras (our source) and output to TIFF on the filesystem (our sink). (For this tutorial, we will not use a filter.) Acquire supports up to two such video streams.</p> <p>Sources are implemented as Camera devices, and sinks are implemented as Storage devices. We'll start by seeing all the devices that Acquire supports:</p> <pre><code>import acquire\n\nruntime = acquire.Runtime()\ndm = runtime.device_manager()\n\nfor device in dm.devices():\n    print(device)\n</code></pre> <p>The runtime is the main entry point in Acquire. Through the runtime, you configure your devices, start acquisition, check acquisition status, inspect data as it streams from your cameras, and terminate acquisition.</p> <p>Let's configure our devices now. To do this, we'll get a copy of the current runtime configuration. We can update the configuration with identifiers from the runtime's device manager, but these devices won't be created until we start the acquisition.</p> <p>Before configuring the streams, grab the current configuration of the <code>Runtime</code> object with:</p> <pre><code>config = runtime.get_configuration()\n</code></pre> <p>Video streams are configured independently. Configure the first video stream by setting properties on <code>config.video[0]</code> and the second video stream with <code>config.video[1]</code>. We'll be using simulated cameras, one generating a radial sine pattern and one generating a random pattern.</p> <pre><code>config.video[0].camera.identifier = dm.select(acquire.DeviceKind.Camera, \"simulated: radial sin\")\n\n# how many adjacent pixels in each direction to combine by averaging; here, 1 means not to combine\nconfig.video[0].camera.settings.binning = 1\n\n# how long (in microseconds) your camera should collect light from the sample; for simulated cameras,\n# this is just a waiting period before generating the next frame\nconfig.video[0].camera.settings.exposure_time_us = 5e4  # 50 ms\n\n# the data type representing each pixel; here we choose unsigned 8-bit integer\nconfig.video[0].camera.settings.pixel_type = acquire.SampleType.U8\n\n# the shape, in pixels, of the image; width first, then height\nconfig.video[0].camera.settings.shape = (1024, 768)\n</code></pre> <pre><code>config.video[1].camera.identifier = dm.select(acquire.DeviceKind.Camera, \"simulated: uniform random\")\n\n# how many adjacent pixels in each direction to combine by averaging; here, 1 means not to combine\nconfig.video[1].camera.settings.binning = 1\n\n# how long (in microseconds) your camera should collect light from the sample; for simulated cameras,\n# this is just a waiting period before generating the next frame\nconfig.video[1].camera.settings.exposure_time_us = 1e4  # 10 ms\n\n# the data type representing each pixel; here we choose unsigned 8-bit integer\nconfig.video[1].camera.settings.pixel_type = acquire.SampleType.U8\n\n# the shape, in pixels, of the image; width first, then height\nconfig.video[1].camera.settings.shape = (1280, 720)\n</code></pre> <p>Now we'll configure each output, or sink device. For both simulated cameras, we'll be writing to TIFF, a well-known format for storing image data. For now, we'll simply specify the output file name. </p> <pre><code>config.video[0].storage.identifier = dm.select(acquire.DeviceKind.Storage, \"Tiff\")\n\n# what file or directory to write the data to\nconfig.video[0].storage.settings.filename = \"output1.tif\"\n</code></pre> <pre><code>config.video[1].storage.identifier = dm.select(acquire.DeviceKind.Storage, \"Tiff\")\n\n# what file or directory to write the data to\nconfig.video[1].storage.settings.filename = \"output2.tif\"\n</code></pre> <p>Finally, let's specify how many frames to generate for each camera before stopping our simulated acquisition. We also need to register our configuration with the runtime using the <code>set_configuration</code> method.</p> <p>If you want to let the runtime acquire effectively forever, you can set <code>max_frame_count</code> to <code>2**64 - 1</code>.</p> <pre><code>config.video[0].max_frame_count = 100 # collect 100 frames\nconfig.video[1].max_frame_count = 150 # collect 150 frames\n\nconfig = runtime.set_configuration(config)\n</code></pre> <p>Note</p> <p>If you run this tutorial multiple times, you can clear output from previous runs with:</p> <pre><code>from pathlib import Path\n\nPath(config.video[0].storage.settings.uri).unlink(missing_ok=True)\nPath(config.video[1].storage.settings.uri).unlink(missing_ok=True)\n</code></pre>"},{"location":"acquire-imaging/get_started/#acquire-data","title":"Acquire Data","text":"<p>To start acquiring data:</p> <pre><code>runtime.start()\n</code></pre> <p>Acquisition happens in a separate thread, so at any point we can check on the status by calling the  <code>get_state</code> method.</p> <pre><code>runtime.get_state()\n</code></pre> <p>Finally, once we're done acquiring, we call <code>runtime.stop()</code>. This method will wait until you've reached the number of frames to collect specified in <code>config.video[0].max_frame_count</code> or <code>config.video[1].max_frame_count</code>, whichever is larger.</p> <pre><code>runtime.stop()\n</code></pre>"},{"location":"acquire-imaging/get_started/#visualizing-the-data-with-napari","title":"Visualizing the data with napari","text":"<p>Let's take a look at what we've written. We'll load each Zarr dataset as a Dask array and inspect its dimensions, then we'll use napari to view it.</p> <pre><code>from skimage.io import imread\nimport napari\n\ndata1 = imread(config.video[0].storage.settings.filename)\ndata2 = imread(config.video[1].storage.settings.filename)\n\nviewer1 = napari.view_image(data1)\n\nviewer2 = napari.view_image(data2)\n</code></pre>"},{"location":"acquire-imaging/get_started/#conclusion","title":"Conclusion","text":"<p>For more examples of using Acquire, check out our tutorials page.</p> <p>References:</p>"},{"location":"acquire-imaging/tutorials/","title":"Tutorials","text":"<p>These tutorials will help you explore the main use cases of Acquire and show examples of using the API. Please submit an issue on Github if you'd like to request a tutorial, or if you are also interested in contributing to a tutorial to this documentation please visit our contribution guide.</p> Setup acquisition <p>Learn how to configure and run an acquisition</p> Setup acquisition Using JSON <p>Learn how to save and retrieve acquisition settings</p> Using JSON Data <p>Learn how to access data during acquisition</p> Data Zarr <p>Learn about using OME-Zarr with Acquire</p> Zarr"},{"location":"acquire-imaging/tutorials/access_data/","title":"Data","text":"<p>These tutorials will help you learn how to access data during acquisition. Please submit an issue on GitHub if you'd like to request a tutorial. If you are also interested in contributing to this documentation, please visit our contribution guide.</p> <ul> <li>Accessing Data during Acquisition</li> <li>Livestream to napari</li> </ul>"},{"location":"acquire-imaging/tutorials/access_data/framedata/","title":"Accessing Data during Acquisition","text":"<p>This tutorial will provide an example of accessing data from a video source during acquisition.</p>"},{"location":"acquire-imaging/tutorials/access_data/framedata/#configure-runtime","title":"Configure <code>Runtime</code>","text":"<p>To start, we'll create a <code>Runtime</code> object and configure the streaming process.</p> <pre><code>import acquire\n\n# Initialize a Runtime object\nruntime = acquire.Runtime()\n\n# Initialize the device manager\ndm = runtime.device_manager()\n\n# Grab the current configuration\nconfig = runtime.get_configuration()\n\n# Select the radial sine simulated camera as the video source\nconfig.video[0].camera.identifier = dm.select(acquire.DeviceKind.Camera, \"simulated: radial sin\")\n\n# Set the storage to trash to avoid saving the data\nconfig.video[0].storage.identifier = dm.select(acquire.DeviceKind.Storage, \"Trash\")\n\n# Set the time for collecting data for a each frame\nconfig.video[0].camera.settings.exposure_time_us = 5e4  # 50 ms\n\n# Set the shape of the region of interest on the camera chip\nconfig.video[0].camera.settings.shape = (1024, 768)\n\n# Set the max frame count to 2**(64-1) the largest number supported by Uint64 for essentially infinite acquisition\nconfig.video[0].max_frame_count = 100 # collect 100 frames\n\n# Update the configuration with the chosen parameters\nconfig = runtime.set_configuration(config)\n</code></pre>"},{"location":"acquire-imaging/tutorials/access_data/framedata/#working-with-availabledata-objects","title":"Working with <code>AvailableData</code> objects","text":"<p>During Acquisition, the <code>AvailableData</code> object is the streaming interface. We can create an <code>AvailableData</code> object by calling <code>get_available_data</code> in a <code>with</code> statement, and work with the <code>AvailableData</code> object while it exists inside of the <code>with</code> loop. The data is invalidated after exiting the <code>with</code> block, so make a copy of the <code>AvailableData</code> object to work with the data outside of the <code>with</code> block. In this example, we'll simply use the <code>AvailableData</code> object inside of the <code>with</code> block.</p> <p>There may not be data available. To increase the likelihood of <code>AvailableData</code> containing data, we'll utilize the <code>time</code> python package to introduce a delay before we create our <code>AvailableData</code> object.</p> <p>If there is data, we'll use the <code>AvailableData</code> <code>frames</code> method, which iterates over the <code>VideoFrame</code> objects in <code>AvailableData</code>, and the python <code>list</code> method to create a variable <code>video_frames</code>, a list of the <code>VideoFrame</code> objects one for each stream. </p> <p><code>VideoFrame</code> has a <code>data</code> method which provides the frame as an <code>NDArray</code>. The shape of this NDArray corresponds to the image dimensions used internally by Acquire namely [planes, height, width, channels]. Since we have a single channel, both the first and the last dimensions will be 1. The interior dimensions are height and width, respectively. We can use the <code>numpy.squeeze</code> method to grab the desired NDArray image data since the other dimensions are 1. This is equivalent to <code>image = first_frame[0][:, :, 0]</code>.</p> <pre><code># package for introducing time delays\nimport time\n\n# start acquisition\nruntime.start()\n\n# time delay of 0.5 seconds\ntime.sleep(0.5)\n\n# grab the packet of data available on disk for video stream 0.\n# This is an AvailableData object.\nwith runtime.get_available_data(0) as available_data:\n\n    # NoneType if there is no available data.\n    # We can only grab frames if data is available.\n    if available_data.get_frame_count() &gt; 0:\n\n        # frames is an iterator over available_data\n        # we'll use this iterator to make a list of the frames\n        video_frames = list(available_data.frames())\n\n    # grab the first VideoStream object in frames and convert it to an NDArray\n    first_frame = video_frames[0].data()\n\n    #inspect the dimensions of the first_frame\n    print(first_frame.shape)\n\n    # Selecting the image data. Equivalent to image = first_frame[0][:, :, 0]\n    image = first_frame.squeeze()\n\n    # inspect the dimensions of the squeezed first_frame\n    print(image.shape)\n\n# stop runtime\nruntime.stop()\n</code></pre> <p>The output will be: <pre><code>(1, 768, 1024, 1)\n(768, 1024)\n</code></pre></p> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/access_data/livestream/","title":"Livestream to napari","text":"<p>The below script can be used to livestream data to the napari viewer. You may also utilize the <code>Acquire</code> napari plugin, which is provided in the package upon install. You can access the plugin in the napari plugins menu once <code>Acquire</code> is installed. You can review the plugin code in the <code>acquire-imaging</code> repository. You may also stream using other packages such at <code>matplotlib</code>.</p> <pre><code>\"\"\"\nThis script will livestream data to the [napari viewer](https://napari.org/stable/). You may also utilize the `Acquire` napari plugin, which is provided in the `acquire-imaging` package on PyPI upon install. You can access the plugin in the napari plugins menu once `Acquire` is installed. You can review the [plugin code in `acquire-imaging`](https://github.com/acquire-project/acquire-python/blob/main/python/acquire/__init__.py).\n\"\"\"\n\nimport acquire\nruntime = acquire.Runtime()\n\n# Initialize the device manager\ndm = runtime.device_manager()\n\n# Grab the current configuration\nconfig = runtime.get_configuration()\n\n# Select the uniform random camera as the video source\nconfig.video[0].camera.identifier = dm.select(acquire.DeviceKind.Camera, \".*random.*\")\n\n# Set the storage to trash to avoid saving the data\nconfig.video[0].storage.identifier = dm.select(acquire.DeviceKind.Storage, \"Trash\")\n\n# Set the time for collecting data for a each frame\nconfig.video[0].camera.settings.exposure_time_us = 5e4  # 500 ms\n\nconfig.video[0].camera.settings.shape = (300, 200)\n\n# Set the max frame count to 100 frames\nconfig.video[0].max_frame_count = 100\n\n# Update the configuration with the chosen parameters\nconfig = runtime.set_configuration(config)\n\n# import napari and open a viewer to stream the data\nimport napari\nviewer = napari.Viewer()\n\nimport time\nfrom napari.qt.threading import thread_worker\n\ndef update_layer(args) -&gt; None:\n    (new_image, stream_id) = args\n    print(f\"update layer: {new_image.shape=}, {stream_id=}\")\n    layer_key = f\"Video {stream_id}\"\n    try:\n        layer = viewer.layers[layer_key]\n        layer._slice.image._view = new_image\n        layer.data = new_image\n        # you can use the private api with layer.events.set_data() to speed up by 1-2 ms/frame\n\n    except KeyError:\n        viewer.add_image(new_image, name=layer_key)\n\n@thread_worker(connect={\"yielded\": update_layer})\ndef do_acquisition():\n    time.sleep(5)\n    runtime.start()\n\n    nframes = [0, 0]\n    stream_id = 0\n\n    def is_not_done() -&gt; bool:\n        return (nframes[0] &lt; config.video[0].max_frame_count) or (\n                nframes[1] &lt; config.video[1].max_frame_count\n                )\n\n    def next_frame(): #-&gt; Optional[npt.NDArray[Any]]:\n        \"\"\"Get the next frame from the current stream.\"\"\"\n        if nframes[stream_id] &lt; config.video[stream_id].max_frame_count:\n            with runtime.get_available_data(stream_id) as data:\n                if packet := data:\n                    n = packet.get_frame_count()\n                    nframes[stream_id] += n\n                    f = next(packet.frames())\n                    return f.data().squeeze().copy()\n        return None\n\n    stream = 1\n    # loop to continue to update the data in napari while acquisition is running\n    while is_not_done():\n        if (frame := next_frame()) is not None:\n            yield frame, stream_id\n        time.sleep(0.1)\n\ndo_acquisition()\n\nnapari.run()\n</code></pre> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/","title":"Setup acquisition","text":"<p>These tutorials will help you learn how to configure and run an acquisition. Please submit an issue on GitHub if you'd like to request a tutorial. If you are also interested in contributing to this documentation, please visit our contribution guide.</p> <ul> <li>Configure an Acquisition</li> <li>Test Camera Drivers</li> <li>Device Selection</li> <li>Utilizing the Setup Method</li> <li>Multiple Acquisitions</li> <li>Storage Device Selection</li> <li>Finite Triggered Acquisition</li> </ul>"},{"location":"acquire-imaging/tutorials/setup_acquisition/configure/","title":"Configure an Acquisition","text":"<p>This tutorial will provide an in-depth explanation of setting configuration properites and demonstrate the relationships between various <code>Acquire</code> classes, such as <code>CameraProperties</code> and <code>StorageProperties</code>, used in the configuration process. In this example, we'll only configure one video source.</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/configure/#initialize-runtime","title":"Initialize <code>Runtime</code>","text":"<p><code>Runtime</code> is the main entry point in <code>Acquire</code>. Through the runtime, you configure your devices, start acquisition, check acquisition status, inspect data as it streams from your cameras, and terminate acquisition. The <code>device_manager</code> method in <code>Runtime</code> creates an instance of the <code>DeviceManager</code> class. The <code>get_configuration</code> method in <code>Runtime</code> creates an instance of the <code>Properties</code> class. To configure the acquisition, we'll use those two methods to grab the configuration and to initialize a <code>DeviceManager</code> object to set the attributes of <code>Properties</code> and related classes.</p> <pre><code>import acquire\n\n# Initialize a Runtime object\nruntime = acquire.Runtime()\n\n# Initialize the device manager\ndm = runtime.device_manager()\n\n# Grab the current configuration\nconfig = runtime.get_configuration()\n</code></pre>"},{"location":"acquire-imaging/tutorials/setup_acquisition/configure/#utilize-devicemanager","title":"Utilize <code>DeviceManager</code>","text":"<p><code>DeviceManager</code> contains a <code>devices</code> method which creates a list of <code>DeviceIdentifier</code> objects each representing a discovered camera or storage device. Each <code>DeviceIdentifier</code> has an attribute <code>kind</code> that is a <code>DeviceKind</code> object, which has attributes specifying whether the device is a camera or storage device, as well as <code>Signals</code> and <code>StageAxes</code> attributes. The <code>Signals</code> and <code>StageAxes</code> attributes would apply to device kinds such as stages, which are not yet supported by <code>Acquire</code>.</p> <p><code>DeviceManager</code> has 2 methods for selecting devices for the camera and storage. For more information on these methods, check out the Device Selection tutorial. We'll use the <code>select</code> method in this example to choose a specific device for the camera and storage.</p> <pre><code># Select the radial sine simulated camera as the video source\nconfig.video[0].camera.identifier = dm.select(acquire.DeviceKind.Camera, \"simulated: radial sin\")\n\n# Set the storage to Tiff\nconfig.video[0].storage.identifier = dm.select(acquire.DeviceKind.Storage, \"Tiff\")\n</code></pre>"},{"location":"acquire-imaging/tutorials/setup_acquisition/configure/#properties-class-explanation","title":"<code>Properties</code> Class Explanation","text":"<p>Using <code>Runtime</code>'s <code>get_configuration</code> method we created <code>config</code>, an instance of the <code>Properties</code> class. <code>Properties</code> contains only one attribute <code>video</code> which is a tuple of <code>VideoStream</code> objects since <code>Acquire</code> currently supports 2 camera streaming. To configure the first video stream, we'll index this tuple to select the first <code>VideoStream</code> object <code>config.video[0]</code>.</p> <p><code>VideoStream</code> objects have 2 attributes <code>camera</code> and <code>storage</code> which are instances of the <code>Camera</code> and <code>Storage</code> classes, respectively, and will be used to set the attributes of the selected camera device <code>simulated: radial sin</code> and storage device <code>Tiff</code>. The other attributes of <code>VideoStream</code> are integers that specify the maximum number of frames to collect and how many frames to average, if any, before storing the data. The <code>frame_average_count</code> has a default value of <code>0</code>, which disables this feature. We'll specify the max frame count, but keep the frame averaging disabled with:</p> <pre><code># Set the maximum number of frames to collect to 100\nconfig.video[0].max_frame_count = 100\n</code></pre>"},{"location":"acquire-imaging/tutorials/setup_acquisition/configure/#configure-camera","title":"Configure <code>Camera</code>","text":"<p><code>Camera</code> class objects have 2 attributes, <code>settings</code>, a <code>CameraProperties</code> object, and an optional attribute <code>identifier</code>, which is a <code>DeviceIdentifier</code> object.</p> <p><code>CameraProperties</code> has 5 attributes that are numbers and specify the exposure time and line interval in microseconds, how many pixels, if any, to bin (set to 1 by default to disable), and tuples for the image size and location on the camera chip. The other attributes are all instances of different classes. The <code>pixel_type</code> attribute is a <code>SampleType</code> object which indicates the data type of the pixel values in the image, such as Uint8. The <code>readout_direction</code> attribute is a <code>Direction</code> object specifying whether the data is read forwards or backwards from the camera. The <code>input_triggers</code> attribute is an <code>InputTriggers</code> object that details the characteristics of any input triggers in the system. The <code>output_triggers</code> attribute is an <code>OutputTriggers</code> object that details the characteristics of any output triggers in the system. All of the attributes of <code>InputTriggers</code> and <code>OutputTriggers</code> objects are instances of the <code>Trigger</code> class. The <code>Trigger</code> class is described in Triggers from a JSON file.</p> <p>We'll configure some camera settings below.</p> <pre><code># Set the time for collecting data for a each frame\nconfig.video[0].camera.settings.exposure_time_us = 5e4  # 50 ms\n\n# (x, y) size of the image in pixels\nconfig.video[0].camera.settings.shape = (1024, 768)\n\n# Specify the pixel type as uint16\nconfig.video[0].camera.settings.pixel_type = acquire.SampleType.U16\n</code></pre>"},{"location":"acquire-imaging/tutorials/setup_acquisition/configure/#configure-storage","title":"Configure <code>Storage</code>","text":"<p><code>Storage</code> objects have 2 attributes, <code>settings</code>, a <code>StorageProperties</code> object, and an optional attribute <code>identifier</code>, which is an instance of the <code>DeviceIdentifier</code> class described above.</p> <p><code>StorageProperties</code> has 2 attributes <code>external_metadata_json</code> and <code>filename</code> which are strings of the filename or filetree of the output metadata in JSON format and image data in whatever format corresponds to the selected storage device, respectively. <code>first_frame_id</code> is an integer ID that corresponds to the first frame of the current acquisition and is typically 0. <code>pixel_scale_um</code> is the camera pixel size in microns. <code>acquisition_dimensions</code> is a list of <code>StorageDimension</code>, one for each acquisition dimension, ordered from fastest changing to slowest changing. <code>enable_multiscale</code> is a boolean used to specify if the data should be saved as an image pyramid.</p> <p>We'll specify the name of the output image file below.</p> <pre><code># Set the output file to out.tiff\nconfig.video[0].storage.settings.filename = \"out.tiff\"\n</code></pre>"},{"location":"acquire-imaging/tutorials/setup_acquisition/configure/#update-configuration-settings","title":"Update Configuration Settings","text":"<p>None of the configuration settings are updated in <code>Runtime</code> until the <code>set_configuration</code> method is called. We'll be creating a new <code>Properties</code> object with the <code>set_configuration</code> method. For simplicity, we'll reuse <code>config</code> for the name of that object as well, but note that <code>new_config = runtime.set_configuration(config)</code> also works here.</p> <pre><code># Update the configuration with the chosen parameters\nconfig = runtime.set_configuration(config)\n</code></pre> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/drivers/","title":"Test Camera Drivers","text":"<p>This tutorial will cover testing that your cameras, or video sources, has been properly identified.</p> <p>Acquire supports the following cameras (currently only on Windows):</p> <ul> <li>Hamamatsu Orca Fusion BT (C15440-20UP)</li> <li>Vieworks VC-151MX-M6H00</li> <li>FLIR Blackfly USB3 (BFLY-U3-23S6M-C)</li> <li>FLIR Oryx 10GigE (ORX-10GS-51S5M-C)</li> </ul> <p>Acquire provides the following simulated cameras:</p> <ul> <li>simulated: uniform random - Produces uniform random noise for each pixel.</li> <li>simulated: radial sin - Produces an animated radial sine wave pattern.</li> <li>simulated: empty - Produces no data, leaving a blank image. This camera simulates acquiring as fast as possible.</li> </ul> <p>Acquire will only identify cameras whose drivers are present on your machine. The <code>DeviceManager</code> class manages selection of cameras and storage. We can create a <code>DeviceManager</code> object using the following:</p> <pre><code>import acquire\n\n# Instantiate a Runtime object\nruntime = acquire.Runtime()\n\n# Instantiate a DeviceManager object for the Runtime\ndm = runtime.device_manager()\n</code></pre> <p><code>DeviceManager</code> objects have <code>device</code> methods which lists the identifiers for discovered devices. You can iterate over this list to determine which cameras were discovered.</p> <pre><code>for device in dm.devices():\n    print(device)\n</code></pre> <p>The output of this code is below. All discovered devices, both cameras and storage devices, will be listed. In this tutorial, no cameras were connected to the machine, so only simulated cameras were found. Note that the storage devices also printed.</p> <pre><code>&lt;DeviceIdentifier Camera \"simulated: uniform random\"&gt;\n&lt;DeviceIdentifier Camera \"simulated: radial sin\"&gt;\n&lt;DeviceIdentifier Camera \"simulated: empty\"&gt;\n&lt;DeviceIdentifier Storage \"raw\"&gt;\n&lt;DeviceIdentifier Storage \"tiff\"&gt;\n&lt;DeviceIdentifier Storage \"trash\"&gt;\n&lt;DeviceIdentifier Storage \"tiff-json\"&gt;\n&lt;DeviceIdentifier Storage \"Zarr\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrBlosc1ZstdByteShuffle\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrBlosc1Lz4ByteShuffle\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrV3\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrV3Blosc1ZstdByteShuffle\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrV3Blosc1Lz4ByteShuffle\"&gt;\n</code></pre> <p>For cameras that weren't discovered you will see an error like the one below. These errors will not affect performance and can be ignored.</p> <pre><code>ERROR acquire.runtime 2023-10-20 19:03:17,917 runtime.rs:40 C:\\actions-runner\\_work\\acquire-driver-hdcam\\acquire-driver-hdcam\\src\\acquire-core-libs\\src\\acquire-device-hal\\device\\hal\\loader.c:114 - driver_load(): Failed to load driver at \"acquire-driver-hdcam\".\n</code></pre> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/select/","title":"Device Selection","text":"<p>This tutorial illustrates the difference between the <code>select</code> and <code>select_one_of</code> methods in the <code>DeviceManager</code> class. <code>select</code> chooses the first discovered device of a specific kind, camera or storage device. You can also, optionally, select a specific device by passing the device name as a string to <code>select</code>. Whereas, <code>select_one_of</code> requires that you specify both the kind of device to select and a list of possible device names. <code>select_one_of</code> will iterate through the list and select the first device in the list of names that is discovered on your machine.</p> <p>To start, instantiate <code>Runtime</code> and <code>DeviceManager</code> objects and subsequently print the discovered devices.</p> <pre><code>import acquire\n\n# Instantiate a Runtime object\nruntime = acquire.Runtime()\n\n# Instantiate a DeviceManager object for the Runtime\nmanager = runtime.device_manager()\n\n# List devices discovered by DeviceManager\nfor device in manager.devices():\n    print(device)\n</code></pre> <p>Output of the above code is below:</p> <pre><code>&lt;DeviceIdentifier Camera \"simulated: uniform random\"&gt;\n&lt;DeviceIdentifier Camera \"simulated: radial sin\"&gt;\n&lt;DeviceIdentifier Camera \"simulated: empty\"&gt;\n&lt;DeviceIdentifier Storage \"raw\"&gt;\n&lt;DeviceIdentifier Storage \"tiff\"&gt;\n&lt;DeviceIdentifier Storage \"trash\"&gt;\n&lt;DeviceIdentifier Storage \"tiff-json\"&gt;\n&lt;DeviceIdentifier Storage \"Zarr\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrBlosc1ZstdByteShuffle\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrBlosc1Lz4ByteShuffle\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrV3\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrV3Blosc1ZstdByteShuffle\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrV3Blosc1Lz4ByteShuffle\"&gt;\n</code></pre> <p>All identified devices will be listed, and in the case of this tutorial, none of the vendor provided camera drivers were installed on the machine, so only simulated cameras were found. Note that discovered storage devices will also print.</p> <p>The order of those printed devices matters. Below are two examples of how the <code>select</code> method works. In the first, without a specific device name provided, <code>select</code> will choose the first device of the specified kind in the list of discovered devices. In the second example, a specific device name is provided, so <code>select</code> will grab that device if it was discovered by <code>Runtime</code>.</p> <p><pre><code># specify that the device should be a camera and not a storage device\nkind = acquire.DeviceKind.Camera\n\n# 1st example: select the first camera in the list of discovered devices\nselected = manager.select(kind)\n\n# 2nd example: select a specific camera\nspecific = manager.select(kind, \"simulated: empty\")\n\n# print the 2 devices\nprint(selected)\nprint(specific)\n</code></pre> The output of the code is below: <pre><code>&lt;DeviceIdentifier Camera \"simulated: uniform random\"&gt;\n&lt;DeviceIdentifier Camera \"simulated: empty\"&gt;\n</code></pre></p> <p>The <code>select_one_of</code> method allows more flexibility since you provide a list of names of acceptable devices for it to iterate through until a discovered device is located.</p> <p><pre><code># specify that the device should be a camera and not a storage device\nkind = acquire.DeviceKind.Camera\n\nselected = manager.select_one_of(kind, [\"Hamamatsu_DCAMSDK4_v22126552\",\n    \"simulated: radial sin\", \"simulated: empty\"])\n\n# print which camera was selected\nprint(selected)\n</code></pre> The output of the code is below. The Hamamatsu camera was not discovered by <code>Runtime</code>, so <code>select_one_of</code> iterates until it finds a device discovered by <code>Runtime</code>. In this case, the next item in the list is a simulated camera that was discovered by <code>Runtime</code>. <pre><code>&lt;DeviceIdentifier Camera \"simulated: radial sin\"&gt;\n</code></pre></p> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/setup/","title":"Utilizing the Setup Method","text":"<p>This tutorial will provide an example of utilizing the setup method to configure <code>Runtime</code> and specify some basic properties.</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/setup/#setup-function-definition","title":"Setup Function Definition","text":"<pre><code>def setup(\n    runtime: Runtime,\n    camera: Union[str, List[str]],\n    storage: Union[str, List[str]],\n    output_filename: Optional[str],\n) -&gt; Properties\n</code></pre> <p>The <code>setup</code> function can be used as a shorthand to simplify the <code>Runtime</code> configuration process. <code>setup</code> takes a <code>Runtime</code> object and strings of the camera and storage device names and returns a <code>Properties</code> object. You may also optionally specify the filename for writing the data.</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/setup/#example","title":"Example","text":"<p><pre><code>import acquire\n\n# Initialize a Runtime object\nruntime = acquire.Runtime()\n\n# use setup to get configuration and set the camera, storage, and filename\nconfig = acquire.setup(runtime, \"simulated: radial sin\", \"Zarr\", \"out.zarr\")\n</code></pre> You can subsequently use <code>config</code> to specify additional settings and set those configurations before beginning acquisition.</p> <p>Without using setup, the process would take a few additional lines of codes. The below code is equivalent to the example above.</p> <pre><code>import acquire\n\n# Initialize a Runtime object\nruntime = acquire.Runtime()\n\n# Grab the current configuration\nconfig = runtime.get_configuration()\n\n# Select the radial sine simulated camera as the video source\nconfig.video[0].camera.identifier = runtime.device_manager().select(acquire.DeviceKind.Camera, \"simulated: radial sin\")\n\n# Set the storage to Zarr to have the option to save multiscale data\nconfig.video[0].storage.identifier = runtime.device_manager().select(acquire.DeviceKind.Storage, \"Zarr\")\n\n# Set the output file to out.zarr\nconfig.video[0].storage.settings.filename = \"out.zarr\"\n</code></pre> <p>In either case, we can update the configuration settings using:</p> <pre><code>config = runtime.set_configuration(config)\n</code></pre> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/start_stop/","title":"Multiple Acquisitions","text":"<p>This tutorial will provide an example of starting, stopping, and restarting acquisition, or streaming from a video source.</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/start_stop/#configure-streaming","title":"Configure Streaming","text":"<p>To start, we'll create a <code>Runtime</code> object and configure the streaming process. To do this, we'll utilize the setup method. More information on that method is detailed in Utilizing the Setup Method.</p> <pre><code>import acquire\n\n# Initialize a Runtime object\nruntime = acquire.Runtime()\n\n# Grab current configuration and\n# Choose Video Source and Storage Device\nconfig = acquire.setup(runtime, \"simulated: radial sin\", \"Tiff\")\n\n# Specify settings\nconfig.video[0].storage.settings.filename == \"out.tif\"\nconfig.video[0].camera.settings.shape = (192, 108)\nconfig.video[0].camera.settings.exposure_time_us = 10e4\nconfig.video[0].max_frame_count = 10\n\n# Update the configuration with the chosen parameters\nconfig = runtime.set_configuration(config)\n</code></pre>"},{"location":"acquire-imaging/tutorials/setup_acquisition/start_stop/#start-stop-and-restart-acquisition","title":"Start, Stop, and Restart Acquisition","text":"<p>During Acquisition, the <code>AvailableData</code> object is the streaming interface. Upon shutdown, <code>Runtime</code> deletes all of the objects created during acquisition to free up resources, and you must stop acquisition by calling <code>runtime.stop()</code> to shutdown after the max frames is collected or <code>runtime.abort()</code> to shutdown immediately) between acquisitions. Otherwise, an exception will be raised.</p> <p>To understand how acquisition works, we'll start, stop, and repeat acquisition and print the <code>DeviceState</code>, which can be <code>Armed</code>, <code>AwaitingConfiguration</code>, <code>Closed</code>, or <code>Running</code>, as well as print the <code>AvailableData</code> object throughout the process.</p> <p>If acquisition has ended, all of the objects are deleted, including <code>AvailableData</code> objects, so those will be <code>None</code> when not acquiring data. In addition, if enough time hasn't elapsed since acquisition started, <code>AvailableData</code> will also be <code>None</code>. We'll utilize the <code>time</code> python package to introduce time delays to account for these facts.</p> <pre><code># package used to introduce time delays\nimport time\n\n# start acquisition\nruntime.start()\n\nprint(runtime.get_state())\nprint(runtime.get_available_data(0))\n\n# wait 0.5 seconds to allow time for data to be acquired\ntime.sleep(0.5)\n\nprint(runtime.get_state())\nprint(runtime.get_available_data(0))\n\n# stop acquisition\nruntime.stop()\n\nprint(runtime.get_state())\nprint(runtime.get_available_data(0))\n\n# start acquisition\nruntime.start()\n\n# time delay of 5 sec &gt; 1 sec acquisition time\ntime.sleep(5)\n\nprint(runtime.get_state())\nprint(runtime.get_available_data(0))\n\n# stop acquisition\nruntime.stop()\n</code></pre> <p>The output will be:</p> <p><pre><code>DeviceState.Running\nNone\nDeviceState.Running\n&lt;builtins.AvailableData object at 0x00000218D685E5B0&gt;\nDeviceState.Armed\nNone\nDeviceState.Armed\n&lt;builtins.AvailableData object at 0x00000218D685E3D0&gt;\n</code></pre> 1. The first time we print is immediately after starting acquisition, so no time has elapsed for data collection as compared to the camera exposure time, so while the camera is running, <code>Running</code>, there is no data available. 2. The next print happens after waiting 0.5 seconds, so acquisition is still runnning and now there is acquired data available. 3. The subsequent print is following calling <code>runtime.stop()</code> which waits until the specified max number of frames is collected and then terminates acquisition. Thus, the device is no longer running and there is no available data, since all objects were deleted by calling the <code>stop</code> method. The device is in an <code>Armed</code> state ready for the next acquisition. 4. The final print occurs after waiting 5 seconds following the start of acquisition. This waiting period is longer than the 1 second acqusition time (0.1 seconds/frame and 10 frames), so the device is no longer collecting data. However, <code>runtime.stop()</code> hasn't been called, so the <code>AvailableData</code> object has not yet been deleted.</p> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/storage/","title":"Storage Device Selection","text":"<p>This tutorial describes the storage device options in <code>Acquire</code>.</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/storage/#description-of-storage-devices","title":"Description of Storage Devices","text":"<p>To start, we'll create a <code>Runtime</code> object and print the storage device options.</p> <p><pre><code>import acquire\n\n# Instantiate a Runtime object\nruntime = acquire.Runtime()\n\n# Instantiate a DeviceManager object for the Runtime\ndm = runtime.device_manager()\n\n# Print devices in DeviceManager of kind Storage\nfor device in dm.devices():\n    if device.kind == acquire.DeviceKind.Storage:\n        print(device)\n</code></pre> The output of that script will be:</p> <pre><code>&lt;DeviceIdentifier Storage \"raw\"&gt;\n&lt;DeviceIdentifier Storage \"tiff\"&gt;\n&lt;DeviceIdentifier Storage \"trash\"&gt;\n&lt;DeviceIdentifier Storage \"tiff-json\"&gt;\n&lt;DeviceIdentifier Storage \"Zarr\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrBlosc1ZstdByteShuffle\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrBlosc1Lz4ByteShuffle\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrV3\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrV3Blosc1ZstdByteShuffle\"&gt;\n&lt;DeviceIdentifier Storage \"ZarrV3Blosc1Lz4ByteShuffle\"&gt;\n</code></pre> <p><code>Acquire</code> supports streaming data to bigtiff, Zarr V2, Zarr V3. For both Zarr V2 and Zarr V3, Acquire provides OME metadata.</p> <p>Zarr has additional capabilities relative to the basic storage devices, namely chunking, compression, and multiscale storage. You can learn more about the Zarr capabilities in <code>Acquire</code> in the Acquire Zarr documentation.</p> <ul> <li> <p>raw - Streams to a raw binary file.</p> </li> <li> <p>tiff - Streams to a bigtiff file. Metadata is stored in the <code>ImageDescription</code> tag for each frame as a <code>JSON</code> string.</p> </li> <li> <p>trash - Writes nothing. Discards incoming data. Useful for live streaming applications.</p> </li> <li> <p>tiff-json - Stores the video stream in a bigtiff, and stores metadata in a <code>JSON</code> file. Both are located in a folder identified by the <code>filename</code> property.</p> </li> <li> <p>Zarr - Streams data to a Zarr V2 file with associated metadata.</p> </li> <li> <p>ZarrBlosc1ZstdByteShuffle - Streams compressed data (zstd codec) to a Zarr V2 file with associated metadata.</p> </li> <li> <p>ZarrBlosc1Lz4ByteShuffle - Streams compressed data (lz4 codec) to a Zarr V2 file with associated metadata.</p> </li> <li> <ul> <li>ZarrV3 - Streams data to a Zarr V3 file with associated metadata.</li> </ul> </li> <li> <p>ZarrV3Blosc1ZstdByteShuffle - Streams compressed data (zstd codec) to a Zarr V3 file with associated metadata.</p> </li> <li> <p>ZarrV3Blosc1Lz4ByteShuffle - Streams compressed data (lz4 codec) to a Zarr V3 file with associated metadata.</p> </li> </ul>"},{"location":"acquire-imaging/tutorials/setup_acquisition/storage/#configure-the-storage-device","title":"Configure the Storage Device","text":"<p>In the example below, the the <code>tiff</code> storage device is selected, and the data from one video source will be streamed to a file <code>out.tif</code>.</p> <pre><code># get the current configuration\nconfig = runtime.get_configuration()\n\n# Select the tiff storage device\nconfig.video[0].storage.identifier = dm.select(acquire.DeviceKind.Storage, \"tiff\")\n\n# Set the data filename to out.tif in your current directory (provide the whole filetree to save to a different directory)\nconfig.video[0].storage.settings.filename = \"out.tif\"\n</code></pre> <p>Before proceeding, complete the <code>Camera</code> setup and call <code>set_configuration</code> to save those new configuration settings.</p> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/trigger/","title":"Finite Triggered Acquisition","text":"<p>Acquire (<code>acquire-imaging</code> on PyPI) is a Python package providing a multi-camera video streaming library focused on performant microscopy, with support for up to two simultaneous, independent, video streams.</p> <p>This tutorial shows an example of setting up triggered acquisition of a finite number of frames with one of Acquire's supported devices and saving the data to a Zarr file.</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/trigger/#initialize-acquisition","title":"Initialize Acquisition","text":"<p>To start, we'll import <code>Acquire</code> and create an acquisition <code>Runtime</code> object, which initializes the driver adaptors needed for the supported cameras.</p> <pre><code>import acquire\nruntime = acquire.Runtime()\n</code></pre>"},{"location":"acquire-imaging/tutorials/setup_acquisition/trigger/#configure-camera","title":"Configure Camera","text":"<p>All camera settings can be captured by an instance of the <code>Properties</code> class, which will be associated with a given camera acquisition. The settings can be stored in a dictionary (e.g: <code>Properties.dict()</code>). These settings can be saved to a JSON file to be subsequently loaded, (e.g. <code>Properties(**json.load(open('acquire.json')))</code>), using the json library. Check out Properties from a JSON file for a more detailed example, but in brief, you would use something like:</p> <pre><code>config = runtime.get_configuration()\n\nimport json\nwith open(\"/path/to/acquire.json\", \"w\") as f:\n    json.dump(config.dict(), f)\n</code></pre> <p>The current configuration settings can be checked and assigned to an instance of the <code>Properties</code> class with:</p> <pre><code>config = runtime.get_configuration()\n</code></pre> <p>Since <code>Acquire</code> supports 2 video streams, each camera, or source, must be configured separately. In this example, we will only use 1 source for the acquisition, so we will only need to configure <code>config.video[0]</code>. To set the first video stream to Hamamatsu Orca Fusion BT (C15440-20UP), you can use the following with a regular expression to grab the Hamamatsu camera:</p> <pre><code>config.video[0].camera.identifier = runtime.device_manager().select(acquire.DeviceKind.Camera, 'Hamamatsu C15440.*')\n</code></pre> <p>Next we'll choose the settings for the Hamamatsu camera. The <code>CameraProperties</code> class describes the available settings, which include exposure time (in microseconds), binning, pixel data type (e.g. u16), and how many frames to acquire.</p> <p>Every property can be set using the following syntax, but in this example, we will only change a few of the available settings. Check out Configure an Acquisition for an explanation of camera properties.</p> <pre><code>config.video[0].camera.settings.binning = 1 # no pixels will be combined\nconfig.video[0].camera.settings.shape = (1700, 512) # shape of the image to be acquired in pixels\nconfig.video[0].camera.settings.offset = (302, 896) # centers the image region of interest on the camera sensor\nconfig.video[0].camera.settings.pixel_type = acquire.SampleType.U16 # sets the pixel data type to a 16-bit unsigned integer\nconfig.video[0].max_frame_count = 10 # finite acquisition of 10 frames. Use 0 for infinite acquisition.\n</code></pre> <p>Triggers can also be set in the <code>CameraProperties</code> object. The parameters can be stored in a dictionary (e.g: <code>Trigger.dict()</code>). You can construct a <code>Trigger</code> from a JSON file (e.g.  <code>acquire.Trigger(**json.loads(open('trigger.json')))</code> ), using the json library. Check out Triggers from a JSON file for a more detailed example, but in brief, you would use something like:</p> <pre><code>trig = acquire.Trigger()\n\nimport json\nwith open(\"/path/to/trigger.json\", \"w\") as f:\n    json.dump(trig.dict(), f)\n</code></pre> <p>In this example, we'll only utilize output triggers. By default, the camera's internal triggering is used, but you may explicitly disable external input triggers using:</p> <pre><code>config.video[0].camera.settings.input_triggers = acquire.InputTriggers() # default: disabled\n</code></pre> <p>Output triggers can be set to begin exposure, start a new frame, or wait before acquiring. We can enable an exposure trigger to start on the rising edge with:</p> <pre><code>config.video[0].camera.settings.output_triggers.exposure = acquire.Trigger(\n    edge=\"Rising\", enable=True, line=1, kind=\"Output\"\n)\n</code></pre>"},{"location":"acquire-imaging/tutorials/setup_acquisition/trigger/#select-storage","title":"Select Storage","text":"<p><code>Storage</code> objects have identifiers which specify the file type (e.g. Zarr or tiff) and settings described by an instance of the <code>StorageProperties</code> class. We can set the file type to Zarr and set the file name to \"out\" with:</p> <pre><code>config.video[0].storage.identifier = runtime.device_manager().select(acquire.DeviceKind.Storage,'zarr')\nconfig.video[0].storage.settings.filename=\"out.zarr\"\n</code></pre>"},{"location":"acquire-imaging/tutorials/setup_acquisition/trigger/#save-configuration","title":"Save configuration","text":"<p>None of these settings will be updated in the <code>Properties</code> object until you call the <code>set_configuration</code> method. This method updates what the current configuration settings are on the device.</p> <p>We'll set the configuration with:</p> <pre><code>config = runtime.set_configuration(config)\n</code></pre> <p>You can optionally print out these settings using the Rich python library to save for your records with:</p> <pre><code>from rich.pretty import pprint\npprint(config.dict())\n</code></pre> <p>Check out Properties from a JSON file for a more detailed example of saving <code>Properties</code>.</p>"},{"location":"acquire-imaging/tutorials/setup_acquisition/trigger/#acquire-data","title":"Acquire data","text":"<p>To begin acquisition:</p> <pre><code>runtime.start()\n</code></pre> <p>You can stop acquisition with <code>runtime.stop()</code> to stop after the max number of frames is collected or <code>runtime.abort()</code> to immediately stop acquisition. You must call one of these methods at the end of an acquisition, as <code>Runtime</code> deletes all of the objects created during acquisition to free up resources upon shutdown. Otherwise, an exception will be raised when trying to restart acquisition.</p> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/using_json/","title":"Using JSON","text":"<p>These tutorials will help you learn how to save and retrieve acquisition settings. Please submit an issue on GitHub if you'd like to request a tutorial. If you are also interested in contributing to this documentation, please visit our contribution guide.</p> <ul> <li>Loading Properties from a JSON file</li> <li>Loading Triggers from a JSON file</li> </ul>"},{"location":"acquire-imaging/tutorials/using_json/props_json/","title":"Properties from a JSON file","text":"<p>This tutorial will provide an example of saving and subsequently loading a <code>Properties</code> object from a JSON file.</p>"},{"location":"acquire-imaging/tutorials/using_json/props_json/#initialize-runtime","title":"Initialize Runtime","text":"<p>To start, we'll import <code>Acquire</code> and create a <code>Runtime</code> object, which coordinates the streaming process.</p> <pre><code>import acquire\nruntime = acquire.Runtime()\n</code></pre>"},{"location":"acquire-imaging/tutorials/using_json/props_json/#configure-camera","title":"Configure Camera","text":"<p>All camera settings are captured by an instance of the <code>Properties</code> class, which will be associated with a given camera acquisition.</p> <pre><code># Instantiate a Properties object for the Runtime\nconfig = runtime.get_configuration()\n</code></pre> <p>You can update any of the settings in this instance of <code>Properties</code>. To save any updated settings, use the <code>set_configuration</code> method.  For this tutorial, we'll simply specify a camera, and then save these new settings. Note that more settings must be provided before this <code>Properties</code> object could be used for an acquistion. Check out Configure an Acquisition for more information on configuring an acquisition.</p> <pre><code># set the radial sine simulated camera as the first video stream\nconfig.video[0].camera.identifier = runtime.device_manager().select(acquire.DeviceKind.Camera, \"simulated: radial sin\")\n\n# save the updated settings\nconfig = runtime.set_configuration(config)\n</code></pre>"},{"location":"acquire-imaging/tutorials/using_json/props_json/#save-properties-to-a-json-file","title":"Save Properties to a JSON file","text":"<p>We'll utilize the json library to write our properties to a JSON file to save for subsequent acquisition.</p> <pre><code>import json\n\n# cast the properties to a dictionary\nconfig = config.dict()\n\n# convert the dictionary to json with \"human-readable\" formatting\nconfig = json.dumps(config, indent=4, sort_keys=True)\n\n# save the properties to file \"sample_props.json\" in the current directory\nwith open(\"sample_props.json\", \"w\") as outfile:\n    outfile.write(config)\n</code></pre>"},{"location":"acquire-imaging/tutorials/using_json/props_json/#example-json-file","title":"Example JSON file","text":"<p>The resulting sample_props.json file is below:</p> <pre><code>{\n    \"video\": [\n        {\n            \"camera\": {\n                \"identifier\": {\n                    \"id\": [\n                        0,\n                        1\n                    ],\n                    \"kind\": \"Camera\",\n                    \"name\": \"simulated: radial sin\"\n                },\n                \"settings\": {\n                    \"binning\": 1,\n                    \"exposure_time_us\": 0.0,\n                    \"input_triggers\": {\n                        \"acquisition_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"exposure\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"frame_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        }\n                    },\n                    \"line_interval_us\": 0.0,\n                    \"offset\": [\n                        0,\n                        0\n                    ],\n                    \"output_triggers\": {\n                        \"exposure\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"frame_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"trigger_wait\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        }\n                    },\n                    \"pixel_type\": \"U16\",\n                    \"readout_direction\": \"Forward\",\n                    \"shape\": [\n                        1,\n                        1\n                    ]\n                }\n            },\n            \"frame_average_count\": 0,\n            \"max_frame_count\": 18446744073709551615,\n            \"storage\": {\n                \"identifier\": {\n                    \"id\": [\n                        0,\n                        5\n                    ],\n                    \"kind\": \"Storage\",\n                    \"name\": \"trash\"\n                },\n                \"settings\": {\n                    \"acquisition_dimensions\": [],\n                    \"enable_multiscale\": false,\n                    \"external_metadata_json\": \"\",\n                    \"filename\": \"\",\n                    \"first_frame_id\": 0,\n                    \"pixel_scale_um\": [\n                        0.0,\n                        0.0\n                    ]\n                },\n                \"write_delay_ms\": 0.0\n            }\n        },\n        {\n            \"camera\": {\n                \"identifier\": {\n                    \"id\": [\n                        0,\n                        0\n                    ],\n                    \"kind\": \"NONE\",\n                    \"name\": \"\"\n                },\n                \"settings\": {\n                    \"binning\": 1,\n                    \"exposure_time_us\": 0.0,\n                    \"input_triggers\": {\n                        \"acquisition_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"exposure\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"frame_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        }\n                    },\n                    \"line_interval_us\": 0.0,\n                    \"offset\": [\n                        0,\n                        0\n                    ],\n                    \"output_triggers\": {\n                        \"exposure\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"frame_start\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        },\n                        \"trigger_wait\": {\n                            \"edge\": \"Rising\",\n                            \"enable\": false,\n                            \"kind\": \"Input\",\n                            \"line\": 0\n                        }\n                    },\n                    \"pixel_type\": \"U16\",\n                    \"readout_direction\": \"Forward\",\n                    \"shape\": [\n                        0,\n                        0\n                    ]\n                }\n            },\n            \"frame_average_count\": 0,\n            \"max_frame_count\": 18446744073709551615,\n            \"storage\": {\n                \"identifier\": {\n                    \"id\": [\n                        0,\n                        0\n                    ],\n                    \"kind\": \"NONE\",\n                    \"name\": \"\"\n                },\n                \"settings\": {\n                    \"acquisition_dimensions\": [],\n                    \"enable_multiscale\": false,\n                    \"external_metadata_json\": \"\",\n                    \"filename\": \"\",\n                    \"first_frame_id\": 0,\n                    \"pixel_scale_um\": [\n                        0.0,\n                        0.0\n                    ]\n                },\n                \"write_delay_ms\": 0.0\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"acquire-imaging/tutorials/using_json/props_json/#load-properties-from-a-json-file","title":"Load Properties from a JSON file","text":"<p>You can load the settings in the JSON file to a <code>Properties</code> object and set this configuration for your <code>Runtime</code> as shown below:</p> <pre><code>import acquire\nimport json\n\n# create a Runtime object\nruntime = acquire.Runtime()\n\n# Instantiate a `Properties` object from the settings in sample_props.json\nconfig = acquire.Properties(**json.load(open('sample_props.json')))\n\n# save the properties for this instance of Runtime\nconfig = runtime.set_configuration(config)\n</code></pre> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/using_json/trig_json/","title":"Triggers from a JSON file","text":"<p>This tutorial will provide an example of saving and subsequently loading a <code>Trigger</code> object from a JSON file.</p>"},{"location":"acquire-imaging/tutorials/using_json/trig_json/#initialize-runtime","title":"Initialize Runtime","text":"<p>To start, we'll import <code>Acquire</code> and create a <code>Runtime</code> object, which coordinates the streaming process.</p> <pre><code>import acquire\nruntime = acquire.Runtime()\n</code></pre>"},{"location":"acquire-imaging/tutorials/using_json/trig_json/#create-a-trigger-object","title":"Create a Trigger Object","text":"<p><code>Trigger</code> objects have 4 attributes: edge, enable, line, and kind. In this example, will only adjust the edge attribute.</p> <pre><code># Instantiate a Trigger object\ntrig = acquire.Trigger()\n\n# change the edge attribute from the default Rising to Falling\ntrig.edge = acquire.TriggerEdge.Falling\n</code></pre>"},{"location":"acquire-imaging/tutorials/using_json/trig_json/#save-properties-to-a-json-file","title":"Save Properties to a JSON file","text":"<p>We'll utilize the json library to write our <code>Trigger</code> to a JSON file to save for subsequent acquisition.</p> <pre><code>import json\n\n# cast the properties to a dictionary\ntrig = trig.dict()\n\n# convert the dictionary to json with \"human-readable\" formatting\ntrig = json.dumps(trig, indent=4, sort_keys=True)\n\n# save the trigger to file \"sample_trig.json\" in the current directory\nwith open(\"sample_trig.json\", \"w\") as outfile:\n    outfile.write(trig)\n</code></pre>"},{"location":"acquire-imaging/tutorials/using_json/trig_json/#example-json-file","title":"Example JSON file","text":"<p>The resulting sample_trig.json file is below:</p> <pre><code>{\n  \"edge\": \"Falling\",\n  \"enable\": false,\n  \"kind\": \"Input\",\n  \"line\": 0\n}\n</code></pre>"},{"location":"acquire-imaging/tutorials/using_json/trig_json/#load-properties-from-a-json-file","title":"Load Properties from a JSON file","text":"<p>You can load the trigger attributes in the JSON file to a <code>Trigger</code> object as shown below:</p> <pre><code># Instantiate a `Trigger` object from the settings in sample_trig.json\ntrig = acquire.Trigger(**json.load(open('sample_trig.json')))\n</code></pre> <p>Download this tutorial as a Python script</p>"},{"location":"acquire-imaging/tutorials/zarr/","title":"Zarr","text":"<p>These tutorials will help you learn about using Zarr with Acquire. Please submit an issue on GitHub if you'd like to request a tutorial. If you are also interested in contributing to this documentation, please visit our contribution guide.</p> <ul> <li>Writing to Compressed Zarr Files</li> </ul>"},{"location":"acquire-imaging/tutorials/zarr/compressed/","title":"Writing to Compressed Zarr Files","text":"<p>This tutorial will provide an example of writing compressed data to a Zarr file.</p> <p><code>Acquire</code> supports streaming compressed data to the <code>ZarrBlosc1*</code> storage devices. Compression is done via Blosc. Supported codecs are lz4 and zstd, available with ZarrBlosc1Lz4ByteShuffle and ZarrBlosc1ZstdByteShuffle devices, respectively. For a comparison of these codecs, please refer to the Blosc docs. You can learn more about the Zarr capabilities in <code>Acquire</code> in the Acquire Zarr documentation.</p>"},{"location":"acquire-imaging/tutorials/zarr/compressed/#configure-runtime","title":"Configure <code>Runtime</code>","text":"<p>To start, we'll create a <code>Runtime</code> object and configure the streaming process, selecting <code>ZarrBlosc1ZstdByteShuffle</code> as the storage device to enable compressing the data.</p> <pre><code>import acquire\n\n# Initialize a Runtime object\nruntime = acquire.Runtime()\n\n# Initialize the device manager\ndm = runtime.device_manager()\n\n# Grab the current configuration\nconfig = runtime.get_configuration()\n\n# Select the radial sine simulated camera as the video source\nconfig.video[0].camera.identifier = dm.select(acquire.DeviceKind.Camera, \"simulated: radial sin\")\n\n# Set the storage to ZarrBlosc1ZstdByteShuffle to avoid saving the data\nconfig.video[0].storage.identifier = dm.select(acquire.DeviceKind.Storage, \"ZarrBlosc1ZstdByteShuffle\")\n\n# Set the time for collecting data for a each frame\nconfig.video[0].camera.settings.exposure_time_us = 7e4  # 70 ms\n\n# Set the size in pixels of the image region of interest on the camera\nconfig.video[0].camera.settings.shape = (1024, 768)\n\n# Set the max frame count\nconfig.video[0].max_frame_count = 100 # collect 100 frames\n\n# Set the output location to out.zarr\nconfig.video[0].storage.settings.filename = \"out.zarr\"\n\n# Update the configuration with the chosen parameters\nconfig = runtime.set_configuration(config)\n</code></pre>"},{"location":"acquire-imaging/tutorials/zarr/compressed/#inspect-acquired-data","title":"Inspect Acquired Data","text":"<p>Now that the configuration is set to utilize the <code>ZarrBlosc1ZstdByteShuffle</code> storage device, we can acquire data, which will be compressed before it is stored to <code>out.zarr</code>. Since we did not specify the size of chunks, the data will be saved as a single chunk that is the size of the image data. You may specify chunk sizes using the <code>TileShape</code> class. For example, using <code>acquire.StorageProperties.chunking.tile.width</code> to set the width of the chunks.</p> <pre><code># acquire data\nruntime.start()\nruntime.stop()\n</code></pre> <p>We'll use the zarr-python package to read the data in <code>out.zarr</code> directory.</p> <pre><code># We'll utilize the zarr-python package to read the data\nimport zarr\n\n# load from Zarr\ncompressed = zarr.open(config.video[0].storage.settings.filename)\n</code></pre> <p>We'll print some of the data properties to illustrate how the data was compressed. Since we have not enabled multiscale output, <code>out.zarr</code> will only have one top level array<code>\"0\"</code>.</p> <pre><code># All of the data is stored in the \"0\" directory since the data was stored as a single chunk.\ndata = compressed[\"0\"]\n\nprint(data.compressor.cname)\nprint(data.compressor.clevel)\nprint(data.compressor.shuffle)\n</code></pre> <p>Output:</p> <pre><code>zstd\n1\n1\n</code></pre> <p>As expected, the data was compressed using the <code>zstd</code> codec.</p> <p>Download this tutorial as a Python script</p>"},{"location":"api_reference/","title":"Acquire Zarr API Reference","text":"Python API Reference <p>Information on classes and methods</p> Python API Reference C API Reference <p>Information on structures and methods</p> C API Reference"},{"location":"api_reference/zarr_api/","title":"Zarr Streaming Python API Reference","text":"<p>This documentation details the functions, modules, and objects provided by the Python API. For learning about the core concepts of Zarr, see the Core Concepts page. For examples of using the Python API, see the Python Examples page.</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.ArraySettings","title":"<code>acquire_zarr.ArraySettings</code>","text":"<p>Settings for a single array in the Zarr stream.</p> <p>Attributes:</p> Name Type Description <code>output_key</code> <code>str</code> <p>Key within the Zarr dataset where this array will be stored.</p> <code>dimensions</code> <code>List[Dimension]</code> <p>List of dimension properties defining the dataset structure. Should be ordered from slowest to fastest changing (e.g., [Z, Y, X] for 3D data).</p> <code>data_type</code> <code>Union[DataType, dtype]</code> <p>The pixel data type for the dataset.</p> <code>compression</code> <code>Optional[CompressionSettings]</code> <p>Optional compression settings for chunks. If None, no compression is applied.</p> <code>downsampling_method</code> <code>Optional[DownsamplingMethod]</code> <p>Method used for generating optional multiscale levels (image pyramid).</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.CompressionCodec","title":"<code>acquire_zarr.CompressionCodec</code>","text":"<p>Codec to use for compression, if any.</p> <p>Attributes:</p> Name Type Description <code>NONE</code> <code>CompressionCodec</code> <p>No compression</p> <code>BLOSC_LZ4</code> <code>CompressionCodec</code> <p>LZ4 compression using Blosc</p> <code>BLOSC_ZSTD</code> <code>CompressionCodec</code> <p>Zstd compression using Blosc</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.CompressionSettings","title":"<code>acquire_zarr.CompressionSettings</code>","text":"<p>Settings for compressing during acquisition.</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.Compressor","title":"<code>acquire_zarr.Compressor</code>","text":"<p>Compressor to use, if any.</p> <p>Attributes:</p> Name Type Description <code>NONE</code> <code>Compressor</code> <p>No compression.</p> <code>BLOSC1</code> <code>Compressor</code> <p>Blosc compressor.</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.DataType","title":"<code>acquire_zarr.DataType</code>","text":"<p>Data type used in the stream.</p> <p>Attributes:</p> Name Type Description <code>UINT8</code> <code>DataType</code> <p>Unsigned 8-bit integer.</p> <code>UINT16</code> <code>DataType</code> <p>Unsigned 16-bit integer.</p> <code>UINT32</code> <code>DataType</code> <p>Unsigned 32-bit integer.</p> <code>UINT64</code> <code>DataType</code> <p>Unsigned 64-bit integer.</p> <code>INT8</code> <code>DataType</code> <p>Signed 8-bit integer.</p> <code>INT16</code> <code>DataType</code> <p>Signed 16-bit integer.</p> <code>INT32</code> <code>DataType</code> <p>Signed 32-bit integer.</p> <code>INT64</code> <code>DataType</code> <p>Signed 64-bit integer.</p> <code>FLOAT32</code> <code>DataType</code> <p>Single precision floating point.</p> <code>FLOAT64</code> <code>DataType</code> <p>Double precision floating point.</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.Dimension","title":"<code>acquire_zarr.Dimension</code>","text":"<p>Properties of a dimension of the output array.</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.DimensionType","title":"<code>acquire_zarr.DimensionType</code>","text":"<p>Type of dimension.</p> <p>Attributes:</p> Name Type Description <code>SPACE</code> <code>DimensionType</code> <p>Spatial dimension.</p> <code>CHANNEL</code> <code>DimensionType</code> <p>Channel dimension.</p> <code>TIME</code> <code>DimensionType</code> <p>Time dimension.</p> <code>OTHER</code> <code>DimensionType</code> <p>Other dimension.</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.DownsamplingMethod","title":"<code>acquire_zarr.DownsamplingMethod</code>","text":"<p>Method used to downsample frames.</p> <p>Attributes:</p> Name Type Description <code>DECIMATE</code> <code>DownsamplingMethod</code> <p>Take the top left of each 4x4 block of pixels</p> <code>MEAN</code> <code>DownsamplingMethod</code> <p>Take the mean value of each 4x4 block of pixels</p> <code>MIN</code> <code>DownsamplingMethod</code> <p>Take the minimum value of each 4x4 block of pixels</p> <code>MAX</code> <code>DownsamplingMethod</code> <p>Take the maximum value of each 4x4 block of pixels</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.LogLevel","title":"<code>acquire_zarr.LogLevel</code>","text":"<p>Severity level to filter logs by.</p> <p>Attributes:</p> Name Type Description <code>DEBUG</code> <code>LogLevel</code> <p>Detailed information for debugging purposes.</p> <code>INFO</code> <code>LogLevel</code> <p>Informational messages.</p> <code>WARNING</code> <code>LogLevel</code> <p>Warnings.</p> <code>ERROR</code> <code>LogLevel</code> <p>Errors.</p> <code>NONE</code> <code>LogLevel</code> <p>Disable logging.</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.S3Settings","title":"<code>acquire_zarr.S3Settings</code>","text":"<p>Settings for connecting to and storing data in S3.</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.StreamSettings","title":"<code>acquire_zarr.StreamSettings</code>","text":"<p>Settings for configuring a Zarr stream.</p> <p>This class encapsulates all the configuration options needed to create a Zarr stream, including storage location, array configuration, and format options.</p> <p>Attributes:</p> Name Type Description <code>arrays</code> <code>List[ArraySettings]</code> <p>List of ArraySettings defining the structure and properties of each array in the dataset.</p> <code>store_path</code> <code>str</code> <p>Path to the store. Can be a filesystem path or S3 key prefix. For S3, this becomes the key prefix within the specified bucket.</p> <code>s3</code> <code>Optional[S3Settings]</code> <p>Optional S3 settings for cloud storage. If None, writes to local filesystem.</p> <code>version</code> <code>ZarrVersion</code> <p>Zarr format version to use (V2 or V3).</p> <code>max_threads</code> <code>int</code> <p>Maximum number of threads for parallel processing.</p> <code>custom_metadata</code> <code>Optional[str]</code> <p>Optional JSON-formatted custom metadata to include in the dataset.</p> <code>overwrite</code> <code>bool</code> <p>If True, removes any existing data at store_path before writing.</p> Note <p>For S3 storage with endpoint \"s3://my-endpoint.com\", bucket \"my-bucket\", and store_path \"my-dataset.zarr\", the final location will be \"s3://my-endpoint.com/my-bucket/my-dataset.zarr\".</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.ZarrStream","title":"<code>acquire_zarr.ZarrStream</code>","text":""},{"location":"api_reference/zarr_api/#acquire_zarr.ZarrVersion","title":"<code>acquire_zarr.ZarrVersion</code>","text":"<p>Zarr format version.</p> <p>Attributes:</p> Name Type Description <code>V2</code> <code>ZarrVersion</code> <p>Zarr format version 2</p> <code>V3</code> <code>ZarrVersion</code> <p>Zarr format version 3</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.get_log_level","title":"<code>acquire_zarr.get_log_level() -&gt; LogLevel</code>","text":"<p>Get the current log level for the Zarr API</p>"},{"location":"api_reference/zarr_api/#acquire_zarr.set_log_level","title":"<code>acquire_zarr.set_log_level(level: LogLevel) -&gt; None</code>","text":"<p>Set the log level for the Zarr API</p>"},{"location":"api_reference/c_api/","title":"Zarr Streaming C API Reference","text":"<p>This documentation details the functions and data structures provided by the C API. For learning about the core concepts of Zarr, see the Core Concepts page. For examples of using the C API, see the C/C++ Examples page.</p> <pre>acquire.zarr.h</pre> <p>The primary header file. This provides the main streaming functionality and settings configuration.</p> acquire.zarr.h <pre>zarr.types.h</pre> <p>Contains all type definitions and enumerations used by the library.</p> zarr.types.h"},{"location":"examples/","title":"Examples","text":"<p>Below are code snippets for completing various tasks using the Python API and C Interface to the Acquire Zarr library. Have an example you'd like to share with the community? Submit a GitHub issue and include \"Example:\" in your title.</p> Python Examples <p>Examples that demonstrate how to use the Python library</p> Python Examples C Examples <p>Examples that demonstrate how to use the C interface</p> C Examples"},{"location":"examples/c_examples/","title":"C/C++ examples","text":"<p>Below are examples in C or C++ for working with the Acquire Zarr library. Have an example you'd like to share with the community? Submit a GitHub issue and include \"Example:\" in your title.</p> Example: Basic streaming to filesystem <pre><code>/// @file stream-raw-to-filesystem.c\n/// @brief Basic Zarr V3 streaming to filesystem\n#include \"acquire.zarr.h\"\n\n#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint\nmain()\n{\n    // Configure stream settings\n    ZarrArraySettings array = {\n        .compression_settings = NULL,\n        .data_type = ZarrDataType_uint16,\n    };\n    ZarrStreamSettings settings = {\n        .store_path = \"output_v3.zarr\",\n        .s3_settings = NULL,\n        .version = ZarrVersion_3,\n        .max_threads = 0, // use all available threads\n        .arrays = &amp;array,\n        .array_count = 1,\n    };\n\n    // Set up dimensions (t, y, x)\n    ZarrArraySettings_create_dimension_array(settings.arrays, 3);\n\n    settings.arrays-&gt;dimensions[0] = (ZarrDimensionProperties){\n        .name = \"t\",\n        .type = ZarrDimensionType_Time,\n        .array_size_px = 0,\n        .chunk_size_px = 5,\n        .shard_size_chunks = 2,\n    };\n\n    settings.arrays-&gt;dimensions[1] = (ZarrDimensionProperties){\n        .name = \"y\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 48,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 1,\n    };\n\n    settings.arrays-&gt;dimensions[2] = (ZarrDimensionProperties){\n        .name = \"x\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 64,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 2,\n    };\n\n    // Create stream\n    ZarrStream* stream = ZarrStream_create(&amp;settings);\n    // Free Dimension array\n    ZarrArraySettings_destroy_dimension_array(settings.arrays);\n\n    if (!stream) {\n        fprintf(stderr, \"Failed to create stream\\n\");\n        return 1;\n    }\n\n    // Create sample data\n    const size_t width = 64;\n    const size_t height = 48;\n    uint16_t* frame = (uint16_t*)malloc(width * height * sizeof(uint16_t));\n\n    // Write frames\n    size_t bytes_written;\n    for (int t = 0; t &lt; 50; t++) {\n        // Fill frame with a moving diagonal pattern\n        for (size_t y = 0; y &lt; height; y++) {\n            for (size_t x = 0; x &lt; width; x++) {\n                // Create a diagonal pattern that moves with time\n                // and varies intensity based on position\n                int diagonal = (x + y + t * 8) % 32;\n\n                // Create intensity variation\n                uint16_t intensity;\n                if (diagonal &lt; 16) {\n                    intensity = (uint16_t)((diagonal * 4096)); // Ramp up\n                } else {\n                    intensity = (uint16_t)((31 - diagonal) * 4096); // Ramp down\n                }\n\n                // Add some circular features\n                int centerX = width / 2;\n                int centerY = height / 2;\n                int dx = x - centerX;\n                int dy = y - centerY;\n                int radius = (int)sqrt(dx*dx + dy*dy);\n\n                // Modulate the pattern with concentric circles\n                if (radius % 16 &lt; 8) {\n                    intensity = (uint16_t)(intensity * 0.7);\n                }\n\n                frame[y * width + x] = intensity;\n            }\n        }\n\n        ZarrStatusCode status =\n          ZarrStream_append(stream,\n                            frame,\n                            width * height * sizeof(uint16_t),\n                            &amp;bytes_written,\n                            NULL);\n\n        if (status != ZarrStatusCode_Success) {\n            fprintf(stderr,\n                    \"Failed to append frame: %s\\n\",\n                    Zarr_get_status_message(status));\n            break;\n        }\n    }\n\n    // Cleanup\n    free(frame);\n    ZarrStream_destroy(stream);\n    return 0;\n}\n</code></pre> <p>Download this example</p> Example: Multiscale streaming to filesystem <pre><code>/// @file stream-raw-multiscale-to-filesystem.c\n/// @brief Uncompressed streaming to a Zarr V3 store on the filesystem, with\n/// multiple levels of detail.\n#include \"acquire.zarr.h\"\n#include &lt;stdbool.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint\nmain()\n{\n    // Configure stream settings\n    ZarrArraySettings array = {\n        .compression_settings = NULL,\n        .data_type = ZarrDataType_uint16,\n        .multiscale = true,\n    };\n    ZarrStreamSettings settings = {\n        .store_path = \"output_v3_multiscale.zarr\",\n        .s3_settings = NULL,\n        .version = ZarrVersion_3,\n        .max_threads = 0, // use all available threads\n        .arrays = &amp;array,\n        .array_count = 1,\n    };\n\n    // Set up 5D array (t, c, z, y, x)\n    ZarrArraySettings_create_dimension_array(settings.arrays, 5);\n\n    settings.arrays-&gt;dimensions[0] = (ZarrDimensionProperties){\n        .name = \"t\",\n        .type = ZarrDimensionType_Time,\n        .array_size_px = 10,\n        .chunk_size_px = 5,\n        .shard_size_chunks = 2,\n    };\n\n    settings.arrays-&gt;dimensions[1] = (ZarrDimensionProperties){\n        .name = \"c\",\n        .type = ZarrDimensionType_Channel,\n        .array_size_px = 8,\n        .chunk_size_px = 4,\n        .shard_size_chunks = 2,\n    };\n\n    settings.arrays-&gt;dimensions[2] = (ZarrDimensionProperties){\n        .name = \"z\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 6,\n        .chunk_size_px = 2,\n        .shard_size_chunks = 1,\n    };\n\n    settings.arrays-&gt;dimensions[3] = (ZarrDimensionProperties){\n        .name = \"y\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 48,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 1,\n    };\n\n    settings.arrays-&gt;dimensions[4] = (ZarrDimensionProperties){\n        .name = \"x\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 64,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 2,\n    };\n\n    // Create stream\n    ZarrStream* stream = ZarrStream_create(&amp;settings);\n    // Free Dimension array\n    ZarrArraySettings_destroy_dimension_array(settings.arrays);\n\n    if (!stream) {\n        fprintf(stderr, \"Failed to create stream\\n\");\n        return 1;\n    }\n\n    // Create sample data\n    const size_t width = 64;\n    const size_t height = 48;\n    uint16_t* frame = (uint16_t*)malloc(width * height * sizeof(uint16_t));\n\n    // Write frames\n    size_t bytes_written;\n    for (int i = 0; i &lt; 10; i++) {\n        // Fill frame with sample data\n        for (size_t j = 0; j &lt; width * height; j++) {\n            frame[j] = i * 1000 + j;\n        }\n\n        ZarrStatusCode status =\n          ZarrStream_append(stream,\n                            frame,\n                            width * height * sizeof(uint16_t),\n                            &amp;bytes_written,\n                            NULL);\n\n        if (status != ZarrStatusCode_Success) {\n            fprintf(stderr,\n                    \"Failed to append frame: %s\\n\",\n                    Zarr_get_status_message(status));\n            break;\n        }\n    }\n\n    // Cleanup\n    free(frame);\n    ZarrStream_destroy(stream);\n    return 0;\n}\n</code></pre> <p>Download this example</p> Example: Compressed streaming to filesystem <pre><code>/// @file stream-compressed-to-filesystem.c\n/// @brief Zarr V3 with LZ4 compression to filesystem\n#include \"acquire.zarr.h\"\n\n#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint\nmain()\n{\n    // Configure compression\n    ZarrCompressionSettings compression = {\n        .compressor = ZarrCompressor_Blosc1,\n        .codec = ZarrCompressionCodec_BloscLZ4,\n        .level = 1,\n        .shuffle = 1,\n    };\n\n    // Configure stream settings\n    ZarrArraySettings array = {\n        .compression_settings = &amp;compression,\n        .data_type = ZarrDataType_uint16,\n    };\n    ZarrStreamSettings settings = {\n        .store_path = \"output_v3_compressed.zarr\",\n        .s3_settings = NULL,\n        .version = ZarrVersion_3,\n        .max_threads = 0, // use all available threads\n        .arrays = &amp;array,\n        .array_count = 1,\n    };\n\n    // Set up dimensions (t, y, x)\n    ZarrArraySettings_create_dimension_array(settings.arrays, 3);\n\n    settings.arrays-&gt;dimensions[0] = (ZarrDimensionProperties){\n        .name = \"t\",\n        .type = ZarrDimensionType_Time,\n        .array_size_px = 0,\n        .chunk_size_px = 5,\n        .shard_size_chunks = 2,\n    };\n\n    settings.arrays-&gt;dimensions[1] = (ZarrDimensionProperties){\n        .name = \"y\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 48,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 1,\n    };\n\n    settings.arrays-&gt;dimensions[2] = (ZarrDimensionProperties){\n        .name = \"x\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 64,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 2,\n    };\n\n    // Create stream\n    ZarrStream* stream = ZarrStream_create(&amp;settings);\n    // Free Dimension array\n    ZarrArraySettings_destroy_dimension_array(settings.arrays);\n\n    if (!stream) {\n        fprintf(stderr, \"Failed to create stream\\n\");\n        return 1;\n    }\n\n    // Create sample data\n    const size_t width = 64;\n    const size_t height = 48;\n    int centerX = width / 2;\n    int centerY = height / 2;\n\n    uint16_t* frame = (uint16_t*)malloc(width * height * sizeof(uint16_t));\n\n    // Write frames\n    size_t bytes_written;\n    for (int t = 0; t &lt; 50; t++) {\n        // Fill frame with a moving diagonal pattern\n        for (size_t y = 0; y &lt; height; y++) {\n            int dy = y - centerY;\n            for (size_t x = 0; x &lt; width; x++) {\n                // Create a diagonal pattern that moves with time\n                // and varies intensity based on position\n                int diagonal = (x + y + t * 8) % 32;\n\n                // Create intensity variation\n                uint16_t intensity;\n                if (diagonal &lt; 16) {\n                    intensity = (uint16_t)((diagonal * 4096)); // Ramp up\n                } else {\n                    intensity = (uint16_t)((31 - diagonal) * 4096); // Ramp down\n                }\n\n                // Add some circular features\n                int dx = x - centerX;\n                int radius = (int)sqrt(dx*dx + dy*dy);\n\n                // Modulate the pattern with concentric circles\n                if (radius % 16 &lt; 8) {\n                    intensity = (uint16_t)(intensity * 0.7);\n                }\n\n                frame[y * width + x] = intensity;\n            }\n        }\n\n        ZarrStatusCode status =\n          ZarrStream_append(stream,\n                            frame,\n                            width * height * sizeof(uint16_t),\n                            &amp;bytes_written,\n                            NULL);\n\n        if (status != ZarrStatusCode_Success) {\n            fprintf(stderr,\n                    \"Failed to append frame: %s\\n\",\n                    Zarr_get_status_message(status));\n            break;\n        }\n    }\n\n    // Cleanup\n    free(frame);\n    ZarrStream_destroy(stream);\n    return 0;\n}\n</code></pre> <p>Download this example</p> Example: Basic streaming to S3 <pre><code>/// @file stream-raw-to-s3.c\n/// @brief Zarr V3 with uncompressed data to S3\n#include \"acquire.zarr.h\"\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main() {\n    // Configure S3\n    // Ensure that you have set your S3 credentials in the environment variables\n    // AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and optionally AWS_SESSION_TOKEN\n    ZarrS3Settings s3 = {\n        .endpoint = \"http://localhost:9000\",\n        .bucket_name = \"my-bucket\",\n    };\n\n    // Configure stream settings\n    ZarrArraySettings array = {\n        .compression_settings = NULL, // No compression\n        .data_type = ZarrDataType_uint16,\n    };\n    ZarrStreamSettings settings = {\n        .store_path = \"output_v3_s3.zarr\",\n        .s3_settings = &amp;s3,\n        .version = ZarrVersion_3,\n        .max_threads = 0, // use all available threads\n        .arrays = &amp;array,\n        .array_count = 1,\n    };\n\n    // Set up dimensions (t, z, y, x)\n    ZarrArraySettings_create_dimension_array(settings.arrays, 4);\n\n    settings.arrays-&gt;dimensions[0] = (ZarrDimensionProperties){\n        .name = \"t\",\n        .type = ZarrDimensionType_Time,\n        .array_size_px = 0,  // Unlimited\n        .chunk_size_px = 5,\n        .shard_size_chunks = 2\n    };\n\n    settings.arrays-&gt;dimensions[1] = (ZarrDimensionProperties){\n        .name = \"z\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 10,\n        .chunk_size_px = 2,\n        .shard_size_chunks = 1\n    };\n\n    settings.arrays-&gt;dimensions[2] = (ZarrDimensionProperties){\n        .name = \"y\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 48,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 1\n    };\n\n    settings.arrays-&gt;dimensions[3] = (ZarrDimensionProperties){\n        .name = \"x\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 64,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 2\n    };\n\n    // Create stream\n    ZarrStream* stream = ZarrStream_create(&amp;settings);\n    // Free Dimension array\n    ZarrArraySettings_destroy_dimension_array(settings.arrays);\n\n    if (!stream) {\n        fprintf(stderr, \"Failed to create stream\\n\");\n        return 1;\n    }\n\n    // Create sample data\n    const size_t width = 64;\n    const size_t height = 48;\n    uint16_t* frame = (uint16_t*)malloc(width * height * sizeof(uint16_t));\n\n    // Write frames\n    size_t bytes_written;\n    for (int i = 0; i &lt; 10; i++) {\n        // Fill frame with sample data\n        for (size_t j = 0; j &lt; width * height; j++) {\n            frame[j] = i * 1000 + j;\n        }\n\n        ZarrStatusCode status =\n          ZarrStream_append(stream,\n                            frame,\n                            width * height * sizeof(uint16_t),\n                            &amp;bytes_written,\n                            NULL);\n\n        if (status != ZarrStatusCode_Success) {\n            fprintf(stderr, \"Failed to append frame: %s\\n\",\n                    Zarr_get_status_message(status));\n            break;\n        }\n    }\n\n    // Cleanup\n    free(frame);\n    ZarrStream_destroy(stream);\n    return 0;\n}\n</code></pre> <p>Download this example</p> Example: Compressed streaming to S3 <pre><code>/// @file stream-compressed-to-s3.c\n/// @brief Stream data to a Zarr V3 store with Zstd compression data on S3\n#include \"acquire.zarr.h\"\n\n#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint\nmain()\n{\n    // Configure compression\n    ZarrCompressionSettings compression = {\n        .compressor = ZarrCompressor_Blosc1,\n        .codec = ZarrCompressionCodec_BloscZstd,\n        .level = 1,\n        .shuffle = 1,\n    };\n\n    // Configure S3\n    // Ensure that you have set your S3 credentials in the environment variables\n    // AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and optionally AWS_SESSION_TOKEN\n    ZarrS3Settings s3 = {\n        .endpoint = \"http://localhost:9000\",\n        .bucket_name = \"my-bucket\",\n    };\n\n    // Configure stream settings\n    ZarrArraySettings array = {\n        .compression_settings = &amp;compression,\n        .data_type = ZarrDataType_uint16,\n    };\n    ZarrStreamSettings settings = {\n        .store_path = \"output_v3_compressed_s3.zarr\",\n        .s3_settings = &amp;s3,\n        .version = ZarrVersion_3,\n        .max_threads = 0, // use all available threads\n        .arrays = &amp;array,\n        .array_count = 1,\n    };\n\n    // Set up dimensions (t, y, x)\n    ZarrArraySettings_create_dimension_array(settings.arrays, 3);\n\n    settings.arrays-&gt;dimensions[0] = (ZarrDimensionProperties){\n        .name = \"t\",\n        .type = ZarrDimensionType_Time,\n        .array_size_px = 0, // Unlimited\n        .chunk_size_px = 5,\n        .shard_size_chunks = 2,\n    };\n\n    settings.arrays-&gt;dimensions[1] = (ZarrDimensionProperties){\n        .name = \"y\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 48,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 1,\n    };\n\n    settings.arrays-&gt;dimensions[2] = (ZarrDimensionProperties){\n        .name = \"x\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 64,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 2,\n    };\n\n    // Create stream\n    ZarrStream* stream = ZarrStream_create(&amp;settings);\n    // Free Dimension array\n    ZarrArraySettings_destroy_dimension_array(settings.arrays);\n\n    if (!stream) {\n        fprintf(stderr, \"Failed to create stream\\n\");\n        return 1;\n    }\n\n    // Create sample data\n    const size_t width = 64;\n    const size_t height = 48;\n    uint16_t* frame = (uint16_t*)malloc(width * height * sizeof(uint16_t));\n\n    // Write frames\n    size_t bytes_written;\n    for (int t = 0; t &lt; 50; t++) {\n        // Fill frame with a moving diagonal pattern\n        for (size_t y = 0; y &lt; height; y++) {\n            for (size_t x = 0; x &lt; width; x++) {\n                // Create a diagonal pattern that moves with time\n                // and varies intensity based on position\n                int diagonal = (x + y + t * 8) % 32;\n\n                // Create intensity variation\n                uint16_t intensity;\n                if (diagonal &lt; 16) {\n                    intensity = (uint16_t)((diagonal * 4096)); // Ramp up\n                } else {\n                    intensity = (uint16_t)((31 - diagonal) * 4096); // Ramp down\n                }\n\n                // Add some circular features\n                int centerX = width / 2;\n                int centerY = height / 2;\n                int dx = x - centerX;\n                int dy = y - centerY;\n                int radius = (int)sqrt(dx*dx + dy*dy);\n\n                // Modulate the pattern with concentric circles\n                if (radius % 16 &lt; 8) {\n                    intensity = (uint16_t)(intensity * 0.7);\n                }\n\n                frame[y * width + x] = intensity;\n            }\n        }\n\n        ZarrStatusCode status =\n          ZarrStream_append(stream,\n                            frame,\n                            width * height * sizeof(uint16_t),\n                            &amp;bytes_written,\n                            NULL);\n\n        if (status != ZarrStatusCode_Success) {\n            fprintf(stderr,\n                    \"Failed to append frame: %s\\n\",\n                    Zarr_get_status_message(status));\n            break;\n        }\n    }\n\n    // Cleanup\n    free(frame);\n    ZarrStream_destroy(stream);\n    return 0;\n}\n</code></pre> <p>Download this example</p> Example: Multiscale compressed streaming to S3 <pre><code>/// @file stream-compressed-multiscale-to-s3.c\n/// @brief Multiscale Zarr V3 with compressed data to S3\n#include \"acquire.zarr.h\"\n\n#include &lt;math.h&gt;\n#include &lt;stdbool.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint\nmain()\n{\n    // Configure compression\n    ZarrCompressionSettings compression = {\n        .compressor = ZarrCompressor_Blosc1,\n        .codec = ZarrCompressionCodec_BloscZstd,\n        .level = 1,\n        .shuffle = 1,\n    };\n\n    // Configure S3\n    // Ensure that you have set your S3 credentials in the environment variables\n    // AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and optionally AWS_SESSION_TOKEN\n    ZarrS3Settings s3 = {\n        .endpoint = \"http://127.0.0.1:9000\",\n        .bucket_name = \"my-bucket\",\n    };\n\n    // Configure stream settings\n    ZarrArraySettings array = {\n        .compression_settings = &amp;compression,\n        .data_type = ZarrDataType_uint16,\n        .multiscale = true,\n    };\n    ZarrStreamSettings settings = {\n        .store_path = \"output_v3_compressed_multiscale_s3.zarr\",\n        .s3_settings = &amp;s3,\n        .version = ZarrVersion_3,\n        .max_threads = 0, // use all available threads\n        .arrays = &amp;array,\n        .array_count = 1,\n    };\n\n    // Set up dimensions (t, z, y, x)\n    ZarrArraySettings_create_dimension_array(settings.arrays, 4);\n\n    settings.arrays-&gt;dimensions[0] = (ZarrDimensionProperties){\n        .name = \"t\",\n        .type = ZarrDimensionType_Time,\n        .array_size_px = 0, // Unlimited\n        .chunk_size_px = 5,\n        .shard_size_chunks = 2,\n    };\n\n    settings.arrays-&gt;dimensions[1] = (ZarrDimensionProperties){\n        .name = \"z\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 10,\n        .chunk_size_px = 2,\n        .shard_size_chunks = 1,\n    };\n\n    settings.arrays-&gt;dimensions[2] = (ZarrDimensionProperties){\n        .name = \"y\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 48,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 1,\n    };\n\n    settings.arrays-&gt;dimensions[3] = (ZarrDimensionProperties){\n        .name = \"x\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 64,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 2,\n    };\n\n    // Create stream\n    ZarrStream* stream = ZarrStream_create(&amp;settings);\n    // Free Dimension array\n    ZarrArraySettings_destroy_dimension_array(settings.arrays);\n\n    if (!stream) {\n        fprintf(stderr, \"Failed to create stream\\n\");\n        return 1;\n    }\n\n    // Create sample data\n    const size_t width = 64;\n    const size_t height = 48;\n    uint16_t* frame = (uint16_t*)malloc(width * height * sizeof(uint16_t));\n\n    // Write frames\n    size_t bytes_written;\n    for (int t = 0; t &lt; 10; t++) {\n        // Fill frame with a moving diagonal pattern\n        for (size_t y = 0; y &lt; height; y++) {\n            for (size_t x = 0; x &lt; width; x++) {\n                // Create a diagonal pattern that moves with time\n                // and varies intensity based on position\n                int diagonal = (x + y + t * 8) % 32;\n\n                // Create intensity variation\n                uint16_t intensity;\n                if (diagonal &lt; 16) {\n                    intensity = (uint16_t)((diagonal * 4096)); // Ramp up\n                } else {\n                    intensity = (uint16_t)((31 - diagonal) * 4096); // Ramp down\n                }\n\n                // Add some circular features\n                int centerX = width / 2;\n                int centerY = height / 2;\n                int dx = x - centerX;\n                int dy = y - centerY;\n                int radius = (int)sqrt(dx*dx + dy*dy);\n\n                // Modulate the pattern with concentric circles\n                if (radius % 16 &lt; 8) {\n                    intensity = (uint16_t)(intensity * 0.7);\n                }\n\n                frame[y * width + x] = intensity;\n            }\n        }\n\n        ZarrStatusCode status =\n          ZarrStream_append(stream,\n                            frame,\n                            width * height * sizeof(uint16_t),\n                            &amp;bytes_written,\n                            NULL);\n\n        if (status != ZarrStatusCode_Success) {\n            fprintf(stderr,\n                    \"Failed to append frame: %s\\n\",\n                    Zarr_get_status_message(status));\n            break;\n        }\n    }\n\n    // Cleanup\n    free(frame);\n    ZarrStream_destroy(stream);\n    return 0;\n}\n</code></pre> <p>Download this example</p> Example: Streaming multiple arrays to a Zarr store on the filesystem <pre><code>/// @file stream-multiarray-to-filesystem.cpp\n/// @brief Stream multiple arrays with different data types to filesystem\n#include \"acquire.zarr.h\"\n\n#include &lt;cstdint&gt; // for uint16_t, uint8_t\n#include &lt;cstdlib&gt; // for rand()\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\ntemplate&lt;typename T&gt;\nvoid\nfill_data(std::vector&lt;uint8_t&gt;&amp; data)\n{\n    T* data_view = reinterpret_cast&lt;T*&gt;(data.data());\n    size_t n_elements = data.size() / sizeof(T);\n\n    for (size_t i = 0; i &lt; n_elements; ++i) {\n        data_view[i] = static_cast&lt;T&gt;(rand() % 65536);\n    }\n}\n\nint\nmain()\n{\n    // Configure compression settings for different arrays\n    ZarrCompressionSettings lz4_compression = {\n        .compressor = ZarrCompressor_Blosc1,\n        .codec = ZarrCompressionCodec_BloscLZ4,\n        .level = 1,\n        .shuffle = 1,\n    };\n\n    ZarrCompressionSettings zstd_compression = {\n        .compressor = ZarrCompressor_Blosc1,\n        .codec = ZarrCompressionCodec_BloscZstd,\n        .level = 3,\n        .shuffle = 2,\n    };\n\n    // Configure stream settings\n    ZarrStreamSettings settings = {\n        .store_path = \"output_multiarray.zarr\",\n        .s3_settings = nullptr,\n        .version = ZarrVersion_3,\n        .max_threads = 0, // use all available threads\n        .overwrite = true,\n    };\n\n    // Allocate arrays\n    ZarrStatusCode status = ZarrStreamSettings_create_arrays(&amp;settings, 3);\n    if (status != ZarrStatusCode_Success) {\n        std::cerr &lt;&lt; \"Failed to create arrays: \"\n                  &lt;&lt; Zarr_get_status_message(status) &lt;&lt; std::endl;\n        return 1;\n    }\n\n    // Array 1: 5D uint16 array with LZ4 compression\n    settings.arrays[0] = {\n        .output_key = \"path/to/uint16_array\",\n        .compression_settings = &amp;lz4_compression,\n        .data_type = ZarrDataType_uint16,\n    };\n\n    // Array 2: 3D float32 array with Zstd compression\n    settings.arrays[1] = {\n        .output_key = \"a/float32/array\",\n        .compression_settings = &amp;zstd_compression,\n        .data_type = ZarrDataType_float32,\n    };\n\n    // Array 3: 3D uint8 array with no compression\n    settings.arrays[2] = {\n        .output_key = \"labels\",\n        .compression_settings = nullptr,\n        .data_type = ZarrDataType_uint8,\n    };\n\n    // Set up dimensions for Array 1: 5D (t, c, z, y, x)\n    ZarrArraySettings_create_dimension_array(&amp;settings.arrays[0], 5);\n    settings.arrays[0].dimensions[0] = {\n        .name = \"t\",\n        .type = ZarrDimensionType_Time,\n        .array_size_px = 0,\n        .chunk_size_px = 5,\n        .shard_size_chunks = 2,\n    };\n    settings.arrays[0].dimensions[1] = {\n        .name = \"c\",\n        .type = ZarrDimensionType_Channel,\n        .array_size_px = 8,\n        .chunk_size_px = 4,\n        .shard_size_chunks = 2,\n    };\n    settings.arrays[0].dimensions[2] = {\n        .name = \"z\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 6,\n        .chunk_size_px = 2,\n        .shard_size_chunks = 1,\n    };\n    settings.arrays[0].dimensions[3] = {\n        .name = \"y\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 48,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 1,\n    };\n    settings.arrays[0].dimensions[4] = {\n        .name = \"x\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 64,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 2,\n    };\n\n    // Set up dimensions for Array 2: 3D (z, y, x)\n    ZarrArraySettings_create_dimension_array(&amp;settings.arrays[1], 3);\n    settings.arrays[1].dimensions[0] = {\n        .name = \"z\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 6,\n        .chunk_size_px = 2,\n        .shard_size_chunks = 1,\n    };\n    settings.arrays[1].dimensions[1] = {\n        .name = \"y\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 48,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 1,\n    };\n    settings.arrays[1].dimensions[2] = {\n        .name = \"x\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 64,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 2,\n    };\n\n    // Set up dimensions for Array 3: 3D (z, y, x)\n    ZarrArraySettings_create_dimension_array(&amp;settings.arrays[2], 3);\n    settings.arrays[2].dimensions[0] = {\n        .name = \"z\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 6,\n        .chunk_size_px = 2,\n        .shard_size_chunks = 1,\n    };\n    settings.arrays[2].dimensions[1] = {\n        .name = \"y\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 48,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 1,\n    };\n    settings.arrays[2].dimensions[2] = {\n        .name = \"x\",\n        .type = ZarrDimensionType_Space,\n        .array_size_px = 64,\n        .chunk_size_px = 16,\n        .shard_size_chunks = 2,\n    };\n\n    // Create stream\n    ZarrStream* stream = ZarrStream_create(&amp;settings);\n\n    if (!stream) {\n        fprintf(stderr, \"Failed to create stream\\n\");\n        // Free dimension arrays before returning\n        for (int i = 0; i &lt; 3; i++) {\n            ZarrArraySettings_destroy_dimension_array(&amp;settings.arrays[i]);\n        }\n        ZarrStreamSettings_destroy_arrays(&amp;settings);\n        return 1;\n    }\n\n    // Create and write sample data for Array 1 (uint16, 5D)\n    size_t uint16_size = 10 * 8 * 6 * 48 * 64;\n    std::vector&lt;uint8_t&gt; uint16_data(uint16_size * sizeof(uint16_t));\n    fill_data&lt;uint16_t&gt;(uint16_data);\n\n    size_t bytes_written;\n    status = ZarrStream_append(stream,\n                               uint16_data.data(),\n                               uint16_size * sizeof(uint16_t),\n                               &amp;bytes_written,\n                               \"path/to/uint16_array\");\n\n    if (status != ZarrStatusCode_Success) {\n        std::cerr &lt;&lt; \"Failed to append uint16 data: \"\n                  &lt;&lt; Zarr_get_status_message(status) &lt;&lt; std::endl;\n    }\n\n    // Create and write sample data for Array 2 (float32, 3D)\n    size_t float32_size = 6 * 48 * 64;\n    std::vector&lt;uint8_t&gt; float32_data(float32_size * sizeof(float));\n    fill_data&lt;float&gt;(float32_data);\n\n    status = ZarrStream_append(stream,\n                               float32_data.data(),\n                               float32_size * sizeof(float),\n                               &amp;bytes_written,\n                               \"a/float32/array\");\n\n    if (status != ZarrStatusCode_Success) {\n        std::cerr &lt;&lt; \"Failed to append float32 data: \"\n                  &lt;&lt; Zarr_get_status_message(status) &lt;&lt; std::endl;\n    }\n\n    // Create and write sample data for Array 3 (uint8, 3D)\n    size_t uint8_size = 6 * 48 * 64;\n    std::vector&lt;uint8_t&gt; uint8_data(uint8_size * sizeof(uint8_t));\n    fill_data&lt;uint8_t&gt;(uint8_data);\n\n    status = ZarrStream_append(stream,\n                               uint8_data.data(),\n                               uint8_size * sizeof(uint8_t),\n                               &amp;bytes_written,\n                               \"labels\");\n\n    if (status != ZarrStatusCode_Success) {\n        std::cerr &lt;&lt; \"Failed to append uint8 data: \"\n                  &lt;&lt; Zarr_get_status_message(status) &lt;&lt; std::endl;\n    }\n\n    // Free dimension arrays\n    for (int i = 0; i &lt; 3; i++) {\n        ZarrArraySettings_destroy_dimension_array(&amp;settings.arrays[i]);\n    }\n    ZarrStreamSettings_destroy_arrays(&amp;settings);\n\n    // Tear down the stream\n    ZarrStream_destroy(stream);\n\n    return 0;\n}\n</code></pre> <p>Download this example</p>"},{"location":"examples/python_examples/","title":"Python examples","text":"<p>Below are examples in Python for working with the Acquire Zarr library. Have an example you'd like to share with the community? Submit a GitHub issue and include \"Example:\" in your title.</p> Example: Basic streaming to filesystem <pre><code># Stream to filesystem without compression\nimport numpy as np\nfrom acquire_zarr import (\n    ArraySettings, StreamSettings, ZarrStream, Dimension, DimensionType,\n    DataType\n)\n\n\ndef make_sample_data():\n    \"\"\"Generate sample data with moving diagonal pattern\"\"\"\n    width, height = 64, 48\n    frames = []\n\n    for t in range(50):\n        frame = np.zeros((height, width), dtype=np.uint16)\n\n        for y in range(height):\n            for x in range(width):\n                # Create a diagonal pattern that moves with time\n                diagonal = (x + y + t * 8) % 32\n\n                # Create intensity variation\n                if diagonal &lt; 16:\n                    intensity = diagonal * 4096  # Ramp up\n                else:\n                    intensity = (31 - diagonal) * 4096  # Ramp down\n\n                # Add circular features\n                center_x, center_y = width // 2, height // 2\n                dx, dy = x - center_x, y - center_y\n                radius = int(np.sqrt(dx*dx + dy*dy))\n\n                # Modulate with concentric circles\n                if radius % 16 &lt; 8:\n                    intensity = int(intensity * 0.7)\n\n                frame[y, x] = intensity\n\n        frames.append(frame)\n\n    return np.array(frames)\n\n\ndef main():\n    settings = StreamSettings()\n\n    # Configure 3D array (t, y, x) - no compression\n    settings.arrays = [\n        ArraySettings(\n            dimensions=[\n                Dimension(\n                    name=\"t\",\n                    kind=DimensionType.TIME,\n                    array_size_px=0,  # Unlimited\n                    chunk_size_px=5,\n                    shard_size_chunks=2,\n                ),\n                Dimension(\n                    name=\"y\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=48,\n                    chunk_size_px=16,\n                    shard_size_chunks=1,\n                ),\n                Dimension(\n                    name=\"x\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=64,\n                    chunk_size_px=16,\n                    shard_size_chunks=2,\n                ),\n            ],\n            data_type=DataType.UINT16,\n        )\n    ]\n\n    settings.store_path = \"output_v3.zarr\"\n\n    # Create stream\n    stream = ZarrStream(settings)\n\n    # Write sample data\n    sample_data = make_sample_data()\n    stream.append(sample_data)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Download this example</p> Example: Multiscale streaming to filesystem <pre><code># Stream to filesystem with multiscale, no compression\nimport numpy as np\nfrom acquire_zarr import (\n    ArraySettings, StreamSettings, ZarrStream, Dimension, DimensionType,\n    DownsamplingMethod\n)\n\n\ndef make_sample_data():\n    \"\"\"Generate sample data matching the 5D structure (t, c, z, y, x)\"\"\"\n    # Shape: (10 timepoints, 8 channels, 6 z-slices, 48 height, 64 width)\n    return np.random.randint(\n        0, 65535,\n        (10, 8, 6, 48, 64),\n        dtype=np.uint16\n    )\n\n\ndef main():\n    settings = StreamSettings()\n\n    # Configure 5D array (t, c, z, y, x) with multiscale, no compression\n    settings.arrays = [\n        ArraySettings(\n            dimensions=[\n                Dimension(\n                    name=\"t\",\n                    kind=DimensionType.TIME,\n                    array_size_px=10,\n                    chunk_size_px=5,\n                    shard_size_chunks=2,\n                ),\n                Dimension(\n                    name=\"c\",\n                    kind=DimensionType.CHANNEL,\n                    array_size_px=8,\n                    chunk_size_px=4,\n                    shard_size_chunks=2,\n                ),\n                Dimension(\n                    name=\"z\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=6,\n                    chunk_size_px=2,\n                    shard_size_chunks=1,\n                ),\n                Dimension(\n                    name=\"y\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=48,\n                    chunk_size_px=16,\n                    shard_size_chunks=1,\n                ),\n                Dimension(\n                    name=\"x\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=64,\n                    chunk_size_px=16,\n                    shard_size_chunks=2,\n                ),\n            ],\n            data_type=np.uint16,\n            downsampling_method=DownsamplingMethod.MEAN\n        )\n    ]\n\n    settings.store_path = \"output_v3_multiscale.zarr\"\n\n    # Create stream\n    stream = ZarrStream(settings)\n\n    # Write sample data\n    stream.append(make_sample_data())\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Download this example</p> Example: Compressed streaming to filesystem <pre><code># Stream to filesystem with LZ4 compression\nimport numpy as np\nfrom acquire_zarr import (\n    ArraySettings, StreamSettings, ZarrStream, Dimension, DimensionType,\n    DataType, Compressor, CompressionCodec, CompressionSettings\n)\n\n\ndef make_sample_data():\n    return np.random.randint(\n        0, 65535,\n        (5, 4, 2, 48, 64),  # Shape matches chunk sizes\n        dtype=np.uint16\n    )\n\n\ndef main():\n    settings = StreamSettings()\n\n    # Configure a 5D compressed output array\n    settings.arrays = [\n        ArraySettings(\n            compression=CompressionSettings(\n                compressor=Compressor.BLOSC1,\n                codec=CompressionCodec.BLOSC_LZ4,\n                level=1,\n                shuffle=1,\n            ),\n            dimensions=[\n                Dimension(\n                    name=\"t\",\n                    kind=DimensionType.TIME,\n                    array_size_px=10,\n                    chunk_size_px=5,\n                    shard_size_chunks=2,\n                ),\n                Dimension(\n                    name=\"c\",\n                    kind=DimensionType.CHANNEL,\n                    array_size_px=8,\n                    chunk_size_px=4,\n                    shard_size_chunks=2,\n                ),\n                Dimension(\n                    name=\"z\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=6,\n                    chunk_size_px=2,\n                    shard_size_chunks=1,\n                ),\n                Dimension(\n                    name=\"y\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=48,\n                    chunk_size_px=16,\n                    shard_size_chunks=1,\n                ),\n                Dimension(\n                    name=\"x\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=64,\n                    chunk_size_px=16,\n                    shard_size_chunks=2,\n                ),\n            ],\n            data_type=DataType.UINT16,\n        )\n    ]\n\n    settings.store_path = \"output_compressed.zarr\"\n\n    # Create stream\n    stream = ZarrStream(settings)\n\n    # Write sample data\n    stream.append(make_sample_data())\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Download this example</p> Example: Basic streaming to S3 <pre><code># Stream to S3\nimport numpy as np\n\n# Ensure that you have set your S3 credentials in the environment variables\n# AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and optionally AWS_SESSION_TOKEN\n# BEFORE importing acquire_zarr\nfrom acquire_zarr import (\n    ArraySettings, StreamSettings, ZarrStream, Dimension, DimensionType,\n    DataType, S3Settings\n)\n\n\ndef make_sample_data():\n    return np.random.randint(\n        0, 65535,\n        (5, 2, 48, 64),  # Shape matches chunk sizes\n        dtype=np.uint16\n    )\n\n\ndef main():\n    settings = StreamSettings()\n\n    # Configure S3\n    settings.s3 = S3Settings(\n        endpoint=\"http://localhost:9000\",\n        bucket_name=\"my-bucket\",\n        region=\"us-east-2\"\n    )\n\n    # Configure 4D array (t, z, y, x)\n    settings.arrays = [\n        ArraySettings(\n            dimensions=[\n                Dimension(\n                    name=\"t\",\n                    kind=DimensionType.TIME,\n                    array_size_px=0,  # Unlimited\n                    chunk_size_px=5,\n                    shard_size_chunks=2,\n                ),\n                Dimension(\n                    name=\"z\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=10,\n                    chunk_size_px=2,\n                    shard_size_chunks=1,\n                ),\n                Dimension(\n                    name=\"y\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=48,\n                    chunk_size_px=16,\n                    shard_size_chunks=1,\n                ),\n                Dimension(\n                    name=\"x\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=64,\n                    chunk_size_px=16,\n                    shard_size_chunks=2,\n                ),\n            ],\n            data_type= DataType.UINT16,\n        )\n    ]\n\n    settings.store_path = \"output_s3.zarr\"\n\n    # Create stream\n    stream = ZarrStream(settings)\n\n    # Write sample data\n    stream.append(make_sample_data())\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Download this example</p> Example: Compressed streaming to S3 <pre><code># Stream to S3 with Zstd compression\nimport numpy as np\n\n# Ensure that you have set your S3 credentials in the environment variables\n# AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and optionally AWS_SESSION_TOKEN\n# BEFORE importing acquire_zarr\nfrom acquire_zarr import (\n    ArraySettings, StreamSettings, ZarrStream, Dimension, DimensionType,\n    DataType, S3Settings, Compressor, CompressionCodec, CompressionSettings\n)\n\n\ndef make_sample_data():\n    \"\"\"Generate sample data with moving diagonal pattern\"\"\"\n    width, height = 64, 48\n    frames = []\n\n    for t in range(50):\n        frame = np.zeros((height, width), dtype=np.uint16)\n\n        for y in range(height):\n            for x in range(width):\n                # Create a diagonal pattern that moves with time\n                diagonal = (x + y + t * 8) % 32\n\n                # Create intensity variation\n                if diagonal &lt; 16:\n                    intensity = diagonal * 4096  # Ramp up\n                else:\n                    intensity = (31 - diagonal) * 4096  # Ramp down\n\n                # Add circular features\n                center_x, center_y = width // 2, height // 2\n                dx, dy = x - center_x, y - center_y\n                radius = int(np.sqrt(dx*dx + dy*dy))\n\n                # Modulate with concentric circles\n                if radius % 16 &lt; 8:\n                    intensity = int(intensity * 0.7)\n\n                frame[y, x] = intensity\n\n        frames.append(frame)\n\n    return np.array(frames)\n\n\ndef main():\n    settings = StreamSettings()\n\n    # Configure S3\n    settings.s3 = S3Settings(\n        endpoint=\"http://localhost:9000\",\n        bucket_name=\"my-bucket\"\n    )\n\n    # Configure 3D array (t, y, x) with Zstd compression\n    settings.arrays = [\n        ArraySettings(\n            compression=CompressionSettings(\n                compressor=Compressor.BLOSC1,\n                codec=CompressionCodec.BLOSC_ZSTD,\n                level=1,\n                shuffle=1,\n            ),\n            dimensions=[\n                Dimension(\n                    name=\"t\",\n                    kind=DimensionType.TIME,\n                    array_size_px=0,  # Unlimited\n                    chunk_size_px=5,\n                    shard_size_chunks=2,\n                ),\n                Dimension(\n                    name=\"y\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=48,\n                    chunk_size_px=16,\n                    shard_size_chunks=1,\n                ),\n                Dimension(\n                    name=\"x\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=64,\n                    chunk_size_px=16,\n                    shard_size_chunks=2,\n                ),\n            ],\n            data_type=DataType.UINT16,\n        )\n    ]\n\n    settings.store_path = \"output_v3_compressed_s3.zarr\"\n\n    # Create stream\n    stream = ZarrStream(settings)\n\n    # Write sample data\n    sample_data = make_sample_data()\n    stream.append(sample_data)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Download this example</p> Example: Multiscale compressed streaming to S3 <pre><code># Stream to S3 with multiscale and Zstd compression\nimport numpy as np\n\n# Ensure that you have set your S3 credentials in the environment variables\n# AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and optionally AWS_SESSION_TOKEN\n# BEFORE importing acquire_zarr\nfrom acquire_zarr import (\n    ArraySettings, StreamSettings, ZarrStream, Dimension, DimensionType,\n    DownsamplingMethod, S3Settings, Compressor, CompressionCodec, CompressionSettings\n)\n\n\ndef make_sample_data():\n    \"\"\"Generate sample data with moving diagonal pattern for 4D array (t, z, y, x)\"\"\"\n    width, height, depth = 64, 48, 10\n    frames = []\n\n    for t in range(10):\n        volume = np.zeros((depth, height, width), dtype=np.uint16)\n\n        for z in range(depth):\n            for y in range(height):\n                for x in range(width):\n                    # Create a diagonal pattern that moves with time\n                    diagonal = (x + y + t * 8) % 32\n\n                    # Create intensity variation\n                    if diagonal &lt; 16:\n                        intensity = diagonal * 4096  # Ramp up\n                    else:\n                        intensity = (31 - diagonal) * 4096  # Ramp down\n\n                    # Add circular features\n                    center_x, center_y = width // 2, height // 2\n                    dx, dy = x - center_x, y - center_y\n                    radius = int(np.sqrt(dx * dx + dy * dy))\n\n                    # Modulate with concentric circles\n                    if radius % 16 &lt; 8:\n                        intensity = int(intensity * 0.7)\n\n                    volume[z, y, x] = intensity\n\n        frames.append(volume)\n\n    return np.array(frames)\n\n\ndef main():\n    settings = StreamSettings()\n\n    # Configure S3\n    settings.s3 = S3Settings(\n        endpoint=\"http://127.0.0.1:9000\",\n        bucket_name=\"my-bucket\"\n    )\n\n    # Configure 4D array (t, z, y, x) with multiscale and Zstd compression\n    settings.arrays = [\n        ArraySettings(\n            compression=CompressionSettings(\n                compressor=Compressor.BLOSC1,\n                codec=CompressionCodec.BLOSC_ZSTD,\n                level=1,\n                shuffle=1,\n            ),\n            dimensions=[\n                Dimension(\n                    name=\"t\",\n                    kind=DimensionType.TIME,\n                    array_size_px=0,  # Unlimited\n                    chunk_size_px=5,\n                    shard_size_chunks=2,\n                ),\n                Dimension(\n                    name=\"z\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=10,\n                    chunk_size_px=2,\n                    shard_size_chunks=1,\n                ),\n                Dimension(\n                    name=\"y\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=48,\n                    chunk_size_px=16,\n                    shard_size_chunks=1,\n                ),\n                Dimension(\n                    name=\"x\",\n                    kind=DimensionType.SPACE,\n                    array_size_px=64,\n                    chunk_size_px=16,\n                    shard_size_chunks=2,\n                ),\n            ],\n            data_type=np.uint16,\n            downsampling_method=DownsamplingMethod.MEAN,\n        )\n    ]\n\n    settings.store_path = \"output_v3_compressed_multiscale_s3.zarr\"\n\n    # Create stream\n    stream = ZarrStream(settings)\n\n    # Write sample data\n    stream.append(make_sample_data())\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Download this example</p> Example: Streaming multiple arrays to a Zarr store on the filesystem <pre><code># Stream multiple arrays to filesystem\nimport numpy as np\n\nfrom acquire_zarr import (\n    ArraySettings, StreamSettings, ZarrStream, Dimension, DimensionType,\n    DownsamplingMethod, Compressor, CompressionCodec, CompressionSettings\n)\n\nfrom typing import Tuple\n\n\ndef make_sample_data(shape: Tuple[int, ...], dtype: np.dtype) -&gt; np.ndarray:\n    is_int = np.issubdtype(dtype, np.integer)\n    typemin = np.iinfo(dtype).min if is_int else np.finfo(dtype).min\n    typemax = np.iinfo(dtype).max if is_int else np.finfo(dtype).max\n\n    if is_int:\n        return np.random.randint(\n            typemin, typemax,\n            shape,\n            dtype=dtype\n        )\n    elif np.issubdtype(dtype, np.floating):\n        return np.random.uniform(\n            typemin, typemax,\n            shape\n        ).astype(dtype)\n    else:\n        raise ValueError(f\"Unsupported data type: {dtype}\")\n\n\ndef main():\n    settings = StreamSettings(\n        arrays=[\n            ArraySettings(\n                output_key=\"path/to/uint16_array\",\n                compression=CompressionSettings(\n                    compressor=Compressor.BLOSC1,\n                    codec=CompressionCodec.BLOSC_LZ4,\n                    level=1,\n                    shuffle=1,\n                ),\n                dimensions=[\n                    Dimension(\n                        name=\"t\",\n                        kind=DimensionType.TIME,\n                        array_size_px=0,\n                        chunk_size_px=5,\n                        shard_size_chunks=2,\n                    ),\n                    Dimension(\n                        name=\"c\",\n                        kind=DimensionType.CHANNEL,\n                        array_size_px=8,\n                        chunk_size_px=4,\n                        shard_size_chunks=2,\n                    ),\n                    Dimension(\n                        name=\"z\",\n                        kind=DimensionType.SPACE,\n                        array_size_px=6,\n                        chunk_size_px=2,\n                        shard_size_chunks=1,\n                    ),\n                    Dimension(\n                        name=\"y\",\n                        kind=DimensionType.SPACE,\n                        array_size_px=48,\n                        chunk_size_px=16,\n                        shard_size_chunks=1,\n                    ),\n                    Dimension(\n                        name=\"x\",\n                        kind=DimensionType.SPACE,\n                        array_size_px=64,\n                        chunk_size_px=16,\n                        shard_size_chunks=2,\n                    ),\n                ],\n                data_type=np.uint16,\n            ),\n            ArraySettings(\n                output_key=\"a/float32/array\",\n                compression=CompressionSettings(\n                    compressor=Compressor.BLOSC1,\n                    codec=CompressionCodec.BLOSC_ZSTD,\n                    level=3,\n                    shuffle=2,\n                ),\n                dimensions=[\n                    Dimension(\n                        name=\"z\",\n                        kind=DimensionType.SPACE,\n                        array_size_px=6,\n                        chunk_size_px=2,\n                        shard_size_chunks=1,\n                    ),\n                    Dimension(\n                        name=\"y\",\n                        kind=DimensionType.SPACE,\n                        array_size_px=48,\n                        chunk_size_px=16,\n                        shard_size_chunks=1,\n                    ),\n                    Dimension(\n                        name=\"x\",\n                        kind=DimensionType.SPACE,\n                        array_size_px=64,\n                        chunk_size_px=16,\n                        shard_size_chunks=2,\n                    ),\n                ],\n                data_type=np.float32,\n                downsampling_method=DownsamplingMethod.MEAN\n            ),\n            ArraySettings(\n                output_key=\"labels\",\n                dimensions=[\n                    Dimension(\n                        name=\"z\",\n                        kind=DimensionType.SPACE,\n                        array_size_px=6,\n                        chunk_size_px=2,\n                        shard_size_chunks=1,\n                    ),\n                    Dimension(\n                        name=\"y\",\n                        kind=DimensionType.SPACE,\n                        array_size_px=48,\n                        chunk_size_px=16,\n                        shard_size_chunks=1,\n                    ),\n                    Dimension(\n                        name=\"x\",\n                        kind=DimensionType.SPACE,\n                        array_size_px=64,\n                        chunk_size_px=16,\n                        shard_size_chunks=2,\n                    ),\n                ],\n                data_type=np.uint8,\n                downsampling_method=DownsamplingMethod.MAX\n            )\n        ],\n        store_path=\"output_multiarray.zarr\",\n        overwrite=True\n    )\n\n    # Create stream\n    stream = ZarrStream(settings)\n\n    # Write sample data to each array\n    stream.append(make_sample_data((10, 8, 6, 48, 64), np.uint16), \"path/to/uint16_array\")\n    stream.append(make_sample_data((6, 48, 64), np.float32), \"a/float32/array\")\n    stream.append(make_sample_data((6, 48, 64), np.uint8), \"labels\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Download this example</p>"},{"location":"for_contributors/","title":"For contributors","text":"<p>Thank you for your interest in contributing to the <code>Acquire</code> project! We welcome contributions to the <code>acquire-zarr</code> code base and to documentation. We are especially interested in contributions of bindings to <code>acquire-zarr</code> in languages relevant to microscopy such as MATLAB and Julia.</p> <ul> <li><code>Acquire</code> project</li> <li><code>Acquire</code> documentation</li> <li><code>acquire-zarr</code></li> <li><code>acquire-imaging</code></li> </ul>"},{"location":"for_contributors/codebase/","title":"Contribute to codebase","text":"<p>To contribute to the latest development version, build the libraries from source following these instructions to enable adding and testing changes locally before making a PR to the <code>acquire-zarr</code> repo. We especially welcome contributions of bug fixes, new features, and bindings in languages relevant to microscopy such as MATLAB and Julia.</p>"},{"location":"for_contributors/docs_contribution_quickstart/","title":"Contribute to docs","text":"<ol> <li>Make sure you have a fresh environment with the latest mkdocs and mkdocs-material installed. You can install them with <code>pip install -r requirements.txt</code> from the root of the repository.</li> <li>Your pages should be written as markdown files, using the basic markdown syntax or following the mkdocs or material for mkdocs syntax.</li> <li>Pages can be added to the top level menu or submenus by editing the <code>mkdocs.yml</code> file. The order of the pages in the menu is determined by the order of the pages in the <code>mkdocs.yml</code> file. Subpages can be added by creating subfolders in the <code>docs/</code> folder (see, for example, the <code>docs/tutorials/</code> folder).</li> <li>To add images, place them in the <code>docs/images/</code> folder and reference them in your markdown files using the relative path <code>../images/your_image.png</code>.</li> <li>Custom CSS configuration goes into the <code>docs/stylesheets/custom.css</code> file.</li> <li>To build the website locally, after activating your environment (either using <code>conda activate &lt;your-environment&gt;</code> or <code>source activate &lt;your-env&gt;</code>, for example), run <code>mkdocs serve</code> to start a local server. You can then view the website at the URL indicated on your console.</li> </ol>"},{"location":"for_contributors/update_version/","title":"Update docs version","text":"<p>After every new release of Acquire Python, the documentation version needs to be manually updated. This can be done by issuing the following command on the root of the Acquire docs repository:</p> <pre><code>mike deploy --push --update-aliases &lt;version-tag&gt; stable\n</code></pre> <p>where <code>&lt;version-tag&gt;</code> is the tag of the new release. This will</p> <ul> <li>create/update the alias <code>stable</code> for the <code>&lt;version-tag&gt;</code> release of the docs;</li> <li>update the version switcher dropdown accordingly (autogenerating the   <code>versions.json</code> file, which is only present in the deployed pages), and</li> <li>deploy the new version of the documentation to the <code>gh-pages</code> branch of the   repository (if the <code>--push</code> option is used, as above.)</li> </ul> <p>The default version of the documentation pages is <code>stable</code>, but this can be changed to another version by using the <code>mike set-default &lt;identifier&gt;</code> command.</p> <p>Note</p> <p>In order to provide downloadable <code>.py</code> files to the tutorials, make sure you run <code>bash .github/workflows/convert.sh</code> before deploying a new version with <code>mike</code>.</p>"},{"location":"acquire_zarr_c_api/annotated/","title":"Class List","text":"<p>Here are the classes, structs, unions and interfaces with brief descriptions:</p> <ul> <li>struct ZarrArraySettings Properties of a Zarr array. </li> <li>struct ZarrCompressionSettings Compression settings for a Zarr array. @detail The compressor is not the same as the codec. A codec is a specific implementation of a compression algorithm, while a compressor is a library that implements one or more codecs. </li> <li>struct ZarrDimensionProperties Properties of a dimension of a Zarr array. </li> <li>struct ZarrS3Settings S3 settings for streaming to Zarr. </li> <li>struct ZarrStreamSettings The settings for a Zarr stream. </li> </ul>"},{"location":"acquire_zarr_c_api/files/","title":"File List","text":"<p>Here is a list of all files with brief descriptions:</p> <ul> <li>dir acquire-zarr <ul> <li>dir include <ul> <li>file acquire.zarr.h </li> <li>file zarr.types.h </li> </ul> </li> </ul> </li> </ul>"},{"location":"acquire_zarr_c_api/structZarrArraySettings/","title":"Struct ZarrArraySettings","text":"<p>ClassList &gt; ZarrArraySettings</p> <p>Properties of a Zarr array. More...</p> <ul> <li><code>#include &lt;zarr.types.h&gt;</code></li> </ul>"},{"location":"acquire_zarr_c_api/structZarrArraySettings/#public-attributes","title":"Public Attributes","text":"Type Name ZarrCompressionSettings * compression_settings ZarrDataType data_type size_t dimension_count ZarrDimensionProperties * dimensions ZarrDownsamplingMethod downsampling_method bool multiscale const char * output_key"},{"location":"acquire_zarr_c_api/structZarrArraySettings/#detailed-description","title":"Detailed Description","text":"<p>Note:</p> <p>The dimensions array may be allocated with ZarrArraySettings_create_dimension_array and freed with ZarrArraySettings_destroy_dimension_array. The order in which you set the dimension properties in the array should match the order of the dimensions from slowest to fastest changing, for example, [Z, Y, X] for a 3D dataset. </p>"},{"location":"acquire_zarr_c_api/structZarrArraySettings/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"acquire_zarr_c_api/structZarrArraySettings/#variable-compression_settings","title":"variable compression_settings","text":"<pre><code>ZarrCompressionSettings* ZarrArraySettings::compression_settings;\n</code></pre>"},{"location":"acquire_zarr_c_api/structZarrArraySettings/#variable-data_type","title":"variable data_type","text":"<pre><code>ZarrDataType ZarrArraySettings::data_type;\n</code></pre>"},{"location":"acquire_zarr_c_api/structZarrArraySettings/#variable-dimension_count","title":"variable dimension_count","text":"<pre><code>size_t ZarrArraySettings::dimension_count;\n</code></pre>"},{"location":"acquire_zarr_c_api/structZarrArraySettings/#variable-dimensions","title":"variable dimensions","text":"<pre><code>ZarrDimensionProperties* ZarrArraySettings::dimensions;\n</code></pre>"},{"location":"acquire_zarr_c_api/structZarrArraySettings/#variable-downsampling_method","title":"variable downsampling_method","text":"<pre><code>ZarrDownsamplingMethod ZarrArraySettings::downsampling_method;\n</code></pre>"},{"location":"acquire_zarr_c_api/structZarrArraySettings/#variable-multiscale","title":"variable multiscale","text":"<pre><code>bool ZarrArraySettings::multiscale;\n</code></pre>"},{"location":"acquire_zarr_c_api/structZarrArraySettings/#variable-output_key","title":"variable output_key","text":"<pre><code>const char* ZarrArraySettings::output_key;\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/runner/work/acquire-docs/acquire-docs/acquire-zarr/include/zarr.types.h</code></p>"},{"location":"acquire_zarr_c_api/structZarrCompressionSettings/","title":"Struct ZarrCompressionSettings","text":"<p>ClassList &gt; ZarrCompressionSettings</p> <p>Compression settings for a Zarr array. @detail The compressor is not the same as the codec. A codec is a specific implementation of a compression algorithm, while a compressor is a library that implements one or more codecs. </p> <ul> <li><code>#include &lt;zarr.types.h&gt;</code></li> </ul>"},{"location":"acquire_zarr_c_api/structZarrCompressionSettings/#public-attributes","title":"Public Attributes","text":"Type Name ZarrCompressionCodec codec ZarrCompressor compressor uint8_t level uint8_t shuffle"},{"location":"acquire_zarr_c_api/structZarrCompressionSettings/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"acquire_zarr_c_api/structZarrCompressionSettings/#variable-codec","title":"variable codec","text":"<pre><code>ZarrCompressionCodec ZarrCompressionSettings::codec;\n</code></pre> <p>Codec to use </p>"},{"location":"acquire_zarr_c_api/structZarrCompressionSettings/#variable-compressor","title":"variable compressor","text":"<pre><code>ZarrCompressor ZarrCompressionSettings::compressor;\n</code></pre> <p>Compressor to use </p>"},{"location":"acquire_zarr_c_api/structZarrCompressionSettings/#variable-level","title":"variable level","text":"<pre><code>uint8_t ZarrCompressionSettings::level;\n</code></pre> <p>Compression level </p>"},{"location":"acquire_zarr_c_api/structZarrCompressionSettings/#variable-shuffle","title":"variable shuffle","text":"<pre><code>uint8_t ZarrCompressionSettings::shuffle;\n</code></pre> <p>Whether to shuffle the data before compressing </p> <p>The documentation for this class was generated from the following file <code>/home/runner/work/acquire-docs/acquire-docs/acquire-zarr/include/zarr.types.h</code></p>"},{"location":"acquire_zarr_c_api/structZarrDimensionProperties/","title":"Struct ZarrDimensionProperties","text":"<p>ClassList &gt; ZarrDimensionProperties</p> <p>Properties of a dimension of a Zarr array. </p> <ul> <li><code>#include &lt;zarr.types.h&gt;</code></li> </ul>"},{"location":"acquire_zarr_c_api/structZarrDimensionProperties/#public-attributes","title":"Public Attributes","text":"Type Name uint32_t array_size_px uint32_t chunk_size_px const char * name double scale uint32_t shard_size_chunks ZarrDimensionType type const char * unit"},{"location":"acquire_zarr_c_api/structZarrDimensionProperties/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"acquire_zarr_c_api/structZarrDimensionProperties/#variable-array_size_px","title":"variable array_size_px","text":"<pre><code>uint32_t ZarrDimensionProperties::array_size_px;\n</code></pre> <p>Size of the array along this dimension in pixels </p>"},{"location":"acquire_zarr_c_api/structZarrDimensionProperties/#variable-chunk_size_px","title":"variable chunk_size_px","text":"<pre><code>uint32_t ZarrDimensionProperties::chunk_size_px;\n</code></pre> <p>Size of the chunks along this dimension in pixels </p>"},{"location":"acquire_zarr_c_api/structZarrDimensionProperties/#variable-name","title":"variable name","text":"<pre><code>const char* ZarrDimensionProperties::name;\n</code></pre> <p>Name of the dimension </p>"},{"location":"acquire_zarr_c_api/structZarrDimensionProperties/#variable-scale","title":"variable scale","text":"<pre><code>double ZarrDimensionProperties::scale;\n</code></pre> <p>Unit of the dimension Scale of the dimension </p>"},{"location":"acquire_zarr_c_api/structZarrDimensionProperties/#variable-shard_size_chunks","title":"variable shard_size_chunks","text":"<pre><code>uint32_t ZarrDimensionProperties::shard_size_chunks;\n</code></pre> <p>Number of chunks in a shard along this dimension </p>"},{"location":"acquire_zarr_c_api/structZarrDimensionProperties/#variable-type","title":"variable type","text":"<pre><code>ZarrDimensionType ZarrDimensionProperties::type;\n</code></pre> <p>Type of the dimension </p>"},{"location":"acquire_zarr_c_api/structZarrDimensionProperties/#variable-unit","title":"variable unit","text":"<pre><code>const char* ZarrDimensionProperties::unit;\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/runner/work/acquire-docs/acquire-docs/acquire-zarr/include/zarr.types.h</code></p>"},{"location":"acquire_zarr_c_api/structZarrS3Settings/","title":"Struct ZarrS3Settings","text":"<p>ClassList &gt; ZarrS3Settings</p> <p>S3 settings for streaming to Zarr. </p> <ul> <li><code>#include &lt;zarr.types.h&gt;</code></li> </ul>"},{"location":"acquire_zarr_c_api/structZarrS3Settings/#public-attributes","title":"Public Attributes","text":"Type Name const char * bucket_name const char * endpoint const char * region"},{"location":"acquire_zarr_c_api/structZarrS3Settings/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"acquire_zarr_c_api/structZarrS3Settings/#variable-bucket_name","title":"variable bucket_name","text":"<pre><code>const char* ZarrS3Settings::bucket_name;\n</code></pre>"},{"location":"acquire_zarr_c_api/structZarrS3Settings/#variable-endpoint","title":"variable endpoint","text":"<pre><code>const char* ZarrS3Settings::endpoint;\n</code></pre>"},{"location":"acquire_zarr_c_api/structZarrS3Settings/#variable-region","title":"variable region","text":"<pre><code>const char* ZarrS3Settings::region;\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/runner/work/acquire-docs/acquire-docs/acquire-zarr/include/zarr.types.h</code></p>"},{"location":"acquire_zarr_c_api/structZarrStreamSettings/","title":"Struct ZarrStreamSettings","text":"<p>ClassList &gt; ZarrStreamSettings</p> <p>The settings for a Zarr stream. More...</p> <ul> <li><code>#include &lt;acquire.zarr.h&gt;</code></li> </ul>"},{"location":"acquire_zarr_c_api/structZarrStreamSettings/#public-attributes","title":"Public Attributes","text":"Type Name size_t array_count ZarrArraySettings * arrays unsigned int max_threads bool overwrite ZarrS3Settings * s3_settings const char * store_path ZarrVersion version"},{"location":"acquire_zarr_c_api/structZarrStreamSettings/#detailed-description","title":"Detailed Description","text":"<p>This struct contains the settings for a Zarr stream, including the store path, custom metadata, S3 settings, chunk compression settings, dimension properties, whether to stream to multiple levels of detail, the pixel data type, and the Zarr format version. </p> <p>Note:</p> <p>The store path can be a filesystem path or an S3 key prefix. For example, supplying an endpoint \"s3://my-endpoint.com\" and a bucket \"my-bucket\" with a store_path of \"my-dataset.zarr\" will result in the store being written to \"s3://my-endpoint.com/my-bucket/my-dataset.zarr\". </p>"},{"location":"acquire_zarr_c_api/structZarrStreamSettings/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"acquire_zarr_c_api/structZarrStreamSettings/#variable-array_count","title":"variable array_count","text":"<pre><code>size_t ZarrStreamSettings::array_count;\n</code></pre> <p>The number of arrays in the Zarr stream. </p>"},{"location":"acquire_zarr_c_api/structZarrStreamSettings/#variable-arrays","title":"variable arrays","text":"<pre><code>ZarrArraySettings* ZarrStreamSettings::arrays;\n</code></pre> <p>The settings for the Zarr arrays being streamed. </p>"},{"location":"acquire_zarr_c_api/structZarrStreamSettings/#variable-max_threads","title":"variable max_threads","text":"<pre><code>unsigned int ZarrStreamSettings::max_threads;\n</code></pre> <p>The maximum number of threads to use in the stream. Set to 0 to use the supported number of concurrent threads. </p>"},{"location":"acquire_zarr_c_api/structZarrStreamSettings/#variable-overwrite","title":"variable overwrite","text":"<pre><code>bool ZarrStreamSettings::overwrite;\n</code></pre> <p>Remove everything in store_path if true. </p>"},{"location":"acquire_zarr_c_api/structZarrStreamSettings/#variable-s3_settings","title":"variable s3_settings","text":"<pre><code>ZarrS3Settings* ZarrStreamSettings::s3_settings;\n</code></pre> <p>Optional S3 settings for the store. </p>"},{"location":"acquire_zarr_c_api/structZarrStreamSettings/#variable-store_path","title":"variable store_path","text":"<pre><code>const char* ZarrStreamSettings::store_path;\n</code></pre> <p>Path to the store. Filesystem path or S3 key prefix. </p>"},{"location":"acquire_zarr_c_api/structZarrStreamSettings/#variable-version","title":"variable version","text":"<pre><code>ZarrVersion ZarrStreamSettings::version;\n</code></pre> <p>The version of the Zarr format to use. 2 or 3. </p> <p>The documentation for this class was generated from the following file <code>/home/runner/work/acquire-docs/acquire-docs/acquire-zarr/include/acquire.zarr.h</code></p>"},{"location":"acquire_zarr_c_api/dir_333e6df7611621adb9e912e152b800c4/","title":"Dir /home/runner/work/acquire-docs/acquire-docs/acquire-zarr","text":"<p>FileList &gt; acquire-zarr</p>"},{"location":"acquire_zarr_c_api/dir_333e6df7611621adb9e912e152b800c4/#directories","title":"Directories","text":"Type Name dir include <p>The documentation for this class was generated from the following file <code>/home/runner/work/acquire-docs/acquire-docs/acquire-zarr/</code></p>"},{"location":"acquire_zarr_c_api/dir_ccebfe39b92f73ccebee9a2fb203dc1b/","title":"Dir /home/runner/work/acquire-docs/acquire-docs/acquire-zarr/include","text":"<p>FileList &gt; acquire-zarr &gt; include</p>"},{"location":"acquire_zarr_c_api/dir_ccebfe39b92f73ccebee9a2fb203dc1b/#files","title":"Files","text":"Type Name file acquire.zarr.h file zarr.types.h <p>The documentation for this class was generated from the following file <code>/home/runner/work/acquire-docs/acquire-docs/acquire-zarr/include/</code></p>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/","title":"File acquire.zarr.h","text":"<p>FileList &gt; acquire-zarr &gt; include &gt; acquire.zarr.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"zarr.types.h\"</code></li> </ul>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#classes","title":"Classes","text":"Type Name struct ZarrStreamSettings The settings for a Zarr stream."},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#public-types","title":"Public Types","text":"Type Name typedef struct ZarrStream_s ZarrStream"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#public-functions","title":"Public Functions","text":"Type Name ZarrStatusCode ZarrArraySettings_create_dimension_array (ZarrArraySettings * settings, size_t dimension_count) Allocate memory for the dimension array in the Zarr array settings struct. void ZarrArraySettings_destroy_dimension_array (ZarrArraySettings * settings) Free memory for the dimension array in the Zarr array settings struct. ZarrStatusCode ZarrStreamSettings_create_arrays (ZarrStreamSettings * settings, size_t array_count) Allocate memory for the ZarrArraySettings array in the Zarr stream settings struct. void ZarrStreamSettings_destroy_arrays (ZarrStreamSettings * settings) Free memory for the ZarrArraySettings array in the Zarr stream. ZarrStatusCode ZarrStream_append (ZarrStream * stream, const void * data, size_t bytes_in, size_t * bytes_out, const char * key) Append data to the Zarr stream. ZarrStream * ZarrStream_create (ZarrStreamSettings * settings) Create a Zarr stream. void ZarrStream_destroy (ZarrStream * stream) Destroy a Zarr stream. ZarrStatusCode ZarrStream_write_custom_metadata (ZarrStream * stream, const char * custom_metadata, bool overwrite) Write custom metadata to the Zarr stream. const char * Zarr_get_api_version () Get the version of the Zarr API. ZarrLogLevel Zarr_get_log_level () Get the log level for the Zarr API. const char * Zarr_get_status_message (ZarrStatusCode code) Get the message for the given status code. ZarrStatusCode Zarr_set_log_level (ZarrLogLevel level) Set the log level for the Zarr API."},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#typedef-zarrstream","title":"typedef ZarrStream","text":"<pre><code>typedef struct ZarrStream_s ZarrStream;\n</code></pre>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarrarraysettings_create_dimension_array","title":"function ZarrArraySettings_create_dimension_array","text":"<p>Allocate memory for the dimension array in the Zarr array settings struct. <pre><code>ZarrStatusCode ZarrArraySettings_create_dimension_array (\n    ZarrArraySettings * settings,\n    size_t dimension_count\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>settings</code> The Zarr array settings struct. </li> <li><code>dimension_count</code> The number of dimensions in the array to allocate memory for. </li> </ul> <p>Returns:</p> <p>ZarrStatusCode_Success on success, or an error code on failure. </p>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarrarraysettings_destroy_dimension_array","title":"function ZarrArraySettings_destroy_dimension_array","text":"<p>Free memory for the dimension array in the Zarr array settings struct. <pre><code>void ZarrArraySettings_destroy_dimension_array (\n    ZarrArraySettings * settings\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>settings</code> The Zarr array settings struct containing the dimension array to free. </li> </ul>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarrstreamsettings_create_arrays","title":"function ZarrStreamSettings_create_arrays","text":"<p>Allocate memory for the ZarrArraySettings array in the Zarr stream settings struct. <pre><code>ZarrStatusCode ZarrStreamSettings_create_arrays (\n    ZarrStreamSettings * settings,\n    size_t array_count\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>settings</code> The Zarr stream settings struct. </li> <li><code>array_count</code> The number of Zarr arrays in the dataset to allocate memory for. </li> </ul> <p>Returns:</p> <p>ZarrStatusCode_Success on success, or an error code on failure. </p>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarrstreamsettings_destroy_arrays","title":"function ZarrStreamSettings_destroy_arrays","text":"<p>Free memory for the ZarrArraySettings array in the Zarr stream. <pre><code>void ZarrStreamSettings_destroy_arrays (\n    ZarrStreamSettings * settings\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>settings</code> The Zarr stream settings struct containing the ZarrArraySettings array to free. </li> </ul>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarrstream_append","title":"function ZarrStream_append","text":"<p>Append data to the Zarr stream. <pre><code>ZarrStatusCode ZarrStream_append (\n    ZarrStream * stream,\n    const void * data,\n    size_t bytes_in,\n    size_t * bytes_out,\n    const char * key\n) \n</code></pre></p> <p>This function will block while chunks are compressed and written to the store. It will return when all data has been written. Multiple frames can be appended in a single call. </p> <p>Parameters:</p> <ul> <li><code>stream</code> The Zarr stream struct. </li> <li><code>data</code> The data to append. </li> <li><code>bytes_in</code> The number of bytes in <code>data</code>. This can be any nonnegative integer. On a value of 0, this function will immediately return. </li> <li><code>bytes_out</code> The number of bytes written to the stream. </li> </ul> <p>Returns:</p> <p>ZarrStatusCode_Success on success, or an error code on failure. </p>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarrstream_create","title":"function ZarrStream_create","text":"<p>Create a Zarr stream. <pre><code>ZarrStream * ZarrStream_create (\n    ZarrStreamSettings * settings\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>settings</code> The settings for the Zarr stream. </li> </ul> <p>Returns:</p> <p>A pointer to the Zarr stream struct, or NULL on failure. </p>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarrstream_destroy","title":"function ZarrStream_destroy","text":"<p>Destroy a Zarr stream. <pre><code>void ZarrStream_destroy (\n    ZarrStream * stream\n) \n</code></pre></p> <p>This function waits for all pending writes to complete and frees the memory allocated for the Zarr stream. </p> <p>Parameters:</p> <ul> <li><code>stream</code> The Zarr stream struct to destroy. </li> </ul>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarrstream_write_custom_metadata","title":"function ZarrStream_write_custom_metadata","text":"<p>Write custom metadata to the Zarr stream. <pre><code>ZarrStatusCode ZarrStream_write_custom_metadata (\n    ZarrStream * stream,\n    const char * custom_metadata,\n    bool overwrite\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>stream</code> The Zarr stream struct. </li> <li><code>custom_metadata</code> JSON-formatted custom metadata to be written to the dataset. </li> <li><code>overwrite</code> If true, overwrite any existing custom metadata. Otherwise, if custom_metadata is not empty and the stream has already written custom metadata, this function will return an error. </li> </ul> <p>Returns:</p> <p>ZarrStatusCode_Success on success, or an error code on failure. </p>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarr_get_api_version","title":"function Zarr_get_api_version","text":"<p>Get the version of the Zarr API. <pre><code>const char * Zarr_get_api_version () \n</code></pre></p> <p>Returns:</p> <p>Semver formatted version of the Zarr API. </p>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarr_get_log_level","title":"function Zarr_get_log_level","text":"<p>Get the log level for the Zarr API. <pre><code>ZarrLogLevel Zarr_get_log_level () \n</code></pre></p> <p>Returns:</p> <p>The log level for the Zarr API. </p>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarr_get_status_message","title":"function Zarr_get_status_message","text":"<p>Get the message for the given status code. <pre><code>const char * Zarr_get_status_message (\n    ZarrStatusCode code\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>code</code> The status code. </li> </ul> <p>Returns:</p> <p>A human-readable status message. </p>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h/#function-zarr_set_log_level","title":"function Zarr_set_log_level","text":"<p>Set the log level for the Zarr API. <pre><code>ZarrStatusCode Zarr_set_log_level (\n    ZarrLogLevel level\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>level</code> The log level. </li> </ul> <p>Returns:</p> <p>ZarrStatusCode_Success on success, or an error code on failure. </p> <p>The documentation for this class was generated from the following file <code>/home/runner/work/acquire-docs/acquire-docs/acquire-zarr/include/acquire.zarr.h</code></p>"},{"location":"acquire_zarr_c_api/acquire_8zarr_8h_source/","title":"File acquire.zarr.h","text":"<p>File List &gt; acquire-zarr &gt; include &gt; acquire.zarr.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"zarr.types.h\"\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    typedef struct ZarrStreamSettings_s\n    {\n        const char* store_path; \n        ZarrS3Settings* s3_settings; \n        ZarrVersion\n          version; \n        unsigned int max_threads; \n        bool overwrite; \n        ZarrArraySettings* arrays; \n        size_t array_count; \n    } ZarrStreamSettings;\n\n    typedef struct ZarrStream_s ZarrStream;\n\n    const char* Zarr_get_api_version();\n\n    ZarrStatusCode Zarr_set_log_level(ZarrLogLevel level);\n\n    ZarrLogLevel Zarr_get_log_level();\n\n    const char* Zarr_get_status_message(ZarrStatusCode code);\n\n    ZarrStatusCode ZarrStreamSettings_create_arrays(\n      ZarrStreamSettings* settings,\n      size_t array_count);\n\n    void ZarrStreamSettings_destroy_arrays(ZarrStreamSettings* settings);\n\n    ZarrStatusCode ZarrArraySettings_create_dimension_array(\n      ZarrArraySettings* settings,\n      size_t dimension_count);\n\n    void ZarrArraySettings_destroy_dimension_array(ZarrArraySettings* settings);\n\n    ZarrStream* ZarrStream_create(ZarrStreamSettings* settings);\n\n    void ZarrStream_destroy(ZarrStream* stream);\n\n    ZarrStatusCode ZarrStream_append(ZarrStream* stream,\n                                     const void* data,\n                                     size_t bytes_in,\n                                     size_t* bytes_out,\n                                     const char* key);\n\n    ZarrStatusCode ZarrStream_write_custom_metadata(ZarrStream* stream,\n                                                    const char* custom_metadata,\n                                                    bool overwrite);\n\n#ifdef __cplusplus\n}\n#endif\n</code></pre>"},{"location":"acquire_zarr_c_api/zarr_8types_8h/","title":"File zarr.types.h","text":"<p>FileList &gt; acquire-zarr &gt; include &gt; zarr.types.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;stdbool.h&gt;</code></li> <li><code>#include &lt;stddef.h&gt;</code></li> <li><code>#include &lt;stdint.h&gt;</code></li> </ul>"},{"location":"acquire_zarr_c_api/zarr_8types_8h/#classes","title":"Classes","text":"Type Name struct ZarrArraySettings Properties of a Zarr array. struct ZarrCompressionSettings Compression settings for a Zarr array. @detail The compressor is not the same as the codec. A codec is a specific implementation of a compression algorithm, while a compressor is a library that implements one or more codecs. struct ZarrDimensionProperties Properties of a dimension of a Zarr array. struct ZarrS3Settings S3 settings for streaming to Zarr."},{"location":"acquire_zarr_c_api/zarr_8types_8h/#public-types","title":"Public Types","text":"Type Name enum ZarrDownsamplingMethod"},{"location":"acquire_zarr_c_api/zarr_8types_8h/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"acquire_zarr_c_api/zarr_8types_8h/#enum-zarrdownsamplingmethod","title":"enum ZarrDownsamplingMethod","text":"<pre><code>enum ZarrDownsamplingMethod {\n    ZarrDownsamplingMethod_Decimate = 0,\n    ZarrDownsamplingMethod_Mean,\n    ZarrDownsamplingMethod_Min,\n    ZarrDownsamplingMethod_Max,\n    ZarrDownsamplingMethodCount\n};\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/runner/work/acquire-docs/acquire-docs/acquire-zarr/include/zarr.types.h</code></p>"},{"location":"acquire_zarr_c_api/zarr_8types_8h_source/","title":"File zarr.types.h","text":"<p>File List &gt; acquire-zarr &gt; include &gt; zarr.types.h</p> <p>Go to the documentation of this file</p> <pre><code>#ifndef H_ACQUIRE_ZARR_TYPES_V0\n#define H_ACQUIRE_ZARR_TYPES_V0\n\n#include &lt;stdbool.h&gt;\n#include &lt;stddef.h&gt;\n#include &lt;stdint.h&gt;\n\n#ifdef __cplusplus\nextern \"C\"\n{\n#endif\n\n    typedef enum\n    {\n        ZarrStatusCode_Success = 0,\n        ZarrStatusCode_InvalidArgument,\n        ZarrStatusCode_Overflow,\n        ZarrStatusCode_InvalidIndex,\n        ZarrStatusCode_NotYetImplemented,\n        ZarrStatusCode_InternalError,\n        ZarrStatusCode_OutOfMemory,\n        ZarrStatusCode_IOError,\n        ZarrStatusCode_CompressionError,\n        ZarrStatusCode_InvalidSettings,\n        ZarrStatusCode_WillNotOverwrite,\n        ZarrStatusCodeCount,\n    } ZarrStatusCode;\n\n    typedef enum\n    {\n        ZarrVersion_2 = 2,\n        ZarrVersion_3,\n        ZarrVersionCount\n    } ZarrVersion;\n\n    typedef enum\n    {\n        ZarrLogLevel_Debug = 0,\n        ZarrLogLevel_Info,\n        ZarrLogLevel_Warning,\n        ZarrLogLevel_Error,\n        ZarrLogLevel_None,\n        ZarrLogLevelCount\n    } ZarrLogLevel;\n\n    typedef enum\n    {\n        ZarrDataType_uint8 = 0,\n        ZarrDataType_uint16,\n        ZarrDataType_uint32,\n        ZarrDataType_uint64,\n        ZarrDataType_int8,\n        ZarrDataType_int16,\n        ZarrDataType_int32,\n        ZarrDataType_int64,\n        ZarrDataType_float32,\n        ZarrDataType_float64,\n        ZarrDataTypeCount\n    } ZarrDataType;\n\n    typedef enum\n    {\n        ZarrCompressor_None = 0,\n        ZarrCompressor_Blosc1,\n        ZarrCompressorCount\n    } ZarrCompressor;\n\n    typedef enum\n    {\n        ZarrCompressionCodec_None = 0,\n        ZarrCompressionCodec_BloscLZ4,\n        ZarrCompressionCodec_BloscZstd,\n        ZarrCompressionCodecCount\n    } ZarrCompressionCodec;\n\n    typedef enum\n    {\n        ZarrDimensionType_Space = 0,\n        ZarrDimensionType_Channel,\n        ZarrDimensionType_Time,\n        ZarrDimensionType_Other,\n        ZarrDimensionTypeCount\n    } ZarrDimensionType;\n\n    typedef enum\n    {\n        ZarrDownsamplingMethod_Decimate = 0,\n        ZarrDownsamplingMethod_Mean,\n        ZarrDownsamplingMethod_Min,\n        ZarrDownsamplingMethod_Max,\n        ZarrDownsamplingMethodCount,\n    } ZarrDownsamplingMethod;\n\n    typedef struct\n    {\n        const char* endpoint;\n        const char* bucket_name;\n        const char* region;\n    } ZarrS3Settings;\n\n    typedef struct\n    {\n        ZarrCompressor compressor;  \n        ZarrCompressionCodec codec; \n        uint8_t level;              \n        uint8_t shuffle; \n    } ZarrCompressionSettings;\n\n    typedef struct\n    {\n        const char* name;           \n        ZarrDimensionType type;     \n        uint32_t array_size_px;     \n        uint32_t chunk_size_px;     \n        uint32_t shard_size_chunks; \n        const char* unit;           \n        double scale;               \n    } ZarrDimensionProperties;\n\n    typedef struct\n    {\n        const char* output_key;\n        ZarrCompressionSettings* compression_settings;\n        ZarrDimensionProperties* dimensions;\n        size_t dimension_count;\n        ZarrDataType data_type;\n        bool multiscale;\n        ZarrDownsamplingMethod downsampling_method;\n    } ZarrArraySettings;\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif // H_ACQUIRE_ZARR_TYPES_V0\n</code></pre>"},{"location":"acquire_zarr_c_api/namespaces/","title":"Namespace List","text":"<p>Here is a list of all namespaces with brief descriptions:</p>"},{"location":"acquire_zarr_c_api/classes/","title":"Class Index","text":""},{"location":"acquire_zarr_c_api/classes/#z","title":"z","text":"<ul> <li>ZarrArraySettings</li> <li>ZarrCompressionSettings</li> <li>ZarrDimensionProperties</li> <li>ZarrS3Settings</li> <li>ZarrStreamSettings</li> </ul>"},{"location":"acquire_zarr_c_api/hierarchy/","title":"Class Hierarchy","text":"<p>This inheritance list is sorted roughly, but not completely, alphabetically:</p> <ul> <li>struct ZarrArraySettings Properties of a Zarr array. </li> <li>struct ZarrCompressionSettings Compression settings for a Zarr array. @detail The compressor is not the same as the codec. A codec is a specific implementation of a compression algorithm, while a compressor is a library that implements one or more codecs. </li> <li>struct ZarrDimensionProperties Properties of a dimension of a Zarr array. </li> <li>struct ZarrS3Settings S3 settings for streaming to Zarr. </li> <li>struct ZarrStreamSettings The settings for a Zarr stream. </li> </ul>"},{"location":"acquire_zarr_c_api/modules/","title":"Modules","text":"<p>No modules found.</p>"},{"location":"acquire_zarr_c_api/pages/","title":"Related Pages","text":"<p>Here is a list of all related documentation pages:</p>"},{"location":"acquire_zarr_c_api/class_members/","title":"Class Members","text":""},{"location":"acquire_zarr_c_api/class_members/#a","title":"a","text":"<ul> <li>array_size_px (ZarrDimensionProperties)</li> <li>array_count (ZarrStreamSettings)</li> <li>arrays (ZarrStreamSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#b","title":"b","text":"<ul> <li>bucket_name (ZarrS3Settings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#c","title":"c","text":"<ul> <li>compression_settings (ZarrArraySettings)</li> <li>codec (ZarrCompressionSettings)</li> <li>compressor (ZarrCompressionSettings)</li> <li>chunk_size_px (ZarrDimensionProperties)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#d","title":"d","text":"<ul> <li>data_type (ZarrArraySettings)</li> <li>dimension_count (ZarrArraySettings)</li> <li>dimensions (ZarrArraySettings)</li> <li>downsampling_method (ZarrArraySettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#e","title":"e","text":"<ul> <li>endpoint (ZarrS3Settings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#l","title":"l","text":"<ul> <li>level (ZarrCompressionSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#m","title":"m","text":"<ul> <li>multiscale (ZarrArraySettings)</li> <li>max_threads (ZarrStreamSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#n","title":"n","text":"<ul> <li>name (ZarrDimensionProperties)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#o","title":"o","text":"<ul> <li>output_key (ZarrArraySettings)</li> <li>overwrite (ZarrStreamSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#r","title":"r","text":"<ul> <li>region (ZarrS3Settings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#s","title":"s","text":"<ul> <li>shuffle (ZarrCompressionSettings)</li> <li>scale (ZarrDimensionProperties)</li> <li>shard_size_chunks (ZarrDimensionProperties)</li> <li>s3_settings (ZarrStreamSettings)</li> <li>store_path (ZarrStreamSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#t","title":"t","text":"<ul> <li>type (ZarrDimensionProperties)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#u","title":"u","text":"<ul> <li>unit (ZarrDimensionProperties)</li> </ul>"},{"location":"acquire_zarr_c_api/class_members/#v","title":"v","text":"<ul> <li>version (ZarrStreamSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_functions/","title":"Class Member Functions","text":"<p>Nothing related to Class Member Functions found.</p>"},{"location":"acquire_zarr_c_api/class_member_variables/","title":"Class Member Variables","text":""},{"location":"acquire_zarr_c_api/class_member_variables/#a","title":"a","text":"<ul> <li>array_size_px (ZarrDimensionProperties)</li> <li>array_count (ZarrStreamSettings)</li> <li>arrays (ZarrStreamSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#b","title":"b","text":"<ul> <li>bucket_name (ZarrS3Settings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#c","title":"c","text":"<ul> <li>compression_settings (ZarrArraySettings)</li> <li>codec (ZarrCompressionSettings)</li> <li>compressor (ZarrCompressionSettings)</li> <li>chunk_size_px (ZarrDimensionProperties)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#d","title":"d","text":"<ul> <li>data_type (ZarrArraySettings)</li> <li>dimension_count (ZarrArraySettings)</li> <li>dimensions (ZarrArraySettings)</li> <li>downsampling_method (ZarrArraySettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#e","title":"e","text":"<ul> <li>endpoint (ZarrS3Settings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#l","title":"l","text":"<ul> <li>level (ZarrCompressionSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#m","title":"m","text":"<ul> <li>multiscale (ZarrArraySettings)</li> <li>max_threads (ZarrStreamSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#n","title":"n","text":"<ul> <li>name (ZarrDimensionProperties)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#o","title":"o","text":"<ul> <li>output_key (ZarrArraySettings)</li> <li>overwrite (ZarrStreamSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#r","title":"r","text":"<ul> <li>region (ZarrS3Settings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#s","title":"s","text":"<ul> <li>shuffle (ZarrCompressionSettings)</li> <li>scale (ZarrDimensionProperties)</li> <li>shard_size_chunks (ZarrDimensionProperties)</li> <li>s3_settings (ZarrStreamSettings)</li> <li>store_path (ZarrStreamSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#t","title":"t","text":"<ul> <li>type (ZarrDimensionProperties)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#u","title":"u","text":"<ul> <li>unit (ZarrDimensionProperties)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_variables/#v","title":"v","text":"<ul> <li>version (ZarrStreamSettings)</li> </ul>"},{"location":"acquire_zarr_c_api/class_member_typedefs/","title":"Class Member Typedefs","text":"<p>Nothing related to Class Member Typedefs found.</p>"},{"location":"acquire_zarr_c_api/class_member_enums/","title":"Class Member Enums","text":"<p>Nothing related to Class Member Enums found.</p>"},{"location":"acquire_zarr_c_api/namespace_members/","title":"Namespace Members","text":"<p>Nothing related to Namespace Members found.</p>"},{"location":"acquire_zarr_c_api/namespace_member_functions/","title":"Namespace Member Functions","text":"<p>Nothing related to Namespace Member Functions found.</p>"},{"location":"acquire_zarr_c_api/namespace_member_variables/","title":"Namespace Member Variables","text":"<p>Nothing related to Namespace Member Variables found.</p>"},{"location":"acquire_zarr_c_api/namespace_member_typedefs/","title":"Namespace Member Typedefs","text":"<p>Nothing related to Namespace Member Typedefs found.</p>"},{"location":"acquire_zarr_c_api/namespace_member_enums/","title":"Namespace Member Enums","text":"<p>Nothing related to Namespace Member Enums found.</p>"},{"location":"acquire_zarr_c_api/functions/","title":"Functions","text":""},{"location":"acquire_zarr_c_api/functions/#z","title":"z","text":"<ul> <li>ZarrArraySettings_create_dimension_array (acquire.zarr.h)</li> <li>ZarrArraySettings_destroy_dimension_array (acquire.zarr.h)</li> <li>ZarrStreamSettings_create_arrays (acquire.zarr.h)</li> <li>ZarrStreamSettings_destroy_arrays (acquire.zarr.h)</li> <li>ZarrStream_append (acquire.zarr.h)</li> <li>ZarrStream_create (acquire.zarr.h)</li> <li>ZarrStream_destroy (acquire.zarr.h)</li> <li>ZarrStream_write_custom_metadata (acquire.zarr.h)</li> <li>Zarr_get_api_version (acquire.zarr.h)</li> <li>Zarr_get_log_level (acquire.zarr.h)</li> <li>Zarr_get_status_message (acquire.zarr.h)</li> <li>Zarr_set_log_level (acquire.zarr.h)</li> </ul>"},{"location":"acquire_zarr_c_api/macros/","title":"Macros","text":"<p>Nothing related to Macros found.</p>"},{"location":"acquire_zarr_c_api/variables/","title":"Variables","text":""},{"location":"acquire_zarr_c_api/variables/#z","title":"z","text":"<ul> <li>ZarrStream (acquire.zarr.h)</li> <li>ZarrDownsamplingMethod (zarr.types.h)</li> </ul>"},{"location":"acquire_zarr_c_api/links/","title":"Links","text":"<ul> <li>Related Pages</li> <li>Modules</li> <li>Class List</li> <li>Namespace ListNamespace List</li> <li>Namespace Members</li> <li>Namespace Member Functions</li> <li>Namespace Member Variables</li> <li>Namespace Member Typedefs</li> <li>Namespace Member Enumerations</li> <li>Class Index</li> <li>Class Hierarchy</li> <li>Class Members</li> <li>Class Member Functions</li> <li>Class Member Variables</li> <li>Class Member Typedefs</li> <li>Class Member Enumerations</li> <li>Files</li> <li>File Variables</li> <li>File Functions</li> <li>File Macros</li> </ul>"}]}